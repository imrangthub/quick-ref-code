


#object-data
==================================================
1) Spring boot vs spring Framework
2) Currect Project Structure: componetn / technology / 
3) OAuth2 vs OAuth2.1 in details, all flow details
4) How to maintain Security in Angular.
5) Hibernate loking, Transaction type
6) K8 logging system, centralize logging 
7) Transactional database, distributation system vi Report.


Senior JAVA Engineer-required skill
==================================================
+-------------------------------+-------------------------------------------------------------------------------------+
| Skill Category                | Required Skills & Technologies                                                      |
+-------------------------------+-------------------------------------------------------------------------------------+
| Backend Development           | Java 11/17/21, Spring Framework, Spring MVC, Spring Webflux, Spring Boot,           |
|                               | Spring Cloud, Spring Data, Spring Security, Hibernate, JPA, Caching,                |
|                               | 12 Factor Application                                                               |
|                               | Entity Framework Core, RESTful APIs, GraphQL, DGS Framework                         |
|                               | Microservices Architecture, CQRS, Kafka / Flink Streaming                           |
+-------------------------------+-------------------------------------------------------------------------------------+
| Frontend Development          | Angular / React, TypeScript, JavaScript (ES6+)                                      |
|                               | HTML5, CSS3, Responsive UI (Bootstrap, Material UI)                                 |
|                               | State Management (Redux, NgRx, Signal)                                              |
+-------------------------------+-------------------------------------------------------------------------------------+
|                               | SOLID Principles, Design Patterns                                                   |
|                               | Clean Code, Code Refactoring                                                        |
| System Design & Architecture  | Distributed Transaction Management, CDC (Change Data Capture)                       |
|                               | Scalable & Distributed Systems                                                      |
|                               | Event-Driven Architecture                                                           |
+-------------------------------+-------------------------------------------------------------------------------------+
| Database Management           | PostgreSQL, MySQL, SQL Server                                                       |
|                               | NoSQL Databases (MongoDB, DynamoDB, Redis)                                          |
|                               | Query Optimization & Indexing                                                       |
|                               | Database Sharding & Replication                                                     |
+-------------------------------+-------------------------------------------------------------------------------------+
| DevOps & Cloud                | AWS / Azure                                                                         |
|                               | CI/CD (Jenkins, GitLab CI, Azure DevOps, ArgoCD)                                    |
|                               | Docker, Podman, Kubernetes, Service Mesh (ISTIO)                                    |
|                               | Infrastructure as Code (Terraform/CloudFormation)                                   |
|                               | Monitoring & Logging (ELK, Prometheus, Grafana, OpenTel, Jaeger)                    |
|                               | Kustomize, Helm, Operator                                                           |
|                               | Certificate Management, KMS                                                         |
|                               | Sonarqube                                                                           |
+-------------------------------+-------------------------------------------------------------------------------------+
| System Security               | OAuth 2.0, OpenID Connect (OIDC)                                                    |
|      & Authentication         | SAML, JWT, LDAP                                                                     |
|                               | Secure API Development                                                              |
+-------------------------------+-------------------------------------------------------------------------------------+
| Testing                       | Unit Testing (JUnit, Mockito)                                                       |
|                               | Contact Testing, Integration Testing                                                |
|                               | Test Automation Framework (Selenium, Katalon)                                       |
+-------------------------------+-------------------------------------------------------------------------------------+
| Version Control & Agile       | Git, GitHub, GitLab, Bitbucket                                                      |
|                               | Agile / Scrum Methodologies                                                         |
+-------------------------------+-------------------------------------------------------------------------------------+
| AI & Emerging Technologies    | AI/ML Integration (OpenAI)                                                          |
+-------------------------------+-------------------------------------------------------------------------------------+
| Others                        | JasperReports,Scripting (Bash, Python)                                              |
+-------------------------------+-------------------------------------------------------------------------------------+






#thampPay
==================================================
1) Describe about Microserive, discovery, configserver ?
2) What is Asynchronous and How we can achive Asynchronous ?
3) How is MultiThradding work? How to achive multithreading ?
4) How many way can create thread in java ? what is Thrad pool ?
5) Jdk7 vs jdk8
6) TCP vs Http
7) Ready to deal with older webservice integration ?
8) Why Redis so Faster


Asynchronous programming is a technique that allows a system to perform multiple tasks c
oncurrently without waiting for one task to finish before starting another. 
asynchronous operations allow a program to continue executing other tasks while waiting for a long-running operation 
(like I/O, network calls, or database queries) to complete.

Asynchronous in Java/Spring:
    ‚úî @Async ‚Üí Best for simple background tasks.
    ‚úî CompletableFuture ‚Üí Use when you need to return results asynchronously.
    ‚úî ThreadPoolTaskExecutor ‚Üí Use for efficient thread management.
    ‚úî WebFlux (Mono/Flux) ‚Üí Use for non-blocking reactive APIs.
    ‚úî Kafka / RabbitMQ ‚Üí Use for event-driven async processing. Distributed async processing


How Does Multithreading Work in Java?
    Multithreading is the ability of a CPU to execute multiple threads concurrently.
    Java provides built-in support for multithreading using the Thread class and Runnable interface.
    Java creates threads within the same process (unlike multiple processes, which have separate memory).
    Each thread runs independently but shares resources such as memory and CPU.
    Java's JVM manages thread execution using a thread scheduler, which assigns CPU time based on priority.

How to Achieve Multithreading in Java:
    ‚úî Thread Class ‚Üí Extend for simple threads.
    ‚úî Runnable Interface ‚Üí Implement for flexible thread usage.
    ‚úî ExecutorService ‚Üí Use for efficient thread pool management.
    ‚úî Callable & Future ‚Üí Use when threads need to return values.
    ‚úî ForkJoinPool ‚Üí Use for parallel processing.



JDK 7 focused on minor enhancements, while JDK 8 introduced major improvements like Lambdas, Streams, 
Functional Interfaces, and a new Date-Time API. 

Redis is fast because it operates in-memory, uses efficient data structures, 
and optimizes request handling with a non-blocking event loop. 


#adcty
==================================================
1) What is component of microservices?
2) Microserive reqeust flow.
3) How manage zero downtime for deployment microserice.
4) Waht is Java Striem api, how it make faster ? diffn between normal loop an striem.
5) How spring boot autoconfig work.
6) MyslQuery: a cutomer,order,orderitem table, now fine then cusname, order id and total amount of item.


Key Components of Microservices Architecture:
    API Gateway ‚Äì Handles client requests, routing, authentication, and load balancing.
    Service Discovery ‚Äì Helps services find and communicate with each other dynamically.
    Configuration Management ‚Äì Centralized configuration storage (e.g., Spring Cloud Config, Consul).
    Load Balancer ‚Äì Distributes traffic across multiple service instances (e.g., Nginx, Ribbon).
    Service Communication ‚Äì Uses REST, gRPC, GraphQL, or Messaging (Kafka, RabbitMQ) for inter-service communication.
    Database per Service ‚Äì Each microservice has its own dedicated database (SQL/NoSQL) for data isolation.
    Logging & Monitoring ‚Äì Tools like ELK (Elasticsearch, Logstash, Kibana), Prometheus, Grafana for observability.
    Security ‚Äì Uses JWT, OAuth2, API keys for authentication & authorization.
    Containerization & Orchestration ‚Äì Uses Docker, Kubernetes for scalability & deployment.
    Event-Driven Architecture ‚Äì Uses Kafka, RabbitMQ for asynchronous communication & event sourcing.

How Stream API is Faster? 
    Internal Iteration ‚Äì Optimized iteration handled by JVM, unlike for loops (external iteration).
    Lazy Evaluation ‚Äì Operations are executed only when needed, reducing unnecessary computations.
    Parallel Processing ‚Äì parallelStream() uses multi-threading to process large datasets faster.
    Optimized Pipeline Execution ‚Äì Chains operations without creating intermediate collections, saving memory.


Why Internal Iteration is Faster? 
    Optimized Execution: JVM can optimize iteration logic at runtime.
    Parallel Processing: parallelStream() can process elements using multiple threads.
        parallelStream() splits the list into multiple parts and processes them concurrently.
        Each task runs in a different thread, improving performance on large datasets.

    Lazy Evaluation: Operations execute only when needed, avoiding unnecessary processing.
    Optimized Pipeline Execution ‚Äì Chains operations without creating intermediate collections, saving memory.
External Iteration (for-loops) is manual and less optimized.
Internal Iteration (Stream API) lets JVM handle iteration, enabling faster & parallel execution. üöÄ



How Spring Boot Auto-Configuration Works? 
    Spring Boot Auto-Configuration automatically configures beans based on classpath dependencies and application properties.
    Registers Beans Automatically
    Example: If H2 or MySQL driver is found, Spring Boot configures a DataSource automatically.
    Spring Boot Checks Dependencies
    If you add a dependency (e.g., spring-boot-starter-web), Spring Boot detects it.


#Brain Station 23  | Software Engineer, JAVA
=========================================================
1) What is Spring and Spring Boot?
2) What different between Rest Api and Normal API?
3) How work OAuth2 with Spring Security?
4) What is different Server generated token and Other same info token ?
5) Java Abstract class extemd another abstract class for limit abstraction.
6) Java Interface, Same argument for differnet class in a Method.
7) Oracle Table Indexcing is good if it done for every column in a table?
8) Java Static property.
9) Java Final keyword for class, method, field.
10) If we keep some big abount of data in as Static, is good ? 



API (Application Programming Interface):
    This is a set of rules that allows software applications to communicate with each other. 
    It defines how applications can request and exchange data.

REST Principles:
Identification of resources: Each resource is uniquely identified by a URI (Uniform Resource Identifier). ¬† 
Typically uses lightweight data formats like JSON. ¬† 
Uses standard HTTP methods (GET, POST, PUT, DELETE). ¬†
Stateless:
    The server doesn't store any client session information between requests. ¬† 
Cacheable:
    Responses can be cached, improving performance by reducing the need for repeated server requests. ¬† 
Client-Server:
    The client and server are separate entities. This separation allows them to evolve independently. ¬† 
Layered System:
    The architecture can consist of multiple layers, such as proxies or load balancers, without affecting the client.


Relation SOAP and Http:
    SOAP's Role:
        SOAP defines the structure and format of messages, typically using XML. It specifies how those messages should be exchanged. ¬† 
        It's concerned with the "what" of the message.
    HTTP's Role:
        HTTP is a protocol for transferring data over the web. It defines how data is transmitted between clients and servers. ¬† 
        It's concerned with the "how" of the message is transported.
SOAP provides the message format, and HTTP provides the transport mechanism. 


SOAP API:
    Base: Yes, ultimately, it relies on TCP for the underlying network transport.
    Protocol: Uses the SOAP protocol for message structure and exchange.
    Security: Can use WS-Security for enhanced security features.
    Data Presentation: Primarily uses XML for data representation.
    Transport: Commonly (but not exclusively) uses HTTP as the application-level protocol for transmitting SOAP messages over the network. 
    It can use other protocols also.

REST API:
    Base: Yes, ultimately, it relies on TCP for the underlying network transport.
    Architectural Style: Adheres to the REST architectural style, emphasizing resources and standard HTTP methods.
    Data Presentation: Commonly uses JSON for data representation, but can also use other formats like XML.
    Transport: Uses HTTP as the application-level protocol for communication.

Key Refinements:
    SOAP and HTTP: It's crucial to remember that SOAP is not bound to HTTP. 
    While HTTP is the most common transport, SOAP can operate over other protocols.
    REST and Data format: While JSON is very common with REST, REST is not limited to only Json.
    TCP as the base: Both rest and soap rely on TCP.

It is more accurate to say that SOAP has more built in security protocols, where as REST relies on 
the proper implementation of security practices.


Relationships Summarized:
    TCP is the underlying transport layer that enables communication. ¬† 
    HTTP builds upon TCP, providing a standardized way to exchange messages on the web. ¬† 
    REST APIs utilize HTTP to facilitate communication between clients and servers. ¬† 
    SOAP services can use HTTP (or other protocols like TCP) to transport SOAP messages. ¬† 
    REST servers host REST APIs, and SOAP servers host SOAP services.



OAuth2 with JWT Flow in Spring Security:
1Ô∏è‚É£ User Provides Credentials
    The user logs in to the Authorization Server (e.g., Keycloak, Okta).
    If credentials are valid, the server generates a JWT token.

2Ô∏è‚É£ Authorization Server Issues JWT
    The JWT token is signed (using a private key) and sent to the user.
    This JWT contains claims like sub (subject), exp (expiration), roles, etc.

3Ô∏è‚É£ User Sends Request to Resource Server
    The user includes the JWT in the Authorization header:
    The request is sent to the Resource Server (Spring Boot API).

4Ô∏è‚É£ Resource Server Validates JWT
    The Resource Server verifies the JWT using the public key of the Authorization Server.
    If valid, it extracts the claims (like user roles) and grants access.

5Ô∏è‚É£ Response Sent
    If the JWT is valid, the requested resource is returned.
    If invalid/expired, the request is denied (401 Unauthorized or 403 Forbidden).



Abstraction Rule:
    If an abstract method remains unimplemented, the first concrete subclass must implement it.
    If Mammal does not implement makeSound(), then Dog must.
    Otherwise, the compiler will throw an error.


Java Static DataIssu:
    High Memory Consumption (Heap Usage):
        Static fields are stored in the heap memory (inside the class metadata section).
        If the data is large, it remains in memory as long as the application is running, leading to:
        Increased RAM usage.
        OutOfMemoryError if the heap is full.


    Class Loading Delays
        Static properties are initialized when the class is loaded.
        If the data is too large, class loading takes more time, delaying application startup.

    Thread Safety Issues
        If multiple threads modify the static data, race conditions and inconsistent data may occur.
        Solution: Use synchronized blocks or Concurrent Collections.

    Memory Leaks
        If the static data holds references to other objects, those objects cannot be garbage collected, leading to a memory leak.



#BRAC IT Services Limited | Sr. Software Engineer, JAVA,
=========================================================

1) What is Java Private Class activity
2) Runtime polymorphism
3) Java String = new String(getName()) in a Loop ?
4) Java String = getName() in a Loop ?
5) obj1 == obj2 how will retrun true for different object.
6) Spring Been Scope
7) What is Singleton been and Other been in Spring ?
8) Which been are not Singleton in Spring.
9) What is Servlet, how work it, is Servlet Singleton or not ?
10) Is every http request generate a single thared for per request ?


When to Use a Private Class?
üî∏ When a class is only needed inside another class (e.g., helper/utility logic).
üî∏ When you want to encapsulate sensitive logic that should not be accessible externally.
A private class can only exist inside another class (it cannot be a top-level class).
    There are two types of private inner classes:
        Private (Non-Static ) Inner Class:



Runtime Polymorphism in Java:
üîπ Runtime polymorphism (also called dynamic method dispatch) is a concept where method overriding allows a
   subclass to provide a specific implementation of a method that is already defined in its superclass.
üîπ The method to be executed is determined at runtime based on the object type, not the reference type.

Method Overloading (same method name with different parameters) is compile-time polymorphism, NOT runtime polymorphism.

Static Methods Do NOT Support Runtime Polymorphism, its call Method Hiding.
    The method is resolved at compile time based on the reference type (Animal), not the object type (new Dog()).
    Even though myAnimal refers to a Dog object, it still calls Animal.makeSound(), not Dog.makeSound().


String concatenation in a loop can lead to high memory usage because strings in Java are immutable. 
Each concatenation creates a new String object.
Use StringBuilder or StringBuffer for concatenation in loops.



How Tomcat Handles Requests (Default Behavior)
    1Ô∏è‚É£ A client sends an HTTP request to Tomcat.
    2Ô∏è‚É£ Tomcat assigns a thread from its pool (e.g., http-nio-8080-exec-1).
    3Ô∏è‚É£ The thread processes the request (e.g., runs a Spring MVC controller).
    4Ô∏è‚É£ After sending the response, the thread is returned to the pool for reuse.


Default Behavior in Spring Boot:
    Spring MVC	Tomcat (Blocking, Thread-per-Request)
    Spring WebFlux	Netty (Non-blocking, Event-Driven)

Using WebFlux with Netty (Default):
    If you use Spring Boot with WebFlux, Netty is used automatically:
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-webflux</artifactId>
    </dependency>
‚úî No need to specify Netty explicitly.
‚úî Spring Boot excludes Tomcat and enables Netty automatically.



#WaltonGroup | Fullstack Software Engineer
===========================================
1) What king of helping hand you need to develope a complate application development ?
2) Why app Performance slower ?
3) How to prevent multiple hit or too many hit a api on your application.
4) About corss origin access.
5) What is Good Practiese for application developint in backend layer. 
6) Hibernate caching.
7) How to provide security to a REST Api?
8) How to provide security to angular app ?



#Seirion Software Engineer | Ahsanullah University 
==================================================
1) Stirng memory Lack
2) Java volatile keyword
3) Generate randol number withh our builin 
4) Creae custom exception
5) db check duplicated value
6) convaett string to date date to Strin
7) url encodieng tiny url,  biltr url
8) microservice chanalge
9) product app issue finding
10) micaroservice error regiliency, concurrency user, 
11) Optomize sisgin for new application application layer and db layer



=================================================
@@##ex-solution
=================================================  
https://www.datacamp.com/blog/top-sql-interview-questions-and-answers-for-beginners-and-intermediate-practitioners
https://www.interviewbit.com/sql-interview-questions/




================================================= 
##Enosis exam
================================================= 
Problem solving
Java basics
SQL basics
JavaScript basics
90 mins from the time you start.

Basic programming, analytical, testing and debugging questions 
1. Find the duplicates elements among arrays. 

String right alignment , 
Map Vector Tree related problems.You are asked to write the code for 
right-aligning a text in a text-box.

1. Reverse string ( input=abc, output=cba) 
3. Check duplicate elements... etc Testing Question: 
1. They will give a picture of a software and tell you to find the testing features 
2. Finding errors from code

 (1) Write a function that will receive a string as an input and will return the string in reverse order. 
 (2) Write a function that will print the following series of numbers using only one loop: "1,2,3,4,5,6,7,8,9,10,9,8,7,6,5,4,3,2,1" 
 (3) Write a function that will print all the multiples of 3 between 1-200 ( in reverse order ) There were other programming questions as well but of the same difficulty level.
 
4. print multiples of 3 from 200 to 1 etc coding test : give a window size .

 
1. there is some basic questions from math like simple probability finding, 
finding age of father from son's age, angle finding, perimeter, 
circle related problem. very easy questions. it may have 1-2 mcq. 
2. Then there is coding questions. first questions will be - what are the basic concepts of OOP and write a code to implement them. 
after this there will be some coding problem- like string reverse etc. 

sql queries:
	find the max, 2nd max salary, swap two columns of two table etc. 
	practice some query. it may have 1-2 mcq. 4. then there will be questions from QA. like difference 
    among white,black, gray box testing. 
	then there will be picture find out diff in those pictures, then there will be some scenario - 
    you have to write how will you test it or how you will you improve it. 
	very easy questions. write as your wish. last questions will be what is your most memorable achievement,
 Write code of 1st 100 Prime number series, Fibonnaci series. Testing related questions.
 
 
=================================================================
##javaScript
=================================================================
https://builtin.com/software-engineering-perspectives/javascript-interview-questions


<html>
<style>
h2 {
  color: red;
}

.pcls {
  text-align: right;
  color: red;
}
</style>
<body>


<h1 id="hid1">Hello </h1>

<h2 id="hid1">Hello </h2>

<p class="pcls">This is simple prapgrap</p>

<p id="p2id" style="color: red"></p>

<div id="p3id"></div>

<input type="text" id="inpid"></input>

<button id="btn1">ClickMe</button>


<script>
    console.log("app ready=============");
    const btn1 = document.getElementById("btn1");
    const p2 = document.getElementById("p2id");

    btn1.addEventListener("click", function(){
        var text = document.getElementById("inpid").value;
        console.log(text);
        document.getElementById("p2id").innerText=text;
        document.getElementById("p3id").innerHTML='<h1>'+text+'</h1>';
    });
</script>

Loop:
------------
let rsVal = 0;
let incCal = 1;

for( let i=1; i<=19; i++){
    if(rsVal==10){
      incCal=-1;
    }
    rsVal+=incCal;
    console.log(rsVal);
}
----------

let myArr = [2,3,3,4,5,5,6,7,7]
let dupArr = [];
let mySet = new Set();
let myStr = 'Md Imran Hossain';

console.log(myStr.split(" "))

myArr.forEach(item => {
  // console.log(item);
});

for(myit of myArr){
  mySet.add(myit);
}

let uniqArr = [...mySet];
console.log(uniqArr);

let duplicates = myArr.filter((item, index) => myArr.indexOf(item) !== index);
console.log(duplicates);


    


=================================================================
Mysql
==================================================================
SqL:
select floor(avg(price)) from book
select truncate(avg(price),3) from book
select round(avg(price),2) from book


truncate() then cuts off the decimal portion after 3 decimal places without rounding.
floor() always rounds down, even if the decimal part is closer to the next whole number.
It always results in a whole number (an integer).
round() then rounds the average to 2 decimal places, using standard rounding rules.

StringOps:
select reverse(name) from book
select lpad(name,100,"*") from book
select repeat(name,10) from book
select LOCATE("g",name) from book
select distinct type from book

1) price is maximum:
select max(price) as maxData from book;

select * from book
where price=(select max(price) from book)

2)Find the Second Maximum Salary	
select max(price) as maxData from book
where price<(select max(price) from book)

select * from book
order by price desc
limit 1 offset 1;

select * from book
order by id desc
limit 1 offset 2


3)Find Employees Who Earn More Than the Average Salary
select * from book
where price> (select avg(price) from book)


GroupBy:
select type, count(id) from book
group by type


select depid, count(depid) from std_tbl
group by depid


select type, count(id), max(price) from book
group by type

SELECT type, GROUP_CONCAT(name SEPARATOR ', ') as names, COUNT(*) as count 
FROM book 
GROUP BY type;

addColumn:
ALTER TABLE std_tbl ADD COLUMN depid INT;
alter table std_tbl add column dep int default 1;
alter table std_tbl drop column depid2;

Update:
update std_tbl set dep=2 where id in (1,2,3)
update std_tbl set dep=2 where id between 1 and 10 

select * from std_tbl 
where gender like 'M%'

SwapColumnDametabl:
UPDATE std_tbl
SET
 bookid = (@temp := bookid),
 bookid=depid,
 depid=@temp
 where id =1
 
UPDATE employees
SET salary = salary * 1.10
WHERE department = 'Sales';


	

SELECT * FROM Customers WHERE CustomerID IN (SELECT CustomerID FROM Orders);

(SELECT CITY, LENGTH(CITY) AS CITY_LENGTH
 FROM STATION
 WHERE LENGTH(CITY) = (SELECT MIN(LENGTH(CITY)) FROM STATION)
 ORDER BY CITY
 LIMIT 1)
 
UNION ALL
 
(SELECT CITY, LENGTH(CITY) AS CITY_LENGTH
 FROM STATION
 WHERE LENGTH(CITY) = (SELECT MAX(LENGTH(CITY)) FROM STATION)
 ORDER BY CITY
 LIMIT 1);



Give some examples of common SQL commands of each type.
	DDL: CREATE, ALTER TABLE, DROP, TRUNCATE, and ADD COLUMN
	DML: UPDATE, DELETE, and INSERT
	DCL: GRANT and REVOKE
	TCL: COMMIT, SET TRANSACTION, ROLLBACK, and SAVEPOINT
	DQL: ‚Äì SELECT
	 

13. What is the order of appearance of the common statements in the SELECT query?
SELECT ‚Äì FROM ‚Äì JOIN ‚Äì ON ‚Äì WHERE ‚Äì GROUP BY ‚Äì HAVING ‚Äì ORDER BY ‚Äì LIMIT

14. In which order the interpreter executes the common statements in the SELECT query?
FROM ‚Äì JOIN ‚Äì ON ‚Äì WHERE ‚Äì GROUP BY ‚Äì HAVING ‚Äì SELECT ‚Äì ORDER BY ‚Äì LIMIT










=================================================
@@##ead | staff-level or senior Java roles
=================================================     
1. ‚òï What really happens when you type new in Java?
Why it‚Äôs asked:
To assess your understanding of memory management, object creation, and the JVM under the hood.

Your Answer Should Cover:
    new allocates memory on the heap.
    Constructor is called after memory allocation.
    If class uses finalizers or implements AutoCloseable, lifecycle tracking comes into play.
    The object is managed by GC (Garbage Collector) post-creation.



2. How does Java handle memory management and garbage collection?
Why it‚Äôs asked:
To gauge how well you understand the JVM‚Äôs automatic memory management and how to write performant code.

Your Answer Should Cover:
    JVM memory areas: Heap, Stack, PermGen/Metaspace, Code Cache.
    Generational GC: Young Gen (Eden, Survivor), Old Gen.
    GC algorithms: G1GC, ZGC, Shenandoah (especially for low-latency systems).
    Memory leaks in Java (e.g., via static references or poorly managed caches).
    Latest enhancements in java with respect to memory mamangement



3. What is the difference between Virtual Threads and Platform Threads in Java?
Why it‚Äôs asked:
Java 21 introduced Virtual Threads ‚Äî a game-changer for concurrent applications.

Your Answer Should Cover:
    Platform threads are OS-managed; expensive to create and block.
    Virtual threads (Project Loom) are lightweight, Java-managed threads.
    Ideal for I/O-heavy apps like microservices and APIs.
    Supported by structured concurrency for task orchestration.



4. How does the Java Memory Model ensure visibility and ordering?
Why it‚Äôs asked:
Multithreaded correctness is more important than ever ‚Äî especially for high-concurrency apps.

Your Answer Should Cover:
    JMM defines how threads interact through memory.
    volatile ensures visibility (not atomicity).
    synchronized and java.util.concurrent primitives create happens-before relationships.
    CPU caches and instruction reordering necessitate memory fences.



5. What are the implications of using Optional in method signatures?
Why it‚Äôs asked:
Modern Java pushes for clarity, null safety, and immutability.

Your Answer Should Cover:
    Use Optional for return types, not parameters.
    Optional is not serializable by default ‚Äî watch out in APIs.
    Improves readability and eliminates boilerplate null checks.



6. Explain how Spring Boot uses Java features under the hood
Why it‚Äôs asked:
To test how deeply you understand Java‚Äôs synergy with Spring ‚Äî a must for backend engineers.

Your Answer Should Cover:
    Uses annotations, reflection, and bytecode manipulation (via CGLIB or ASM).
    Heavy use of Optional, streams, functional interfaces in newer versions.
    Spring AOP relies on dynamic proxies (JDK or CGLIB).
    Beans are mostly managed via constructor injection (encouraging immutability).



7. What are Records in Java, and when should you use them?
Why it‚Äôs asked:
To check if you‚Äôre keeping up with modern Java.

Your Answer Should Cover:
    Records are immutable data carriers, introduced in Java 14 (preview), stabilized in Java 16.
    Concise syntax: no boilerplate getters, setters, equals/hashCode.
    Use for DTOs, value objects ‚Äî not for entities with behavio



8. How would you design a thread-safe, high-throughput in-memory cache in Java?
Why it‚Äôs asked:
To test concurrency, collections, and design thinking.

Your Answer Should Cover:
    Use ConcurrentHashMap.
    Support eviction (size-based/time-based) with Caffeine.
    Avoid global locks; prefer atomic operations.
    For time-based expiry: ScheduledExecutor or Caffeine.





9. How do you debug memory leaks or performance issues in a Java application?
Why it‚Äôs asked:
Real-world senior dev work involves firefighting prod issues.

Your Answer Should Cover:
    Use tools: VisualVM, JFR, JConsole, YourKit, or Flight Recorder.
    Look for GC activity, object retention, thread dumps.
    Detect memory leaks via heap dumps, reference chains.




10. What are sealed classes and why do they matter?
Why it‚Äôs asked:
To check if candidate is using the latest java enhancements/features or not . Java 17 LTS introduced sealed classes to enhance polymorphic control.

Your Answer Should Cover:
Sealed classes restrict inheritance using permits keyword.
Improves exhaustiveness checks in switch expressions.
Great for modeling state machines, domain models, or exhaustive enums.





=================================================
@@##sr.Software Engineer | req skills
=================================================     

##Core Java	
=================================================
1) Java Class, Fields, Methods and Objects
Ans:
    Class: A blueprint for creating objects, defining their properties and behaviors.
    Fields: Variables declared inside a class to represent the properties of objects.
    Methods: Functions within a class that define the behavior of its objects.
    Objects: Instances of a class, created using the new keyword, representing real-world entities.


2) Access Modifiers, Constructor, Object creation
Ans:
Access Modifiers: Control the visibility of classes, fields, and methods:
Public: Accessible from anywhere.
Private: Accessible only within the same class.
Protected: Accessible within the same package and by subclasses.
    The protected access modifier allows access to members within the same package and 
    by subclasses (even if they are in different packages).
    Restrictions: Non-subclass classes outside the package1 cannot directly access protected members.
    Examlple:
        Parent.java class has a protected method: protected void displayMessage();
        Now a chile cllas in differenet package not able to accessa this displayMessage(); createing new object of Parent class
        But able to access with in Child class if Clild class extedn Prant class as:
         // Child class in package2
            package package2;
            import package1.Parent;

            public class Child extends Parent {
                public void show() {
                    displayMessage(); // Accessible because Child is a subclass of Parent
                }
            }

    But not as:
        // Parent parent = new Parent();
        // parent.displayMessage(); // Compilation error: displayMessage() is not accessible directly.
Default (no modifier): Accessible within the same package.

Constructor:
    A constructor is a special method in Java that is used to initialize objects when they are created.
    It has the same name as the class.
    It has no return type.
    Can be overloaded.
Called automatically when an object is created using new.
Every Java class has a default constructor only if you don't define any constructor yourself.
If you explicitly declare a constructor, Java does not create the default one.


3) Java Record
Ans:
    A record is a special kind of class introduced in Java 14 (Preview) and finalized in Java 16.
    It is designed to simplify the creation of immutable data objects by automatically generating constructors, 
    getters, toString(), equals(), and hashCode() methods.

    Example a Record:
        // Record declaration
        public record Person(String name, int age) {}
        
        public class Main {
            public static void main(String[] args) {
                // Creating a record object
                Person person = new Person("Alice", 30);

                // Accessing fields (no 'get' prefix)
                System.out.println(person.name()); // Output: Alice
                System.out.println(person.age());  // Output: 30

                // Implicitly generated toString
                System.out.println(person); // Output: Person[name=Alice, age=30]
            }
        }
Limitations of Records:
    Cannot extend other classes (records are implicitly final).
    Cannot have mutable fields.
    Designed only for data-carrying classes, not behavior-rich objects.

Enum vs Records:
    Use Records for immutable data structures with a focus on simplicity and reduced boilerplate.
    Use Enums for defining a fixed set of constants with optional, shared, or custom behavior.
    Records Can have custom methods, but mainly used for data storage
    Enum for Constant values (e.g., days of the week, statuses)
    Records for Immutable data objects (e.g., DTOs, key-value pairs)

When to Use What?
    Use enum ‚Üí When defining constant values (e.g., DAYS_OF_WEEK, USER_ROLE).
    Use record ‚Üí When you need immutable data objects with minimal boilerplate.

What Does "Immutable Data Object" Mean?
    An immutable data object is an object whose state (fields) cannot be changed after creation.
    Once you set its values (via constructor), you cannot modify them.




4) OOP in Java - Abstraction, Polymorphism, Encapsulation, Inheritance
Ans:
Abstraction:
    Hides implementation details and shows only the essential features.
    Achieved using abstract classes and interfaces.
Polymorphism
    Allows one entity to take many forms (e.g., method overriding and overloading).
    Example (Method Overriding):
Encapsulation
    Restricts direct access to fields and methods using access modifiers.
    Achieved by using private fields with public getters and setters.
Inheritance
    Allows a class to inherit fields and methods from a parent class.
    Achieved using the extends keyword.


In Java, overloading can be broadly categorized into three types, each serving a specific purpose:
    1. Method Overloading
    2. Constructor Overloading
    3. Operator Overloading (Limited to Built-in Operators),Java does limited operator overloading, mainly with built-in types!
        +	Numbers, Strings	5 + 10 = 15, "Hello" + "World" = "HelloWorld"
        +=	Numbers, Strings	x += 5, "Java" += " Rocks!"
        ==	Primitives (value), Objects (reference)	5 == 5 (true), new String("Hi") == new String("Hi") (false)
        Other operators (like -, *, /, %, etc.) are NOT overloaded and only work with their specific data types.
        Java does not allow custom operator overloading like C++ does!

5) JavaString, StringBuilder, StringBuffer, TextBlock
String:
    Immutable sequence of characters.
    Operations like concatenation create new objects.
    Example:
    String str = "Hello";
    str = str + " World"; // Creates a new String object

StringBuilder:
    Mutable and faster for single-threaded operations.(Not thread-safe)
    Ideal for frequent string modifications.
    Suitable for single-threaded operations.
Example:
    StringBuilder sb = new StringBuilder("Hello");
    sb.append(" World"); // Modifies the same object

StringBuffer:
    Mutable and thread-safe (synchronized).
    Slower than StringBuilder due to synchronization overhead.
    Suitable for multi-threaded operations.
    Example:
        StringBuffer sb = new StringBuffer("Hello");
        sb.append(" World");
        
Both StringBuilder and StringBuffer are mutable classes for handling strings.

TextBlock:
Introduced in Java 15, it simplifies multiline string creation.
Uses triple quotes (""") for better readability.
Example:
    String json = """
                {
                    "name": "Alice",
                    "age": 30
                }
                """;


6) StringLitterals, String creating with new keyworkd:
Ans:
    StringLiterals:
        Strings created using double quotes ("") are stored in the String Pool,  is located in the heap memory.
        If a literal already exists in the pool, the same reference is returned.
        Example:
            String s1 = "Hello"; // Stored in String Pool
            String s2 = "Hello"; // Same reference as s1
            System.out.println(s1 == s2); // Output: true

    String with new Keyword:
        Creates a new String object in heap memory, bypassing the String Pool.
        Even if the content is the same, a new reference is created.
    Example:
        String s1 = new String("Hello"); // New object in the heap
        String s2 = new String("Hello"); // Another new object
        System.out.println(s1 == s2); // Output: false (different references)



7) String constant pool, String comparison, TrimString:
Ans:
Key Points:
    When a new string literal is created, Java first checks the pool to see if an equivalent string already exists.
    If it exists, the new reference points to the existing object. Otherwise, a new object is created in the pool.
    Strings created using new are stored in the heap, not in the pool.

String Comparison:
There are two ways to compare strings in Java:
    Using ==:
        Compares references, not content.
        Only returns true if both references point to the same object.
    Using .equals():
        Compares the content of the strings.
        Returns true if the actual text of the strings is identical

TrimString:
    It does not modify the original string (strings are immutable in Java).
    Returns a new String without leading or trailing spaces.




8) StringMatching, Searching, convertion wiht valueOf(), String Concatanation
Ans:
String Matching:
    equals(): Checks content equality (case-sensitive).
    equalsIgnoreCase(): Ignores case during comparison.

String Searching:
    contains(): Checks if a string contains a sequence of characters.
    indexOf(): Returns the index of the first occurrence of a substring.
    startsWith() / endsWith(): Checks if the string starts/ends with a specific substring.

Conversion with valueOf():
    Converts data types (e.g., integers, floats, objects) into a String.
    Example:
        int num = 42;
        String str = String.valueOf(num); // Converts int to String
        System.out.println(str); // "42"

StringConcatenation:
    Neither + nor .concat() modifies the original strings (s1, s2). 
    Instead, they both create new String objects to store the result.

StringBuilder and StringBuffer do not create a new String object for every modification.


Use +:
    Handles implicit type conversions.
    Readability is a priority: The + operator is more intuitive and easier to read.
    Simple concatenations: When you're concatenating a few strings or literals.
    Mixed types: When you need to concatenate non-String types (e.g., numbers, booleans).

Use .concat() (String Method):
    Explicit string operations are needed: Use .concat() when you want to emphasize you're working strictly with String objects.
    Performance is not critical: Though .concat() is slightly faster than +.



9) Why is the character array preferred over string for storing confidential information?
Ans:
    Sensitive data stored in a String (e.g., passwords) remains in memory until garbage collection clears it, 
    which may not happen immediately.
    This increases the risk of memory exposure (e.g., through memory dumps).
    With a char[], you have full control over how long the data stays in memory and can clear it immediately after use.
    A String's contents are outside your control and might stay in memory longer.


10) Replace character in string, Format String
Ans:
    Using replace() : Example: "hello".replace("l", "x") ‚Üí "hexxo"
    Replaces all occurrences of a character or substring with another.
    Using replaceAll() : Example: "hello123".replaceAll("\\d", "x") ‚Üí "helloxxx"
    Replaces all substrings that match a regular expression.
Use replace() for simple replacements and replaceAll() for regex-based replacements.

    Using replaceFirst()
    Replaces the first substring that matches a regular expression.

    Use the String.format() method to format strings with placeholders.
        %s: String
        %d: Integer
        %f: Floating-point number

    Alignment and Padding:
        Left-align: %-n
        Right-align: %n



11) Pass by Value and Pass by Reference:
Ans:
    Pass by value
        A copy of the variable's value is passed to the function, and the function works on the copy. 
        Changes made to the variable within the function will not affect the original variable.

    Pass by reference
        The memory address of the variable is shared with the function argument. 
        This means that any changes made to the argument within the function will also affect the original variable.
"In Java, everything is passed by value"

Java is always pass by value, but for objects, the "value" passed is the reference to the same object. 
This is why it sometimes feels like "pass by reference."

Pass by Value for Primitives:
    For primitive types (int, double, etc.), the value is copied directly.
    Changes to the parameter inside the method do not affect the original value.
    Example:
        public class Example {
            public static void main(String[] args) {
                int x = 10;
                modifyPrimitive(x);
                System.out.println("x after method call: " + x); // Output: 10
            }

            public static void modifyPrimitive(int num) {
                num = 20; // Modifies the local copy, not the original
            }
        }

Pass by Value for Objects:
    For objects, the value of the reference (the memory address) is passed, not the object itself.
    This means the method receives a copy of the reference, pointing to the same object.
    You can modify the object's internal state, but you cannot reassign the original reference in the caller's scope.

Example: Modifying Object State:
        class Person {
            String name;
        }

        public class Example {
            public static void main(String[] args) {
                Person person = new Person();
                person.name = "Alice";
                modifyObject(person);
                System.out.println("Name after method call: " + person.name); // Output: Bob
            }

            public static void modifyObject(Person p) {
                p.name = "Bob"; // Modifies the object itself
            }
        }
Example: Re-assigning Reference:
    public class Example {
        public static void main(String[] args) {
            Person person = new Person();
            person.name = "Alice";
            reassignReference(person);
            System.out.println("Name after method call: " + person.name); // Output: Alice
        }

        public static void reassignReference(Person p) {
            p = new Person(); // Reassigns the local reference, not the original one
            p.name = "Bob";
        }
    }


12) Java Date & Time:
Ans:
    Java 8 introduced a new java.time package for handling date & time efficiently with LocalDate, LocalTime, LocalDateTime,
    ZonedDateTime (Date, Time & Timezone),Duration, Period and more.
    For working with date, time, and both.
    Format and parse with DateTimeFormatter.
    Instant for timestamps, Duration for time differences.
    Date and Calendar for older date handling(Legacy Classes)


java.time package:
------------------------------------------------------------
| Class              | Purpose             | Example Output               |
------------------------------------------------------------
| LocalDate         | Date only           | 2025-03-18                   |
------------------------------------------------------------
| LocalTime         | Time only           | 14:30:10                     |
------------------------------------------------------------
| LocalDateTime     | Date & Time         | 2025-03-18T14:30:10          |
------------------------------------------------------------
| ZonedDateTime     | Date, Time & Timezone | 2025-03-18T14:30:10+06:00[Asia/Dhaka] |
------------------------------------------------------------
| Instant          | UTC Timestamp       | 2025-03-18T08:30:10Z         |
------------------------------------------------------------
| Duration         | Time Difference     | 2 hours                       |
------------------------------------------------------------
| Period           | Date Difference     | 25 years, 2 months            |
------------------------------------------------------------
| DateTimeFormatter | Formatting         | 2025/03/18 14:30:10           |
------------------------------------------------------------

Period (Date Difference)
‚úÖ Used for measuring days, months, years between dates

Duration (Time Difference)
‚úÖ Used for measuring time differences (e.g., between two timestamps).

DateTimeFormatter (Formatting & Parsing)
‚úÖ Converts LocalDateTime to String and vice versa.



Multiple Inheritance ( Not Supported in Java for Classes)
A class inherits from multiple parent classes.

Multilevel Inheritance (Supported in Java)
A class is inherited in a chain (hierarchical manner).




13) Java Interfaces and Abstract class, Java Enum, Java Iterator and Iterable
Ans:
    Interface
        An interface is a reference type, similar to a class, that can contain only constants, method signatures, 
        default methods, static methods, and nested types.
        All methods in an interface are implicitly abstract (unless defined as default or static).
        An interface defines a contract that a class must follow if it implements the interface, 
        but it does not provide the method implementations.
        A class can implement multiple interfaces, allowing for more flexible design (multiple inheritance).

    Abstract Class:
        An abstract class is a class that cannot be instantiated on its own and is intended to be subclassed.
        It can contain both abstract methods (methods without a body) and concrete methods (methods with a body).
        It can have fields, constructors, and method implementations, unlike interfaces.
        A subclass of an abstract class must implement all the abstract methods unless it is also abstract.
        Abstract classes are typically used to represent "shared" functionality for a group of related classes.
    Enum
        An enum in Java is a special class that represents a group of constants (unchangeable variables).
        Enums are more powerful than simple constants because they can have fields, methods, and constructors.
        They are implicitly final and cannot be subclassed.
        Enums are useful when you have a fixed set of related constants, such as days of the week, directions, or status codes.

Interface:
    Used to define a contract (behavior) that multiple classes can implement.
    Focuses on "what to do" rather than "how to do it."

If you want to force multiple classes to have the same method signatures, use interfaces.
Example: Different payment gateways (PayPal, Stripe) must implement processPayment().
Java does not support multiple inheritance with classes, but a class can implement multiple interfaces.

Abstract Class:
    Serves as a base class for other classes.
    Can define common functionality while leaving some methods abstract for subclasses to implemen
You Need Partial Implementation (Some Methods Implemented)
If a class has common behavior for all subclasses but also needs some abstract methods, use an abstract class.
If you want to provide some common behavior while allowing subclasses to define certain methods.
Example: All animals sleep, but their sound (makeSound()) differs.
You Want to Use a Constructor
Unlike interfaces, abstract classes can have constructors.
You Want to Use Access Modifiers (private, protected, etc.)
    Methods in interfaces are public by default.
    Abstract classes allow private, protected, or public methods.



14) Java Object class and its mehtod: - wait(), notify(), toString(), equals(), hashCode()
Ans:
    In Java, every class implicitly inherits from the Object class, which is the root of the class hierarchy. 
    The Object class provides several methods that are fundamental for all Java objects.
    wait() and notify(): Used in multi-threading for inter-thread communication.
    toString(): Helps in providing a string representation of the object.
    equals() and hashCode(): Important for object comparison and hashing in collections. 
    When you override equals(), you must also override hashCode() to maintain consistency.

hashCode:
To maek unique key inseide HashMap object as key need override hash-code of the object.
Overriding hashCode (along with equals) is critical for situations where you need to use custom objects as keys in 
hash-based collections (like HashMap, HashSet, and Hashtable). 

Optimizing Performance in Hash-based Caching:
    Why it's needed: When using a hash-based cache (like ConcurrentHashMap), hashCode is used to quickly look up objects. 
    If hashCode and equals are not properly overridden, the cache may fail to correctly identify existing entries, 
    leading to poor performance or incorrect cache lookups.


Implementing Data Integrity in Custom Data Structures:
    Why it's needed: If you're building your own data structure (such as a custom map or set) that needs to 
    store objects based on content equality, overriding hashCode and equals ensures that your structure works correctly.
    Example: If you're building a custom EmployeeRegistry that stores Employee objects based on employeeId, 
    you need to implement hashCode and equals to ensure that the registry behaves correctly when checking for 
    duplicates or updating existing entries.

Without these overrides, you may encounter bugs such as duplicate entries in a Set, 
incorrect lookups in a Map, or inefficient performance due to poor object comparison.






15) Object cloning in java, why it is needed ?
Ans:
    Object cloning in Java is the process of creating an exact copy of an object, usually with the same values and attributes, 
    but in a different memory location. Java provides the clone() method, which is a part of the Object class.
When you need to duplicate objects but retain their independent state.
In situations where object immutability is required for safety, but cloning allows temporary modifications 
without altering the original object.

Shallow vs. Deep Cloning
    Shallow cloning: Only the references to objects are copied, so changes to the nested objects 
    in the clone will affect the original object.
    Deep cloning: Involves recursive cloning of nested objects, ensuring that the clone is fully independent 
    of the original object.

Cloneable Interface
    Implementing the Cloneable interface is not enough for deep cloning. You often need to manually override clone() to 
    handle deep cloning if required.

Exceptions:
    Cloning can lead to CloneNotSupportedException if the class does not implement Cloneable. 
    The clone() method must also handle exceptions appropriately.

Object Cloning and Performance
    Cloning is a relatively expensive operation. In some cases, creating a new object manually might be more efficient 
    than cloning, especially for complex objects with deep structures.







16) Java Collection Framework - List, Set, Map, ArrayList, HashMap, Hashtable, HashSet, 
LinkedList and different operations on collection.

Ans:
Java Collection Framework:
The Java Collection Framework (JCF) is a set of classes and interfaces in Java that provide a standard way to store, 
manipulate, and retrieve data efficiently. 
It includes various List, Set, Queue, and Map implementations.

    The Java Collection Framework provides a set of interfaces and classes to handle groups of objects. 
    It is part of the java.util package and includes 
    three main types  interfaces, with concrete classes to handle groups of objects: List, Set, and Map.

List, Set, and Map are interfaces.
ArrayList, LinkedList, HashSet, HashMap, and Hashtable are classes that implement these interfaces.

        1. List
        What: Ordered, allows duplicates.
        Example-class: 
        ArrayList ‚Üí Fast random access, but slow insert/delete in the middle.
        LinkedList ‚Üí Fast insert/delete, but slow random access.
        Vector ‚Üí Synchronized version of ArrayList.
        Stack ‚Üí Last-In-First-Out (LIFO) structure.

        List<String> list = new ArrayList<>();
        list.add("A");
        list.add("B");
No default sorting order.
Elements maintain insertion order.

        2. Set
        What: Unordered, no duplicates.
        Example: 
            HashSet ‚Üí Uses hashing, fast lookup (O(1) time on average).
            LinkedHashSet ‚Üí Maintains insertion order.
            TreeSet ‚Üí Maintains sorted order (uses Red-Black Tree).
        Set<String> set = new HashSet<>();
        set.add("A");
        set.add("B");
No default sorting order.
Elements are unordered.
Use a TreeSet instead if you need sorted elements (natural order or custom Comparator).

        3. Map
        What: Key-value pairs, unique keys.
        Example: 
        HashMap ‚Üí Unordered, fast lookup (O(1) time complexity).
        LinkedHashMap ‚Üí Maintains insertion order.
        TreeMap ‚Üí Maintains sorted order (uses Red-Black Tree).

        Map<String, Integer> map = new HashMap<>();
        map.put("A", 1);
        map.put("B", 2);

No default sorting order.
Keys are unordered.
For sorting, use TreeMap (sorted by keys in natural order or custom Comparator) or LinkedHashMap (preserves insertion order).



Collection vs. Collections:
Collection	Interface that represents a group of objects (List, Set, Queue).
Collections	Utility class that provides helper methods like sort(), reverse(), etc.
Example using Collections.sort():



ArrayList ‚Üí Fast Random Access, But Slow Insert/Delete in the Middle
How It Works
ArrayList is backed by a dynamic array (internally, an array of objects).
Random access is fast (O(1)) because elements are stored in contiguous memory locations, allowing direct access via index (list.get(i)).
Insertion/Deletion is slow (O(n)) when modifying elements in the middle because it requires shifting elements.

LinkedList ‚Üí Fast Insert/Delete, But Slow Random Access
How It Works
LinkedList is a doubly linked list, where each node contains:
A data element.
A pointer to the next node.
A pointer to the previous node (for quick backward traversal).



Does ArrayList Reduce Its Internal Size Automatically?
No, the ArrayList does not shrink automatically when elements are removed.
Internally, ArrayList maintains an underlying array that remains the same size until explicitly resized.
Yes, this is memory inefficient because:
 How to Reduce Memory Usage?
You can manually trim the capacity of the ArrayList using trimToSize():



17) How does the size of ArrayList grow dynamically? And also state how it is implemented internally.
Internal Implementation of ArrayList
    Backing Array:
        Internally, an ArrayList uses an array to store its elements.
        The array is initialized with a default size (10 elements) when the ArrayList is created.

    Growth Mechanism:
        When an element is added and the current capacity is full, a new array is created with twice the size of the original array.
        This means if the initial size is 10, it will grow to 20, 40, 80, etc.
        Array Resize Process:
            Step 1: Create a new array with double the size.
            Step 2: Copy all elements from the old array to the new array.
            Step 3: Update the reference to point to the new array.

    Efficiency Considerations:
        This dynamic resizing ensures that the ArrayList can grow without worrying about its size upfront.
        Although resizing can be an expensive operation (since it involves copying elements), 
        it happens infrequently because the growth is exponential (doubling each time).

When remove element of array call trimToSize  cos:
clling trimToSize() ensures that the internal array's capacity matches the list's actual size, minimizing memory usage.



18) How HashMap works internally and how to minimize hash collision?
Ans:HashMap stores key-value pairs using an array of buckets (or "bins") and handles collisions 
(multiple keys mapping to the same bucket) using linked lists and, in Java 8 and later, potentially red-black trees. 

Summary of How HashMap Works:
    Uses an array of buckets to store key-value pairs.
    Keys are hashed to determine the bucket index.
    Handles collisions with a linked list or red-black tree.
    Operations like put(), get(), and remove() rely on efficient bucket indexing and hashing.

Ways to Minimize Collisions:
    Use a good hashCode() implementation.
    Ensure proper equals() method implementation.
    Adjust the load factor and initial capacity to reduce frequent resizing.



19)Sorting Java Collections, Comparing Java Custom Object, Comparable and Comperator
ans:
Sorting a List
    Using Collections.sort():
    Sorts a list based on the natural ordering of its elements or a custom comparator.
    The list must implement the Comparable interface, or you can use a custom Comparator.
Using List.sort():
    Available from Java 8, this method is equivalent to Collections.sort() but is called directly on the list.
Sorting a Set
    TreeSet: Automatically sorts elements upon insertion using the natural ordering or a comparator.

Comparing Java Custom Objects:
    To sort custom objects, you need to define how two objects are compared. 
    You can achieve this through Comparable or Comparator interfaces.


Java is used to sort elements in a list. It relies on either:
The natural ordering of the elements (if the elements implement the Comparable interface).
A custom ordering provided by a Comparator.


Comparable & Comparator Interfaces in Java
------------------------------------------------
Comparable<T> (Natural Ordering)
    Used for default sorting order.
    Defines sorting logic inside the class using compareTo().
    A class implementing Comparable can have only one sorting logic.


Comparator<T> (Custom Ordering)
Used for multiple sorting options.
Sorting logic is defined outside the class using compare().
A class can have multiple comparators for different sorting rules.


a) Comparable Interface:
    What: Used when you want the class to have a natural order.
    How: Implement the compareTo(T o) method in your class, which compares the current object (this) with the 
    provided object (o).
    Purpose: Define the default sorting behavior of the object.

    class Person implements Comparable<Person> {
        String name;
        int age;
        
        public Person(String name, int age) {
            this.name = name;
            this.age = age;
        }
        
        @Override
        public int compareTo(Person other) {
            return this.age - other.age;  // Sort by age in ascending order
        }
    }

    List<Person> people = new ArrayList<>();
    people.add(new Person("Alice", 30));
    people.add(new Person("Bob", 25));
    Collections.sort(people);  // Sorts by age (natural order)

The compareTo() method returns:
    Negative if this is less than other.
    Zero if they are equal.
    Positive if this is greater than other.

b) Comparator Interface
    What: Used when you want to define multiple sorting orders or external comparison logic.
    How: Implement the compare(T o1, T o2) method in the comparator.
    Purpose: Allows sorting based on different fields or criteria without modifying the object itself.
    class Person {
        String name;
        int age;
        
        public Person(String name, int age) {
            this.name = name;
            this.age = age;
        }
    }

    class NameComparator implements Comparator<Person> {
        @Override
        public int compare(Person p1, Person p2) {
            return p1.name.compareTo(p2.name);  // Sort by name alphabetically
        }
    }

    List<Person> people = new ArrayList<>();
    people.add(new Person("Alice", 30));
    people.add(new Person("Bob", 25));
    people.sort(new NameComparator());  // Sorts by name

Custom sorting using Comparator:
Comparator can also be used with Collections.sort() or List.sort().


String class in Java overrides the hashCode method from the Object class.
This is why String objects work efficiently as keys in hash-based collections like HashMap or HashSet, 
ensuring proper hash-based behavior.



Sorting a List of Numbers:
    When sorting a list of numbers, the natural ordering is used (ascending order). 
    Java's wrapper classes for numbers (like Integer, Double, etc.) implement the Comparable interface

Sorting a List of Strings:
    Strings are sorted based on their lexicographical (dictionary) order because the String class implements Comparable<String>.
    Mechanism: The String.compareTo method compares characters in the string by their Unicode values.

Sorting a List of Custom Objects:
    For custom objects, the sorting behavior depends on:

    Whether the object implements Comparable.
    Whether you provide a Comparator.





20) Lamda Expression, Stream API, Functional Interface, Functional Programming
Lambda Expression:
    Introduced in Java 8, allows writing anonymous functions (compact code for functional-style programming).
    Syntax: (parameters) -> {expression/body}.
    Simplifies code, especially for functional interfaces.
    Example:
        List<Integer> numbers = Arrays.asList(1, 2, 3, 4);
        numbers.forEach(n -> System.out.println(n));  // Print each number

Stream API:
    Introduced in Java 8, processes collections in a functional style.
    Provides operations like filter(), map(), reduce(), sorted().
    Supports lazy evaluation and promotes clean, declarative code.
    Example:
        List<Integer> numbers = Arrays.asList(1, 2, 3, 4);
        List<Integer> evens = numbers.stream().filter(n -> n % 2 == 0).collect(Collectors.toList());

Functional Interface:
    An interface with one abstract method (e.g., Runnable, Callable).
    Annotated with @FunctionalInterface for clarity.
    Enables use of lambda expressions.
    Example:
    @FunctionalInterface
    interface Calculator {
        int calculate(int x, int y);
    }
    Calculator add = (a, b) -> a + b;  // Lambda implementing the interface


Many Stream API methods (like filter, map, forEach) require functional interfaces as arguments. 
Examples include Predicate, Function, Consumer, etc.
    import java.util.Arrays;
    import java.util.List;

    public class StreamFunctionalInterface {
        public static void main(String[] args) {
            List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5);

            // Using Predicate (functional interface)
            numbers.stream()
                .filter(n -> n % 2 == 0) // Predicate: n -> n % 2 == 0
                .forEach(System.out::println); // Consumer: System.out::println
            // Output: 2, 4
        }
    }



Built-in Functional Interfaces:
    Java provides several built-in functional interfaces that are commonly used:

    Runnable: Represents a task with no return value.
    Callable: Represents a task with a return value.
    Comparator: Used to compare objects.
    Predicate, Function, Consumer, etc., for Stream API operations.


Functional Programming:
    With functinal programming we cna do old style code more compact and easy to read less coded.
    Helper implementation for Stream api and Lambda Expressions.
    Instead of writing a lot of loops and if statements, you use functions (like filter, map, reduce) to process data.
    It avoids changing variables or objects (this is called immutability).
    Functions are treated like "values," so you can pass them around, store them in variables, or return them.

Exmaple:Old Way (Using Loops) vs Functional way

    public class OldWayExample {
        public static void main(String[] args) {
            List<Integer> numbers = List.of(1, 2, 3, 4, 5, 6);
            List<Integer> evenNumbers = new ArrayList<>();

            for (int n : numbers) {
                if (n % 2 == 0) {
                    evenNumbers.add(n);
                }
            }

            System.out.println("Even Numbers: " + evenNumbers);
        }
    }

vS:

Functional Way (Using Streams)

    public class FunctionalWayExample {
        public static void main(String[] args) {
            List<Integer> numbers = List.of(1, 2, 3, 4, 5, 6);

            List<Integer> evenNumbers = numbers.stream()
                                            .filter(n -> n % 2 == 0) // Keep even numbers
                                            .collect(Collectors.toList());

            System.out.println("Even Numbers: " + evenNumbers);
        }
    }


What is Functional Programming in Java?
    Functional Programming is a programming paradigm where functions are treated as first-class citizens, meaning they 
    can be assigned to variables, passed as arguments, or returned from other functions. 
    It emphasizes immutability and avoids changing states and mutable data.

    In Java, functional programming became prominent with Java 8, introducing features like lambdas, 
    streams, and the java.util.function package.

Why use Functional programming:
    Functional Programming helps you write cleaner and more readable code.
    It is useful for data processing and scenarios where you process large amounts of data.
    Streams and Lambda expressions are the most common tools in Java for functional programming.
    The focus is on describing what to do (like filtering and mapping) rather than how to do it (like writing loops).


Where to Use Functional Programming?
    Data Processing: When working with collections (e.g., filtering, mapping, reducing).
    Event-driven Applications: Handling events in a clean and declarative way.
    Asynchronous Programming: Functional programming complements reactive programming paradigms.
    Parallel Processing: Operations on data that can be run in parallel with streams.
    Streams API: Provides a functional way to process collections.
    Operations: filter, map, reduce, sorted, distinct, etc.
    Immutability: Avoid modifying existing objects.


‚úÖ Lambda Expressions ‚Üí Shorter, cleaner code for functional interfaces.
‚úÖ Functional Interfaces ‚Üí Allow passing behavior as arguments.
‚úÖ Stream API provides efficient collection processing using functional interfaces like Predicate, Function, Consumer

‚úÖ Lambda expressions work only with Functional Interfaces because they require a single abstract method (SAM) to implement.
‚úÖ If an interface has multiple abstract methods, Java won‚Äôt allow using a Lambda Expression.
A Functional Interface is an interface that has exactly one abstract method but can have multiple default or static methods.

example:
    public class Main {
        public static void main(String[] args) {
            List<String> names = Arrays.asList("Alice", "Bob", "Charlie", "David");

            // Functional Interface: Predicate (Used in filter)
            Predicate<String> startsWithA = name -> name.startsWith("A");

            names.stream()
                .filter(startsWithA) // Uses Predicate Functional Interface
                .forEach(System.out::println); // Uses Consumer Functional Interface
        }
    }


21) Stream API - terminal operations, non terminal operations, Pure Function, Higher Order Funciton, 
Function Composition, different built-in functional interface, different types of aggregation, build your own collector.
Ans:
Stream API
    Non-Terminal Operations (Intermediate):
        Return a Stream for further processing.
        Lazy evaluated (executed only when a terminal operation is applied).
        Examples: filter(), map(), flatMap(), sorted(), distinct().

    Terminal Operations:
        Trigger stream execution, producing a result (e.g., value, collection, side-effect).
        Examples: collect(), reduce(), forEach(), count(), findFirst().

Pure Function:
    A function where the output depends only on its input and has no side effects (e.g., doesn't modify external state).
    Ensures immutability and referential transparency.
    Example: n -> n * 2 is pure since it depends solely on n.

Higher-Order Function
    A function that either:
    Takes another function as input (e.g., map() accepts a lambda).
    Returns a function as output.
    Example:
    Function<Integer, Function<Integer, Integer>> add = x -> y -> x + y;

Function Composition:
    Combines multiple functions into a single function.
    In Java, achieved using methods like andThen() and compose() in Function.
    Example:
    Function<Integer, Integer> doubleIt = x -> x * 2;
    Function<Integer, Integer> addTen = x -> x + 10;
    Function<Integer, Integer> composed = doubleIt.andThen(addTen);  // (x * 2) + 10

Built-in Functional Interfaces:
    Predicate: boolean test(T t) for conditions (filter() uses it).
    Example: Predicate<Integer> isEven = n -> n % 2 == 0;.
    Function: R apply(T t) for transformations (map() uses it).
    Consumer: void accept(T t) for side effects (forEach() uses it).
    Supplier: T get() for supplying values.
    BiFunction, UnaryOperator, BinaryOperator, etc., for specific use cases.

Aggregation in Streams:
    Summing: sum(), Collectors.summingInt().
    Averaging: Collectors.averagingInt().
    Counting: count().
    Reducing: reduce().
    Example:
    int sum = numbers.stream().reduce(0, Integer::sum);  // Sum all nu


Closure:
    Closure: Inline, lightweight, and can capture variables from its surrounding context.
    Function: Defined explicitly and doesn‚Äôt inherently capture its surrounding variables

Java supports closures through lambdas and anonymous classes but requires captured variables to be effectively final 
for safety and consistency.

Example:
    Closure:
    let simpleClosure = {
        print("Hello, Closure")
    }
    simpleClosure() // Call the closure

    Equivalent Function:
    func simpleFunction() {
        print("Hello, Function")
    }
    simpleFunction() // Call the function

Difference Between Function and Closure:
- Functions are declared using the func keyword, while closures don't require it.
- Functions always have a name, whereas closures don't necessarily need one.
- Functions don't use the in keyword, while closures use it to separate the return type and statements inside.


Java supports closure-like behavior using Lambda Expressions and Anonymous Classes, 
but it does not fully support closures like JavaScript or Python. and has some Limitations.





22) Create custom functional interface and use it with Stream API
Ans:
    Creating a Custom Functional Interface:
        Define a functional interface with a single abstract method.
        Annotate it with @FunctionalInterface for clarity.

Custom Functional Interface Simplified Example
Here‚Äôs a streamlined example of a custom functional interface and its use in the Stream API:

@FunctionalInterface
interface Transformer<T, R> {
    R transform(T input);  // Single abstract method
}

public class CustomInterfaceExample {
    public static void main(String[] args) {
        // List of numbers
        List<Integer> numbers = List.of(1, 2, 3, 4, 5);

        // Custom interface implementation using lambda
        Transformer<Integer, String> toStringTransformer = n -> "Number: " + n;

        // Use Stream API with the custom interface
        List<String> transformedList = numbers.stream()
                                              .map(toStringTransformer::transform) // Use custom method
                                              .toList();

        // Print the result
        transformedList.forEach(System.out::println);
    }
}

Explanation:
    Define the Custom Interface:
        Transformer<T, R> transforms an input of type T into a result of type R.
    Lambda Implementation:
        toStringTransformer converts an integer into a formatted string.
    Stream API Integration:
        map(toStringTransformer::transform) applies the custom transformation on each element.
Output
    Copy code
    Number: 1
    Number: 2
    Number: 3
    Number: 4
    Number: 5
    This example is simple yet demonstrates the power of custom functional interfaces with Stream API.

Exmple2:
@FunctionalInterface
interface StringProcessor {
    String process(String input);
}


import java.util.Arrays;
import java.util.List;
import java.util.stream.Collectors;

public class CustomFunctionalInterfaceExample {
    public static void main(String[] args) {

        // Define a list of strings
        List<String> names = Arrays.asList("john", "alice", "bob");

        // Custom Functional Interface Implementation using Lambda
        StringProcessor toUpperCaseProcessor = input -> input.toUpperCase();

        // Using the custom functional interface with Stream API
        List<String> processedNames = names.stream()
                                           .map(toUpperCaseProcessor::process) // Apply the custom interface
                                           .collect(Collectors.toList());

        // Print the processed list
        System.out.println(processedNames); // Output: [JOHN, ALICE, BOB]
    }
}





JVM GC-Comparison Across jdk Versions:
--------------------------------------------
Java 8
Default: Parallel GC.
STW/Impact: Significant, especially for large heaps.
Optional: G1 GC for improved pause times, but requires tuning.
Java 17
Default: G1 GC.
STW/Impact: Lower than Parallel GC; predictable with proper configuration.
Optional: ZGC and Shenandoah for ultra-low-latency.(Z Garbage Collector (ZGC) )
Java 23
Default: Likely G1 GC, with further improvements to ZGC and Shenandoah.
STW/Impact: Minimal with ZGC or Shenandoah; configurable with G1.


How to Check or Change the GC:
=>java -XX:+PrintCommandLineFlags -version
Check Default GC: Use -XX:+PrintCommandLineFlags to see the default GC:

Change GC: Specify the GC explicitly:
    G1 GC: -XX:+UseG1GC
    Parallel GC: -XX:+UseParallelGC
    ZGC: -XX:+UseZGC
    Shenandoah: -XX:+UseShenandoahGC

Why ZGC is Not the Default GC:
    Target Use Cases:
        ZGC is designed for low-latency applications, where pause times need to be extremely short (e.g., <10ms).
        It is not optimized for throughput or general-purpose workloads, which are common in most applications.
        G1 GC, the default, strikes a balance between pause time and throughput, making it more versatile.
    Heap Size Considerations:
        ZGC is optimized for large heaps (from a few GB to TBs in size).
        For small heap sizes, its benefits are less pronounced, and simpler GCs like G1 GC or Parallel GC may perform be

Enabling ZGC:
    java -XX:+UnlockExperimentalVMOptions -XX:+UseZGC -Xms4G -Xmx4G -jar myapp.jar

When to Use ZGC:
    Your application requires consistent low-latency (e.g., trading systems, real-time analytics).
    You work with large heap sizes (e.g., TB-level heaps).
    Predictable response times are more important than maximizing throughput.



What is we use G1 GC  or ZGC(Throughput vs. Latency):
    Imagine two applications:
    Application 1 (High Throughput GC like Parallel GC):
        Handles 1,000 user requests per second.
        GC Behavior:
        GC runs in fewer, longer pauses (e.g., 100ms each), allowing the application to process batches of objects in bulk.
        Total time spent in GC is 5% of the application's runtime.
        Impact:
        High overall throughput (e.g., processes 1,000,000 requests in 10 minutes).
        Long pauses (100ms) are tolerable for batch jobs or non-interactive systems.
    Application 2 (Low Latency GC like ZGC):
        Handles real-time user interactions, e.g., an online gaming server.
        GC Behavior:
        GC runs concurrently with the application, performing small incremental work to avoid long pauses.
        Pause times are under 10ms.
        Total time spent in GC is higher (e.g., 15% of runtime), as the GC is always running in the background.
        Impact:
        Predictable response times for user actions (no noticeable freezes or delays).
        Lower overall throughput compared to Application 1 (e.g., processes 950,000 requests in 10 minutes).





23) Java JDBC, JDBC Batching, PreparedStatement, Connection Pooling
Ans:
Java JDBC:
    Java Database Connectivity (JDBC) is an API for interacting with relational databases.
    Provides methods to execute SQL queries and manage database connections.
    Key Components
        DriverManager: Manages database drivers and connections.
        Connection: Represents a session with the database.
        Statement: Used to execute SQL queries (Statement, PreparedStatement, CallableStatement).
        ResultSet: Holds data retrieved from the database.

PreparedStatement:
    A precompiled SQL statement used to prevent SQL injection and improve performance.
    Placeholders (?) are used for parameters.
    Example:
        PreparedStatement pstmt = connection.prepareStatement("INSERT INTO users (name, age) VALUES (?, ?)");
        pstmt.setString(1, "John");
        pstmt.setInt(2, 25);
        pstmt.executeUpdate();

JDBC Batching:
    Batch processing sends multiple queries in a single database call, reducing round-trips and improving performance.
    Supported by Statement and PreparedStatement.
    Example:
        PreparedStatement pstmt = connection.prepareStatement("INSERT INTO users (name, age) VALUES (?, ?)");
        pstmt.setString(1, "Alice");
        pstmt.setInt(2, 30);
        pstmt.addBatch();

        pstmt.setString(1, "Bob");
        pstmt.setInt(2, 25);
        pstmt.addBatch();

        pstmt.executeBatch()

Connection Pooling: Optimizes connection management for high-performance applications.



24) Understanding JVM internals.
    The Java Virtual Machine (JVM) is an engine that executes Java bytecode, providing platform independence and memory management. 
    in Java, every time you run a Java application using commands like:java -jar app1.jar
    each command creates a new JVM instance.Each java -jar command starts its own separate JVM process.


Key Components:
    I) Class Loader Subsystem:
            Loads .class files into memory.
            Divided into: Bootstrap, Extension, and Application class loaders.

    II) Runtime Data Areas:
            Method Area: Stores class metadata, static variables, and method code.
            Heap: Stores objects and JRE classes. Managed by the Garbage Collector.
            Stack: Stores local variables and method calls (stack frames).
            Program Counter (PC) Register: Tracks the address of the next bytecode instruction.
            Native Method Stack: Handles native method calls.

    III) Execution Engine:
            Interpreter: Reads and executes bytecode line by line.
            Just-In-Time (JIT) Compiler: Converts bytecode to native machine code for faster execution.

    IV) Garbage Collector (GC):
            Automatically manages memory by removing unused objects from the heap.
            GC algorithms: Serial, Parallel, CMS, G1, ZGC.

    V) Java Native Interface (JNI):
            Enables Java to interact with native code (e.g., C, C++).




25) Java Memory Model(JMM), Java Flight Recorder,JIT Compiler
Ans:
    JMM: Defines rules for thread-safe memory access.
    The Java Memory Model (JMM) defines how threads interact through memory, 
    ensuring predictable behavior in concurrent programming.
        Key Concepts:
            Main Memory: Shared memory accessed by all threads.
            Working Memory: Thread-local copies of variables stored in CPU caches.
            Happens-Before Relationship: Guarantees visibility and ordering of operations (e.g., locks, volatile, synchronized).

JIT Compiler: Dynamically compiles bytecode to machine code for performance.
    The JIT Compiler is part of the JVM Execution Engine, enhancing runtime performance by translating 
    bytecode into native machine code.
    Types of Compilation:
    C1 (Client): Optimizes startup and UI responsiveness.
    C2 (Server): Focuses on long-running applications for deeper optimization.

JFR: Helps analyze runtime issues with low overhead.
    JFR is a low-overhead performance monitoring and diagnostic tool integrated into the JVM.
    Features:
    Captures detailed runtime data (e.g., method execution, thread states, GC activity).
    Minimal impact on application performance.





26) JVM Monitoring Tools - VisualVM, JConsole, How to modify different JVM Flags
Ans:
VisualVM
    What: A powerful, all-in-one monitoring and troubleshooting tool for JVM-based applications.
    Features:
    Monitor heap usage, GC activity, and thread states.
    Profile CPU and memory usage.
    Analyze thread dumps and heap dumps.

JConsole
    What: A lightweight GUI tool for monitoring and managing Java applications via JMX (Java Management Extensions).
    Features:
    Monitor heap, threads, and classes loaded.
    Track custom JMX metrics.

Modifying JVM Flags:
JVM flags control runtime behavior such as memory allocation, GC, and debugging.
    Types of JVM Flags:
        Standard Options (e.g., -cp, -version): General commands like setting the classpath.
        Non-Standard Options (start with -X) e.g., -Xmx, -Xms.
        Advanced Options (start with -XX) e.g., -XX:+UseG1GC, -XX:MaxHeapFreeRatio
Example:java -Xmx1024m -XX:+UseG1GC -jar MyApp.jar


With JVM Flag (e.g., Debug/Verbose Logging Enabled) do some Performance Impact like: 
    Increased I/O Operations and Garbage Collection Pressure.

When to Use JVM Flags?
Use JVM flags like -Xlog, -verbose:gc, or debugging flags during development or troubleshooting.
Avoid enabling these in production unless absolutely necessary, as they can significantly degrade performance.

JVM CLI Tools to monitor JVM in realtime - jstack, jinfo, jmap, jhat, jstat, jps


27) Concurrency vs Parallelism
    Concurrency: Handling many tasks at once (may be interleaved).
                Managing multiple tasks by quickly switching between them (e.g., multi-threading).
    Parallelism: Performing many tasks at the same time (simultaneous execution).
                A multi-core CPU running separate tasks simultaneously on different cores.



28) Java Multi Threading, Creating threads in different ways.
        Thread Class: Simple but less flexible, suitable for single-threaded tasks.
        Runnable Interface: Preferred when you need to extend another class or want to share the same task among multiple threads.
        Lambda Expressions: Makes code more concise.
        ExecutorService: Best for managing multiple threads efficiently with a thread pool.

Runnable vs Thread, Thread Lifecycle, Thread Signaling, Thread Join, Volatile keyword, Thread Local, Java Virtual Thread
    Thread Lifecycle:
        New: Thread created but not started.
        Runnable: Ready to run, waiting for CPU.
        Running: Actively executing.
        Blocked/Waiting: Paused, waiting for resources/signals.
        Terminated: Execution completed.

Virtual Threads are lightweight, user-mode threads introduced in Java 19 (preview) and finalized in Java 21 as part of Project Loom.
Java Virtual Threads (Project Loom):
    Traditional Threads:
        Java's standard Thread is mapped to an operating system thread.
        These are heavyweight and limited because the OS manages them.
        Handling thousands of threads (e.g., for concurrent users) is inefficient.

    Virtual Threads:
        Introduced in Project Loom, virtual threads are lightweight threads managed by the JVM, not the OS.
        They enable you to create millions of threads with minimal overhead.
        Each virtual thread runs tasks like a normal thread but consumes far fewer resources.

Non-blocking I/O: Virtual threads make waiting (like for a database query) efficient, as the thread can pause and 
resume without tying up system resources.
Virtual Threads make it cheap and easy to scale Java applications by allowing you to handle many tasks simultaneously 
without complex workarounds!

Example:
    Before Loom:
        // Traditional thread
        Thread thread = new Thread(() -> {
            System.out.println("Hello from thread!");
        });
        thread.start();

    With Loom:
        // Virtual thread
        Thread thread = Thread.ofVirtual().start(() -> {
            System.out.println("Hello from virtual thread!");
        })


Microservice:Scalability: Handle More Concurrent Requests
    Traditional Threads:
        Each request typically corresponds to a thread.
        Limited by the operating system‚Äôs thread capacity (thousands at best).
        High memory and context-switching overhead.
    With Virtual Threads:
        Lightweight threads allow creating millions of threads.
        Each API call or microservice operation can have its own thread without worrying about resource limits.
        Handles high-concurrency scenarios like thousands of simultaneous API users with ease.

Example (Before Loom):
    CompletableFuture.runAsync(() -> {
        // Non-blocking call
        fetchDataFromDatabase();
    });

With Loom:
    Thread.startVirtualThread(() -> {
        // Synchronous but efficient
        fetchDataFromDatabase();
    });


Microservices often perform I/O-heavy tasks(Improved Performance for Blocking Operations):
    Querying databases
    Calling other APIs
    Writing logs
Blocking I/O in traditional threads ties up OS resources.
Virtual threads can block without significant resource costs because the JVM parks and resumes them efficiently.
Enable massive scalability.
Reduce costs and resource usage. This makes them a game-changer for modern microservice architectures!
Enable massive scalability.
Reduce costs and resource usage. This makes them a game-changer for modern microservice architectures!


Optimal Resource Utilization:
    Traditional threads consume ~1MB of memory per thread.
    Virtual threads use only a few kilobytes.
    This means:
    Reduced hardware requirements.
    Cost savings on cloud infrastructure (e.g., fewer containers, smaller VMs).


The API handles concurrent requests with minimal memory and performance overhead, even under heavy load:
    @RestController
    public class MyController {

        @GetMapping("/data")
        public String fetchData() {
            Thread.ofVirtual().start(() -> {
                callAnotherService();
                queryDatabase();
            });
            return "Request handled with Virtual Threads!";
        }

        private void callAnotherService() {
            // Simulated API call
        }

        private void queryDatabase() {
            // Simulated DB query
        }
    }


Feign Clietn with Vertual Thread:
    Feign uses an underlying Executor to handle its HTTP requests. By default, it uses threads from the thread pool, 
    but you can replace this with virtual threads. uses an underlying Executor to handle its HTTP requests. 
    By default, it uses threads from the thread pool, but you can replace this with virtual threads.
 
Configure Feign Client Executor
    You need to set up an Executor for Feign that uses virtual threads.
    Integrate Virtual Threads in Feign Builder
    Provide the custom executor to the Feign client configuration.

Define the Feign client as usual:
    @FeignClient(name = "remoteService", url = "http://example.com")
    public interface RemoteServiceClient {
        @GetMapping("/data")
        String getData();
    }
Custom Feign Configuration with Virtual Threads:
    @Configuration
    public class FeignVirtualThreadConfig {

        @Bean
        public Feign.Builder feignBuilder() {
            // Create an executor that uses virtual threads
            Executor executor = Thread.ofVirtual().factory().newThreadExecutor();
            
            // Use the executor in Feign's async execution
            return Feign.builder()
                        .executor(executor)
                        .options(new Request.Options(5000, 10000)); // Set timeouts
        }
    }




29) Race Condition, Deadlock, Deadlock Prevention.
Ans:
Race Condition:
    Definition: Occurs when multiple threads access shared resources simultaneously, and the outcome depends on the execution order.
    Example: Two threads incrementing the same variable without proper synchronization may lead to incorrect results.
    Solution: Use synchronization mechanisms (e.g., synchronized, Locks) to prevent concurrent access.

Deadlock:
    Definition: Happens when two or more threads are waiting for each other‚Äôs resources, resulting in an infinite wait state.
    Example:
    Thread A holds Resource 1 and waits for Resource 2.
    Thread B holds Resource 2 and waits for Resource 1.

Deadlock Prevention:
    Resource Ordering:
    Acquire resources in a consistent order across threads.

    Avoid Nested Locks:
    Minimize situations where locks are acquired within other locks.

    Try-Lock Mechanism:
    Use methods like tryLock() with a timeout to avoid indefinite blocking.

    Release Locks Properly:
    Always release locks in finally blocks to ensure they are freed, even during exceptions.

    Avoid Circular Wait:
    Ensure no thread holds one resource while waiting for another held by another thread.



30) Locks in Java, Thread Safety, Critical Section, Synchronization
Ans:
Locks in Java
    Definition: Explicit control mechanisms for thread synchronization.
    Types:
    ReentrantLock: A flexible, explicit lock allowing reentrant access.
    ReadWriteLock: Optimizes read operations by allowing multiple readers but single writer.
    StampedLock: Supports optimistic locking for better performance in read-heavy scenarios.

Thread Safety:
    Definition: Ensures consistent behavior of shared resources across threads.
    How to Achieve:
    Synchronization (e.g., synchronized block/method).
    Locks for finer-grained control.
    Atomic classes (e.g., AtomicInteger).

Critical Section:
    Definition: A part of the code that accesses shared resources.
    Risk: Concurrent modification by threads without proper synchronization may lead to race conditions.
    Solution: Protect critical sections using synchronized or locks.

Synchronization:
    Definition: Mechanism to control thread access to shared resources.
    Types:
    Synchronized Method: Locks the whole method on the object or class.
    Synchronized Block: Locks a specific section of code or resource.
    Example:
        synchronized (lock) {
            // critical section
        }
    Drawback: Can lead to performance overhead if overused.



31) Reentrant Locks, Mutex, Semaphore, and Monitor

Reentrant Locks:
    Definition: A lock allowing the same thread to acquire it multiple times without causing a deadlock.
    Key Features:
    Explicit locking/unlocking (lock()/unlock()).
    Provides advanced features like tryLock() with timeout and interruptible locks.
Example:
    ReentrantLock lock = new ReentrantLock();
    lock.lock();
    try {
        // critical section
    } finally {
        lock.unlock();
    }

Mutex:
    Definition: A synchronization primitive ensuring only one thread accesses a resource at a time.
    Java Implementation: Achieved using synchronized or ReentrantLock.

Semaphore:
    Definition: A counter-based synchronization tool controlling access to a limited number of permits.
    Use Case: Limit simultaneous access to resources like a connection pool.
    Types:
    Binary Semaphore (acts like a mutex).
    Counting Semaphore (allows multiple permits).
    Example:
        Semaphore semaphore = new Semaphore(3); // 3 permits
        semaphore.acquire();
        try {
            // critical section
        } finally {
            semaphore.release();
        }

Monitor:
    Definition: A concurrency construct that combines mutual exclusion and thread signaling.
    Java Implementation:
    Implicit monitors via synchronized.
    Provides wait/notify mechanisms.
Example:
    synchronized (lock) {
        lock.wait();  // Wait for signal
        lock.notify();  // Notify waiting threads
    }




32) Executor Framework, Thread Pool, and Blocking Queues
Ans:
Executor Framework
    Purpose: Manages thread execution, replacing manual thread creation.
    Key Interfaces:
        Executor: Basic task execution.
        ExecutorService: Advanced features like thread pools and task scheduling.
        ScheduledExecutorService: Executes tasks periodically or after a delay.
Thread Pool
    Definition: A pool of reusable threads to handle tasks efficiently.
    Advantages:
    Reduces overhead of thread creation.
    Manages a fixed number of threads to optimize resource usage.
    Types:
    Fixed thread pool (Executors.newFixedThreadPool()): Fixed number of threads.
    Cached thread pool (Executors.newCachedThreadPool()): Dynamically growing thread pool.
    Single thread executor (Executors.newSingleThreadExecutor()): Executes tasks sequentially.
Blocking Queues
    Definition: Thread-safe queues used for inter-thread communication.
    Purpose: Blocks threads during enqueue or dequeue when the queue is full or empty.
    Common Implementations:
    ArrayBlockingQueue: Fixed size, FIFO order.
    LinkedBlockingQueue: Dynamically growing size.
    PriorityBlockingQueue: Orders elements based on priority.


Advantages of Thread Pool
    Efficiency: Reuses threads, avoiding the cost of thread creation and destruction.
    Better Resource Management: Controls the number of concurrent threads.
    Prevention of Overhead: Limits excessive thread creation that can cause CPU thrashing.
    Simplified API: Managed via the ExecutorService.

Common Types of Thread Pools:
    Fixed Thread Pool
        Fixed number of threads for consistent task execution.
        ExecutorService fixedPool = Executors.newFixedThreadPool(3);

    Cached Thread Pool
        Dynamically adjusts threads for short-lived tasks.
        ExecutorService cachedPool = Executors.newCachedThreadPool();

    Single Thread Pool
        Ensures tasks execute sequentially in a single thread.
        ExecutorService singlePool = Executors.newSingleThreadExecutor();

    Scheduled Thread Pool
        Executes tasks after a delay or periodically.
        ScheduledExecutorService scheduledPool = Executors.newScheduledThreadPool(2);



33) Fork/Join Framework, How Java parallel stream use this fromework ?
Ans:
Fork/Join Framework
Purpose: Breaks a large task into smaller subtasks (fork), processes them in parallel, and combines the results (join).

Key Classes:
    ForkJoinPool: Manages worker threads.
    RecursiveTask: For tasks that return results.
    RecursiveAction: For tasks that don't return results.
    Example Use: Divide-and-conquer algorithms like mergesort or recursive sum.
    How Java Parallel Stream Uses Fork/Join Framework
    Implementation: Parallel streams internally use a common ForkJoinPool to execute stream operations in parallel.

Process:
    Splits the data source into chunks.
    Executes tasks in parallel across available threads in the ForkJoinPool.
    Merges the results at the end.
    Advantages: Simplifies parallel processing with minimal code.

Example:
List<Integer> numbers = List.of(1, 2, 3, 4, 5);
int sum = numbers.parallelStream().reduce(0, Integer::sum); // Uses Fork/Join internally



34) Thread safe collections, copy on write collections, and how it works
Ans:
Thread-Safe Collections
    Definition: Collections designed for safe concurrent access by multiple threads.
    Examples:
    Vector: Synchronized alternative to ArrayList.
    Hashtable: Synchronized alternative to HashMap.
    Concurrent Collections:
        ConcurrentHashMap: Efficient thread-safe HashMap alternative using fine-grained locks.
        CopyOnWriteArrayList: Thread-safe alternative to ArrayList for read-heavy operations.

List myList = new ArrayList();
    ArrayList is not thread-safe by default.

Copy-On-Write Collections
    Definition: Collections that create a new copy of the data structure on modification (e.g., add/remove).
    Examples:
        CopyOnWriteArrayList
        CopyOnWriteArraySet

    How It Works:
        Read Operations: Directly access the immutable snapshot of the collection.
        Write Operations: Create a new copy, modify it, and replace the old reference.
        Ideal for scenarios where reads greatly outnumber writes.


35) IO Bound vs CPU Bound applicaiton
Ans:
I/O-Bound Application
    Definition: Performance is limited by input/output operations (e.g., reading/writing files, network calls).
    Key Focus: Optimize waiting time (use asynchronous/non-blocking I/O).
    Examples: Web servers, database queries.
    When you make an HTTP request in Java, for example using libraries like HttpURLConnection, HttpClient, or 
    frameworks like Spring Web The JVM will perform network I/O.
CPU-Bound Application
    Definition: Performance is limited by CPU computations (e.g., mathematical calculations, data processing).
    Key Focus: Optimize processing efficiency (use multi-core processors, parallel algorithms).


What is Asynchronous Programming?
    Asynchronous programming in Java allows a program to perform tasks without blocking the execution of other tasks. 
    It helps in improving performance, especially when dealing with time-consuming operations like I/O-bound tasks 
    (e.g., file access, API calls, database queries).

    In synchronous programming, tasks are executed sequentially, and each task must wait for the previous one to complete. 
    In contrast, asynchronous programming lets multiple tasks run independently, reducing the time required to complete operations.

Ways to Achieve Asynchronous Programming in Java:
Threads
    Execute tasks in a new thread.
    new Thread(() -> System.out.println("Task in thread")).start();
ExecutorService
    Use a thread pool for better thread management.
        import java.util.concurrent.ExecutorService;
        import java.util.concurrent.Executors;

        public class AsyncWithExecutor {
            public static void main(String[] args) {
                ExecutorService executor = Executors.newSingleThreadExecutor();
                executor.submit(() -> {
                    System.out.println("Task running asynchronously using ExecutorService");
                });
                executor.shutdown();
                System.out.println("Main thread continues...");
            }
        }
CompletableFuture (Preferred)
    Handle async tasks with functional programming.
    CompletableFuture.runAsync(() -> System.out.println("Task in CompletableFuture"));
Reactive Programming
    Use frameworks like Project Reactor or RxJava.For advanced asynchronous programming, especially when dealing with streams of data.
    Mono.just("Reactive Task").subscribe(System.out::println);
Spring‚Äôs @Async
    Enable @Async for declarative async execution in Spring.
    @Async
    public void asyncTask() { 
        System.out.println("Task with @Async");
         }



Asynchronous with Database, Queue, or Kafka:
    Database
        Store tasks in a table; background jobs poll and process them.
        Simple but can have latency due to polling.

    Message Queues (e.g., RabbitMQ)
        Producers send tasks to a queue; consumers process them independently.
        Reliable and scalable for moderate use cases.

    Kafka
        Producers publish events to topics; consumers process asynchronously.
        Best for high-throughput, distributed systems.





36) Java Happens Before Guarantee, Thread Starvation and Fairness Java CompletableFuture
Ans:
    Happens-Before Guarantee:	Ensures visibility and ordering between threads.
    Thread Starvation:	When threads are denied CPU time due to higher priority tasks, causing delays.
    Fairness:	Ensures equal resource allocation to all threads, preventing starvation.
    CompletableFuture:	Allows non-blocking asynchronous execution and chaining of tasks.



37) Understanding different types of GC - Serial, Parallel, Mark and Sweep, G1, Epsilon. What is stop the word in java
Ans
Types of Garbage Collection (GC) in Java
Serial GC:
Uses a single thread for garbage collection.
Best for single-threaded applications.
Stop-the-world: The application is paused during GC.

Parallel GC:
Uses multiple threads for garbage collection.
Suitable for multi-threaded environments.
Stop-the-world: Application pauses during GC, but multiple threads are used to reduce pause time.

Mark and Sweep GC:
Mark Phase: Identifies live objects.
Sweep Phase: Removes unused objects.
Can lead to fragmentation if not followed by compaction.

G1 (Garbage-First) GC:
Designed for large heaps and low-latency applications.
Divides the heap into regions and prioritizes GC work to minimize pause times.
Stop-the-world: Occurs but is optimized for shorter durations.

Epsilon GC:
A no-op garbage collector that does not reclaim memory.
Primarily used for benchmarking or applications where GC is handled manually.

Stop-the-World
    Definition: A phase during garbage collection where all application threads are paused to allow the garbage collector 
    to perform its task.
    Cause: During GC operations like marking, sweeping, or compacting, the JVM halts all application threads temporarily.
    Impact: Can cause latency spikes, especially in high-performance or real-time applications.



38) Java Generics, Type Erasure, Generic Method and Class, Wildcard Type, Upper Bounded Wildcard,
 Lower Bounded Wildcard, Bounded Type.

Java Generics
    Definition: Allows you to define classes, interfaces, and methods with type parameters, 
    enabling type safety while maintaining flexibility.
    Benefits:
        Provides compile-time type checking.
        Eliminates the need for casting when retrieving elements from collections.

Type Erasure
    Definition: The process by which the generic type information is removed at runtime. 
    After type erasure, the generic type is replaced with its raw type, and type parameters are replaced with bounds (if any).
        List<Integer> list = new ArrayList<>();
        // After type erasure: 
        List becomes List<Object> at runtime

Generic Method and Class:
Generic Method:
    A method that can operate on any type.
    Syntax: <T> returnType methodName(T parameter) { ... }
    Example:
    public <T> void printArray(T[] array) {
        for (T element : array) {
            System.out.println(element);
        }
    }

Generic Class:
    A class with a type parameter.
    Syntax: class ClassName<T> { ... }
    Example:
        class Box<T> {
            private T value;
            public T getValue() {
                return value;
            }
            public void setValue(T value) {
                this.value = value;
            }
        }

Wildcard Type:
    Definition: A placeholder for an unknown type, used in method arguments to increase flexibility.
    Syntax: <?> (Unknown type)
    Example:
    public void printList(List<?> list) { ... }


Bounded Type:
Definition: Specifies the upper or lower bound of a generic type to restrict the types that can be used.

Upper Bounded Wildcard:
    Definition: Restricts the wildcard to types that are subtypes of a specific class or interface.
    Syntax: <? extends T>
    Example:
    public void printNumbers(List<? extends Number> list) { ... }

Lower Bounded Wildcard:
    Definition: Restricts the wildcard to types that are supertypes of a specific class.
    Syntax: <? super T>
    Example:
    public void addIntegers(List<? super Integer> list) { ... }





39) Java Exception and Error Handling
Ans:
    Exceptions represent conditions that can be handled programmatically.
    Errors represent serious issues that generally cannot be handled.
    Use try-catch-finally blocks to handle exceptions and clean up resources.
    Use throw to throw an exception and throws to declare potential exceptions in a method.
    Handle exceptions gracefully and avoid over-catching them.


40) Java Metadata programming - Annotation Processing, and Java Reflection API 
Annotations are used to add metadata to classes, methods, or fields in your code.
Annotation Processors are tools that can read annotations and generate additional code or resources during the compilation process.

Types of Annotations:
    Built-in Annotations: Examples include @Override, @Deprecated, @SuppressWarnings.
    
    Custom Annotations: You can define your own annotations to add metadata specific to your project.
        @interface MyCustomAnnotation {
            String value() default "defaultValue";
        }

Annotation Processing:
You can create a custom annotation processor that extends AbstractProcessor and override the process() method.
How to run: Annotation processors are invoked automatically during compilation by the Java compiler

Java Reflection API
    Definition: The Java Reflection API allows you to inspect and manipulate classes, methods, fields, and other 
    elements of the Java program at runtime, even if they are private or not directly accessible.
    Core Concepts:
        Class: Represents the class or interface at runtime.
        Method: Represents methods of the class.
        Field: Represents fields (variables) of the class.
        Constructor: Represents constructors of the class.

Reflection Operations:
Field Manipulation: Access and modify field values dynamically.
Method Invocation: Call methods of a class without knowing them at compile-time.
Annotations: Retrieve and process annotations at runtime.

Annotation Processing:
    Allows you to process annotations at compile-time to generate code or perform validations.
    It is commonly used for generating boilerplate code, dependency injection, and validation.
Reflection API:
    Provides runtime capabilities to inspect and manipulate classes, methods, fields, and other class members.
    Commonly used in frameworks, dynamic proxies, and testing.
    Can have performance overhead and should be used carefully, especially in production environments.





41) Java Logging 
Java provides a logging API to help developers log messages for monitoring, debugging, and troubleshooting applications. 
The Java Logging API is part of the java.util.logging package

Logging with External Libraries:
    While Java's built-in logging is suitable for many applications, many developers prefer more feature-rich 
    logging libraries, such as:
        Log4j: Apache's logging framework, which offers additional features like advanced configuration, log levels, and appenders.
        SLF4J: Simple Logging Facade for Java, which provides a common interface to different logging 
        libraries (e.g., Log4j, java.util.logging).


42) Java Cryptography:
        Java provides a robust set of cryptographic tools through its Java Cryptography Architecture (JCA) and 
        Java Cryptography Extension (JCE) to implement encryption, decryption, secure communication, and data integrity checks. 
        By using cryptographic classes like Cipher, MessageDigest, Signature, and KeyPairGenerator, 
        you can secure sensitive information effectively. Proper use of key management, secure random number generation, 
        and algorithm selection is essential for building secure Java applications.



43) Java Performance - JMH 
    JMH is the go-to tool for accurate and reliable microbenchmarking in Java. It is designed to eliminate JVM optimizations 
    and background factors that could otherwise skew performance results. By using JMH, developers can benchmark and 
    optimize specific parts of their code with confidence.


44) Java Internationalization (i18n)

    Java Internationalization (i18n)
    Java Internationalization refers to designing applications that can adapt to various languages, regions, 
    cultural conventions.

    Key Concepts:
    Locale: Represents a specific geographical, cultural, or political region. It includes language, country, and variant.
    Locale locale = new Locale("en", "US");

    Why i18n?
    Expands software usability across different regions.
    Reduces costs by avoiding redesigns for multiple markets.


45) Java IO vs NIO
Java IO (Input/Output):
    Stream-based: Reads/writes data as bytes (InputStream/OutputStream) or characters (Reader/Writer).
    Blocking: IO operations block the thread until completion.
    Simpler API: Easy to use but less efficient for high-performance tasks.

Java NIO (New IO):
    Buffer-based: Data is read into buffers for non-blocking operations.
    Non-blocking: Threads can continue executing while IO operations are performed in the background.
    Selectors: Enables monitoring of multiple channels (e.g., sockets).
    Scalable: Suitable for high-performance applications like servers.

Use IO for simple, single-threaded applications.
Use NIO for high-performance, multi-threaded applications.





==================================================
##Framework & Web	| sec2
==================================================

Spring Boot is geared towards a microservices environment. 
It‚Äôs a ‚Äúconvention over configuration‚Äù environment that‚Äôs designed for creating stand-alone, production-grade applications.  


1) What is spring bean ?
Ans:
A Spring Bean is an object managed by the Spring IoC container, created, configured, and wired as part of the application's runtime.
Managed by the Spring container, with lifecycle and dependency injection handled automatically.

What is spring IoC ? What is it responsible for ?
Spring IoC (Inversion of Control) is a design principle where the Spring container manages object creation, configuration, 
and dependency injection.
Responsibilities:
    Creating and managing beans.
    Injecting dependencies automatically.
    Managing bean lifecycle.

What are the bean scopes available in spring
Spring bean scopes:
    Singleton (default): One instance per Spring container.
    Prototype: A new instance for each request.
    Request: One instance per HTTP request (web apps).
    Session: One instance per HTTP session (web apps).
    Application: One instance per ServletContext (web apps).
    WebSocket: One instance per WebSocket session.


Dependency Injection in Spring? How many ways one can inject objects ?
Ans:
Dependency Injection in Spring allows the container to provide required objects to a class.
Ways to inject objects:
    Constructor Injection: Passing dependencies via the constructor.
    Setter Injection: Using setter methods to set dependencies.
    Field Injection: Directly injecting into fields using @Autowired (not recommended for testing).


Default Injection Way: Spring does not enforce a default; 
constructor injection is recommended for required dependencies.

@Autowired
private SimpleService simpleService; (This is field injection)

What is use when?
Field Injection:
Issue: Harder to test because dependencies can't be set manually without reflection.
Use Case: Simple cases or legacy code (not recommended).

Setter Injection:
Issue: Allows changing dependencies after object creation, which can lead to inconsistent state.
Use Case: Optional dependencies.

Constructor Injection (Preferred):
Issue: Slightly more verbose, but no major downsides.
Use Case: Required dependencies. Ensures immutability and easy testing.




2) Differnet ways of creating spring bean?

XML Configuration:
Define beans in an XML configuration file.
<bean id="myBean" class="com.example.MyBean"/>

Annotation-Based Configuration:
Use @Component and related annotations (@Service, @Repository, @Controller) to mark classes as beans.
@Component
public class MyBean {
}

Java-based Configuration:
Use @Configuration, and @Bean annotations in a configuration class.
@Configuration
public class AppConfig {
    @Bean
    public MyBean myBean() {
        return new MyBean();
    }
}

Component Scanning:
Enable component scanning to automatically detect beans in the package.
@Configuration
@ComponentScan(basePackages = "com.example")
public class AppConfig {
}

Factory Method:
Use a static factory method to create a bean.
@Bean
public MyBean myBean() {
    return MyBean.createInstance();
}


3) Circular Dependency - How to solve this ?
Ans:
Circular Dependency occurs when two or more beans depend on each other, causing an infinite loop of dependencies. 
This can happen in Spring if Bean A depends on Bean B, and Bean B depends on Bean A.
Solutions:
    Setter Injection:
    Use setter injection to break the circular dependency.
        @Component
        public class BeanA {
            private BeanB beanB;

            @Autowired
            public void setBeanB(BeanB beanB) {
                this.beanB = beanB;
            }

            public void doSomething() {
                System.out.println("BeanA is doing something with BeanB.");
            }
        }

    Use @Lazy Annotation:
    Use @Lazy to delay the initialization of one of the beans, allowing Spring to break the circular dependency.
        @Component
        public class BeanA {
            private final BeanB beanB;

            @Autowired
            public BeanA(@Lazy BeanB beanB) {
                this.beanB = beanB;
            }

            public void doSomething() {
                System.out.println("BeanA is doing something with BeanB.");
            }
        }

4) Different stereotypes in spring and purpose of the stereotypes
Stereotypes in Spring refer to annotations that are used to define different types of beans with specific roles in the application. 
These annotations help Spring automatically detect and manage beans based on their responsibilities, 
making the code more readable and maintainable.
Key Stereotype Annotations:
    @Component: Marks a generic bean, usually for utility or general-purpose components.
    @Service: A specialized @Component for service layer beans, typically holding business logic.
    @Repository: A specialized @Component for DAO (Data Access Object) classes, often used for database interaction.
                 also makes the class eligible for exception translation, meaning Spring will 
    automatically convert database-related exceptions (like SQLException) into Spring's DataAccessException.
    @Controller: A specialized @Component for Spring MVC controllers that handle HTTP requests.
    @RestController: A combination of @Controller and @ResponseBody, used for REST APIs where the response is 
    typically in JSON or XML format.


5) Injecting Prototype Beans into a Singleton Instance in Spring
Injecting a prototype bean into a singleton bean in Spring can be tricky due to the way Spring manages bean lifecycles. 
A singleton bean is created once and shared across the application, while a prototype bean is created each time it is requested.

Problem:
If you inject a prototype bean directly into a singleton, the singleton bean will hold a reference to a single instance 
of the prototype bean, which violates the intended lifecycle (the prototype bean should be created fresh each time).

Solutions:
    Using @Lookup Annotation:

    Using ApplicationContext:
    You can explicitly request a new instance of the prototype bean from the ApplicationContext inside the singleton.

    Using ObjectFactory or Provider:



6) DI Exceptions - UnsatisfiedDependencyException, Circular Dependency Exception, NoSuchBeanDefinitionException
        UnsatisfiedDependencyException:
            Cause: This exception occurs when Spring cannot satisfy a bean's dependency during injection. 
            It typically happens if the required bean is not found or not correctly configured.

        CircularDependencyException:
            Cause: This happens when two or more beans depend on each other, leading to a circular reference.

        NoSuchBeanDefinitionException:
            Cause: This exception occurs when Spring cannot find a bean definition for a requested type or name.


7) Injecting Collections, Generic Objects
    Spring can inject lists, sets, maps, and arrays into beans using @Autowired.
    You can inject generic beans using @Qualifier if you have multiple beans of the same generic type.
    You can also inject a collection of generic objects into a single bean.

Inject the Collection:
    private final List<Object> services;
    @Autowired
    public ServiceManager(List<Object> services) {
        this.services = services;
    }

Define a Generic Class:
    @Component
    public class GenericService<T> {
        private T value;

        public void setValue(T value) {
            this.value = value;
        }

        public T getValue() {
            return value;
        }
    }
Generaic Metod:
    public class GenericMethodExample {

        // Generic method to display a single value
        public static <T> void display(T value) {
            System.out.println("Value: " + value);
        }

        public static void main(String[] args) {
            // Using the generic method with different types
            display(42);           // Integer
            display("Hello");      // String
            display(3.14);         // Double
            display(true);         // Boolean
        }
    }





8) Use of @Primary, @Qualifier, @Order, @Lazy, and @Lookup
    @Primary: Use it when you want one bean to be the default choice when there are multiple beans of the same type.
    @Qualifier: Use it to specify exactly which bean to inject when there are multiple candidates of the same type.
    @Order: Use it to define the order in which beans are processed or injected.
    @Lazy: Use it to delay the initialization of a bean until it is actually needed.
    @Lookup: Use it to inject a new instance of a prototype bean into a singleton bean.

// @Primary: Marks a bean as the default when multiple candidates exist for autowiring.
    @Component
    @Primary
    public class ServiceA implements MyService {
        public String serve() {
            return "ServiceA is serving!";
        }
    }

    @Component
    public class ServiceB implements MyService {
        public String serve() {
            return "ServiceB is serving!";
        }
    }

    @Component
    public class Client {
        @Autowired
        private MyService myService;

        public void process() {
            System.out.println(myService.serve()); // Output: ServiceA is serving!
        }
    }



// @Qualifier: Specifies which bean to inject when multiple candidates exist.
Overriding @Primary with @Qualifier:
    @Component
    @Primary
    public class ServiceA implements MyService {
        public String serve() {
            return "ServiceA is serving!";
        }
    }

    @Component
    public class ServiceB implements MyService {
        public String serve() {
            return "ServiceB is serving!";
        }
    }

    @Component
    public class Client {
        @Autowired
        @Qualifier("serviceB") // Explicitly specify ServiceB
        private MyService myService;

        public void process() {
            System.out.println(myService.serve()); // Output: ServiceB is serving!
        }
    }





// @Order: Sets the priority order of beans when they are injected into a collection or executed.
    @Component
    @Order(1)
    public class FirstTask implements Task { }

    @Component
    @Order(2)
    public class SecondTask implements Task { }

    // @Lazy: Delays bean initialization until it‚Äôs needed.
    @Component
    @Lazy
    public class LazyService { }
    // @Lookup: Injects a new instance of a prototype-scoped bean into a singleton bean.
    @Component
    public class SingletonService {
        @Lookup
        public PrototypeService getPrototypeService() {
            return null; // Spring overrides this method
        }
    }

 @Component vs @Configuration
    Key Behavior of @Component:
        If you call the @Bean method directly on the AppConfig(anoted with @Component) class (like appConfig.userService()), 
        you bypass Spring‚Äôs context, and a new instance is created.

    Key Behavior of @Configuration with Proxying:
        Even if you access the @Bean method using the @Configuration class reference, the proxy ensures singleton behavior.



9) Spring Cloud, Service Discovery, and Gateway
        Spring Cloud provides a comprehensive set of tools for building and managing microservices.
        Service Discovery enables automatic service registration and discovery via tools like Eureka, 
        so services don‚Äôt need static configurations.
        Spring Cloud Gateway acts as a reverse proxy or API Gateway, providing routing, load balancing, 
        and filtering, and integrates seamlessly with service discovery to route traffic to available services.



10) What is Servlet ? Life cycle of Servlet. What is Dispetcher Servlets, Servlet Filters and Listener ?
    Servlet: A Java class that processes HTTP requests and responses. 
    It has a lifecycle consisting of init(), service(), and destroy() methods.

    DispatcherServlet: In Spring, it acts as the front controller, 
    handling incoming requests and routing them to appropriate controllers.

    ServletFilters: Used to process requests and responses (e.g., logging, authentication) before or after they reach a servlet.
    Servlet Listeners: Listen for specific events in the servlet container, such as context or session creation/destruction, 
    to perform necessary actions.

HttpRequest processing-flow:
---------------------------------------------
    Request Reception:
    A user sends an HTTP request to the web server (e.g., GET /home).

    Routing to DispatcherServlet:
    The web server (like Tomcat) receives the request and forwards it to the DispatcherServlet, 
    which is mapped to a specific URL pattern in the web.xml or Java configuration.

    Handler Mapping:
    DispatcherServlet consults the HandlerMapping to find the appropriate controller method based on the request URL. 
    For example, it may map /home to the HomeController.





11) Spring Security: What is security filter chain ?
The Security Filter Chain in Spring Security is a set of filters that are applied to incoming HTTP 
requests to perform security-related tasks such as authentication, authorization, and logging. 

Default Filters:
    Some common filters included in the default Spring Security filter chain are:
    UsernamePasswordAuthenticationFilter: Handles login requests with a username and password.
    BasicAuthenticationFilter: Processes HTTP Basic authentication.
    CSRFFilter: Protects against Cross-Site Request Forgery (CSRF) attacks.
    ExceptionTranslationFilter: Handles security exceptions and redirects or returns appropriate responses.
    SecurityContextPersistenceFilter: Handles storing and retrieving security context information (e.g., the current authenticated user).
    FilterSecurityInterceptor: The last filter in the chain, responsible for checking if the authenticated user has the necessary permissions to access a resource.


12) Spring Security: Session Based Authentication, Token Based Authentication
    Both Session-Based Authentication and Token-Based Authentication are common methods for securing web applications, 
    but they differ in how user authentication and session management are handled.

Session Based Authentication,
--------------------------------
Session-Based Authentication is simple and stateful, where the server keeps track of the user's session, 
making it suitable for traditional web applications.

Disadvantages:
Scalability: Storing session data on the server can become a bottleneck, especially in distributed environments. 
You may need session replication or sticky sessions in load-balanced environments.
Stateful: The server needs to maintain state, which can be resource-intensive, especially for a large number of users.

Token-Based Authentication
--------------------------------
Token-Based Authentication is stateless, making it ideal for distributed systems, APIs, and microservices, 
offering greater scalability and flexibility, especially in environments like SPAs and mobile apps.
Token interception (must use HTTPS)



Spring Security: Role-Permission Management
Basic Concepts:
    Roles: A role is a high-level concept representing a user's responsibility or job. 
    Typically, roles are associated with permissions, allowing users to access resources.
        Example: ROLE_USER, ROLE_ADMIN.
    Permissions: A permission represents the actual rights a user has to access certain resources or perform specific actions.
        Example: READ_PRIVILEGE, WRITE_PRIVILEGE.

    You can use annotations like @PreAuthorize or @Secured to protect methods based on roles or permissions.
    @PreAuthorize is more flexible and allows you to use SpEL (Spring Expression Language) for more complex authorization rules.
    @Secured is simpler and restricts method access to users with the specified role.

Roles are broad categories that group permissions.
Permissions are granular rights that control access to specific resources.
Spring Security provides different ways to manage both roles and permissions, 
including annotations (@Secured, @PreAuthorize), HTTP security configuration, and database-driven authorization.
    RBAC focuses on user roles, while 
    PBAC (Permission-Based Access Control) offers fine-grained access control.



13) Spring @Transactional with Different types of Transaction Propagation
    In Spring, the @Transactional annotation is used to manage transactions in a declarative way. 
    It ensures that methods are executed within a transaction context, and the transaction can be rolled 
    back or committed based on certain conditions.

How @Transactional Works in Spring:
    The @Transactional annotation in Spring is used to manage transactions declaratively. 
    It ensures that a series of operations within a method or class are executed as a single unit of work. 
    If any operation fails, the transaction is rolled back, and the database is returned to its previous consistent state.

Key Concepts:
    Transaction Boundary:
        @Transactional defines the scope of a transaction. By default, Spring opens a transaction at the beginning of 
        the method and commits it at the end.

    Commit:
        If the method completes successfully without exceptions, the transaction is committed
        meaning changes are saved to the database.

    Rollback:
        If the method throws a RuntimeException (or any checked exception specified in the @Transactional settings), 
        the transaction is rolled back, meaning all changes made during the transaction are undone.

Example of @Transactional:
    @Transactional
    public void processOrder(Order order) {
        orderRepository.save(order);  // Persist order data
        inventoryService.updateInventory(order);  // Update inventory
        paymentService.processPayment(order);  // Process payment
    }
If any part of the above method fails (e.g., paymentService.processPayment throws an exception), 
the changes in orderRepository.save and inventoryService.updateInventory will be rolled back.


By default, Spring only rolls back for unchecked exceptions (RuntimeException and its subclasses). 
You can customize it to rollback on specific checked exceptions too.

Specify which exceptions should trigger a rollback.
    @Transactional(rollbackFor = Exception.class)
    public void someMethod() { ... }

Rollback Mechanism:
    If a RuntimeException (or any exception specified) occurs, Spring marks the transaction for rollback.
    Spring then instructs the underlying database to undo any changes (rollback the transaction) by issuing a 
    rollback command to the database.





Transaction Propagation Types:
Spring provides different propagation types that define how transactions are handled when multiple transactions are involved. 
The propagation attribute of the @Transactional annotation specifies how the current transaction should behave with 
respect to an existing transaction.


When to Use:
    REQUIRED(Default Propagation): Use when you want multiple methods to share the same transaction 
    (e.g., if one method fails, you want all changes to roll back).
    REQUIRES_NEW: Use when you want a method to always run in its own transaction, regardless of any existing transaction. 
        This is useful when you need a method to complete independently (e.g., logging or audit operations).



1. REQUIRED (Default Propagation)
Behavior: If there is an existing transaction, the method will join the existing transaction. 
If there is no transaction, a new one will be created.
Use Case: This is the default behavior and is used for most transactional methods.

Example:
    @Transactional(propagation = Propagation.REQUIRED)
    public void someMethod() {
        // Method logic
    }

2. REQUIRES_NEW
Behavior: A new transaction is always created, and if there is an existing transaction, it is suspended until 
the new transaction completes.
Use Case: Used when you want to ensure that the method runs in its own independent transaction, 
regardless of the existing transaction.

Example:
    @Transactional(propagation = Propagation.REQUIRES_NEW)
    public void someMethod() {
        // Method logic in a new transaction
    }

3. SUPPORTS
Behavior: If there is an existing transaction, the method will join it. If there is no transaction, 
the method will execute without a transaction.
Use Case: Used for operations that are not critical but should participate in a transaction if one exists.

4. MANDATORY
Behavior: If there is an existing transaction, the method will join it. 
If there is no existing transaction, an exception (TransactionRequiredException) is thrown.
Use Case: Used when the method must always run inside an existing transaction.


5)NEVER, NOT_SUPPORTEDER,NESTED



14) Structuring Spring Project

my-spring-project/
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ java/com/example/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/      (config classes)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ controller/  (REST controllers)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service/     (business logic)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ repository/  (data access)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model/       (entities, DTOs)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ MySpringApplication.java (main class)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ resources/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ application.properties
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ static/      (static resources)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ templates/   (Thymeleaf templates)
‚îÇ
‚îú‚îÄ‚îÄ pom.xml (or build.gradle)
‚îî‚îÄ‚îÄ src/test/ (unit tests)



15) How to enable actuator endpoints
1. Add Spring Boot Actuator Dependency
Add the spring-boot-starter-actuator dependency to your pom.xml (for Maven) or build.gradle (for Gradle).

2. Configure Actuator Endpoints in application.properties or application.yml
By default, some actuator endpoints are enabled, but you can customize which ones are enabled or 
exposed using the configuration file.
By adding the spring-boot-starter-actuator dependency and configuring the application.properties or application.yml, 
you can enable and customize the actuator endpoints in your Spring Boot application.


16) Use of @ConfigurationProperties, Usages of Environment Variables in Spring Boot‚Äôs Properties Files
1. @ConfigurationProperties in Spring Boot
@ConfigurationProperties is a Spring annotation used to bind external configuration 
properties (e.g., from application.properties or application.yml) to a Java bean. 
This approach provides a strongly-typed way to handle configuration properties instead of using @Value for individual properties.


17) Spring Boot Environment Variable Resolution
Precedence Order: The order of precedence is:
    Command-line arguments (highest priority)
    Environment variables
    Java system properties
    application.properties / application.yml (lowest priority)



18) AOP - Point Cut, Advice, Joint Point
    Pointcut: Specifies where (which methods) the advice will be applied.
    Advice: Defines the action to take at the join points (e.g., log, validate, modify behavior).
    Join Point: A specific point in program execution (usually a method execution) where advice can be applied.

1. Join Point
    A Join Point represents a point in the execution of a program where an aspect can be applied.
    It can be:
    Method execution
    Constructor call
    Exception handling
    Field access, etc.
    Example: When a method is executed, it is a join point.

    Spring AOP Limitation: Only method execution join points are supported.



Exmple:
    public class MyService {
        public void methodA() {
            System.out.println("Inside methodA");
        }
    }


// Aspect definition for logging
    @Aspect
    @Component
    public class LoggingAspect {

        // Define a pointcut that matches only the method methodA() in MyService
        @Pointcut("execution(void com.example.MyService.methodA())")
        public void methodAPointcut() {}

        // Define an advice: Log before executing methodA()
        @Before("methodAPointcut()")
        public void logBeforeMethodA(JoinPoint joinPoint) {
            System.out.println("Executing methodA()");
        }
    }



Explanation:
    Pointcut (methodAPointcut): The pointcut expression execution(void com.example.MyService.methodA())
         matches only the execution of methodA() in the MyService class.
        void means the return type of methodA() (you can change it to match other return types if necessary).
        com.example.MyService.methodA() specifies the exact method to match.
    Advice (logBeforeMethodA): This advice is executed before methodA() is called and logs "Executing methodA()".
    Join Point: The execution of methodA() in MyService.




19) Unit Testion - JUnit Jupiter
JUnit Jupiter is the new programming model and extension model for JUnit 5, which provides a modern and flexible 
way to write and run tests.
Key Features:
Annotations:
    @Test: Marks a method as a test case.
    @BeforeEach: Runs before each test method.
    @AfterEach: Runs after each test method.
    @BeforeAll: Runs once before all tests in the class.
    @AfterAll: Runs once after all tests in the class.
    @ParameterizedTest: Used for running the same test with different inputs.

Assertions:
assertEquals(), assertTrue(), assertFalse(), assertNull(), etc.
Assertions Library:

Includes fluent assertions like assertThat(), assertThrows() for exception testing.
Test Lifecycle:

Supports test lifecycle hooks for initialization and cleanup using @BeforeEach, @AfterEach, etc.
JUnit Jupiter is the foundation of JUnit 5 and is designed to be more extensible and flexible compared to older versions.



20) JSP, Thymeleaf, Javascript, Ajax
        JSP: Java-based view technology for dynamic web pages (outdated compared to newer technologies).
        Thymeleaf: A more modern templating engine, often used with Spring Boot.
        JavaScript: Client-side scripting language for interactive functionality.
        AJAX: Technique for making asynchronous requests to update page content without a full reload.



Spring vs. Spring Boot
A comprehensive framework for Java EE development. 
It provides a lot of powerful features like dependency injection (DI), AOP, and transaction management, 
but it requires manual configuration for things like setting up a web server, database connections, and security.

Spring Boot, on the other hand,  a specialized extension of Spring that simplifies Spring application development.
It comes with auto-configuration, embedded servers (like Tomcat), and a lot of defaults configuration 
what is let you start coding right away without worrying about a lot of setup.
Eliminates boilerplate code and XML configuration, enabling faster development.

Key Differences:
If you're building a microservice or a REST API, applications needing rapid development and deployment then 
Spring Boot is usually the better choice because it reduces  boilerplate code and speeds up development.

For large enterprise applications that need fine-tuned configurations, you might still prefer plain Spring.

My Experience
In my experience, Spring Boot has been a game changer for developing microservices and REST APIs. 
The auto-configuration, embedded servers, and starter dependencies save a lot of time. 
But if you need custom configurations, especially in large monolithic applications, plain Spring can still be a good option.









##protocol |  Web Server | http https etc
===========================================
1) Web Server	Understanding Web Server: Apache Tomcat, Nginx
A web server handles HTTP requests and serves static content or forwards dynamic requests to application servers.

Apache Tomcat: Serves Java-based applications (Servlets, JSPs).
Nginx: High-performance server for static files, load balancing, and reverse proxy.


How They Work Together
    A web server can serve as the entry point. If a request requires dynamic processing, the web server 
    forwards it to an application server.
    The application server processes the request, often leveraging a servlet container to handle servlet or JSP execution.
    The servlet container is part of the application server or web server (e.g., Tomcat is both).

Examples in Real-world Setups
    Web Server + Servlet Container:
        Apache HTTP Server + Apache Tomcat.

    Nginx + Jetty.
        Web Server + Application Server:

    Apache HTTP Server + JBoss/WildFly.
        Nginx + GlassFish.


Request Flow in a Java Web Application:
Web Server ‚Üí Servlet Container ‚Üí Application Server (for Dynamic Content):

The web server (e.g., Apache HTTP Server or Nginx) receives the HTTP request from the client (e.g., browser).
If the request requires Java-based dynamic processing (like invoking a servlet or JSP), the web server 
forwards it to the servlet container (e.g., Tomcat, Jetty).
The servlet container processes the request (via servlets or JSPs). If additional business logic or 
enterprise features (like transactions or EJBs) are needed, it may forward the request to an 
application server (e.g., WildFly, WebSphere).




All-in-one:
    Apache Tomcat (acts as both servlet container and lightweight application server).
    Client ‚Üí Servlet Container (Tomcat acting as Web Server + Application Server)

With Web Server, Servlet Container, and Application Server:
    Client ‚Üí Web Server (Nginx) ‚Üí Servlet Container (Tomcat) ‚Üí Application Server (WildFly)



Tomcat as a Servlet Container:
    Handles the lifecycle of servlets (e.g., initialization, request handling, destruction).
    Processes HTTP requests and maps them to servlet methods (e.g., doGet, doPost).
    Provides support for Java Servlet API and JSP specifications.


Tomcat as a Lightweight Application Server:
    Although Tomcat is primarily a servlet container, it can act as an application server by providing some 
    basic application-level features:

    Java EE Component Support (Partial):
        Supports key components like:
        Servlets
        JSPs
        WebSocket APIs
        Does not support full Java EE features like EJBs, JCA (Java Connector Architecture), or JPA out of the box.


Summary:
    Tomcat handles HTTP and forwards requests to the Spring DispatcherServlet.
    Spring processes the request using its MVC architecture (Controller ‚Üí Service ‚Üí Repository).
    Tomcat sends the processed response back to the client.
    By combining Tomcat and Spring, you're effectively using Tomcat as a servlet container while 
    relying on Spring to act as the "application server" for advanced logic and application features.



Complete request: Flow in Diagram

Client (Browser/Postman)  
       ‚îÇ  
       ‚ñº  
[Optional] Web Server (Nginx/Apache)  
       ‚îÇ  
       ‚ñº  
Embedded Servlet Container (Tomcat)  
       ‚îÇ  
       ‚ñº  
Spring DispatcherServlet  
       ‚îÇ  
       ‚ñº  
Handler Mapping ‚Üí Resolved Controller  
       ‚îÇ  
       ‚ñº  
Controller ‚Üí Calls Service (Business Logic)  
       ‚îÇ  
       ‚ñº  
[Optional] Service Calls Repository (Database)  
       ‚îÇ  
       ‚ñº  
Database (H2, MySQL, PostgreSQL)  
       ‚îÇ  
       ‚ñº  
Response sent back through the same path  


Spring Boot has an embedded servlet container (Tomcat, Jetty, or Undertow) that acts as both a web server and a lightweight application server.
It directly processes HTTP requests and serves responses.

You only need a full application server (e.g., JBoss, WebLogic) if:
    You are using Java EE features like EJB, JMS, JTA, and EAR packaging.
    Your organization enforces deploying WAR files inside an existing Java EE server.
For Spring Boot applications, this is unnecessary because:
    Spring Boot does not rely on full Java EE stacks.


What Happens When You Build a WAR File and Deploy It in an External Tomcat Server?
The request flow (Tomcat ‚Üí DispatcherServlet ‚Üí Controller ‚Üí Response) is the same in both setups.
‚úî The only difference is whether Tomcat is embedded in the JAR (self-contained) or running externally (shared server for multiple apps).
the request flow remains the same in both embedded Tomcat (Spring Boot JAR) and external Tomcat (WAR deployment), 
but with some minor differences in where the request is processed.


How Does External Tomcat Manage Multiple Applications on the Same Port?
    When using an external Tomcat, all applications run on the same port (e.g., 8080), 
    but Tomcat distinguishes between them using context paths.
    Each deployed WAR file is assigned a unique context path, allowing multiple applications to coexist on a single port.

Context Path Mechanism in Extranal Tomcat:
    Each application in Tomcat has a context path based on its WAR file name.
    If you deploy:
        app1.war ‚Üí Access at http://host-ip:8080/app1/
        app2.war ‚Üí Access at http://host-ip:8080/app2/
    Tomcat routes requests to the correct application based on the context path.

So, Where is Servlet Used?
    Servlets still exist and work in Spring Boot.
        ‚úî DispatcherServlet is a special Servlet that acts as the front controller in Spring.
        ‚úî Tomcat processes requests using the Servlet API before Spring takes over.

Relationship Between Servlet and DispatcherServlet in Spring Boot:
üîπ Servlet API in Tomcat
    Tomcat is a Servlet container, meaning it can execute Java Servlets.
    When a request comes in, Tomcat creates an instance of a Servlet and calls its service() method.
üîπ DispatcherServlet in Spring Boot
    DispatcherServlet is a specialized Servlet provided by Spring.
    It acts as the front controller in the Spring MVC framework.
    It extends HttpServlet and is registered as a Servlet in Tomcat
    DispatcherServlet Takes Over
        DispatcherServlet is a Servlet itself (extends HttpServlet).
        It processes the request using the Spring MVC flow.
        DispatcherServlet itself is a Servlet (it extends HttpServlet).
        It runs inside Tomcat like any other Servlet.

DispatcherServlet does not replace raw Servlets (HttpServlet) but wraps and extends their functionality.
In a Spring Boot application running inside Tomcat, DispatcherServlet acts as the main entry point for handling HTTP requests, 
but it still runs on top of Tomcat‚Äôs standard Servlet mechanism.
Tomcat still relies on Servlets to handle requests, but Spring hides that complexity for you.




2) Thread per request vs Event loop. What are the advantages and disadvantages of them.
Ans
    Thread-per-request:
        Advantages:
        Easy to implement and debug.
        Each request is independent, avoiding shared state issues.

        Disadvantages:
        High memory usage (1 thread/request).
        Poor scalability under high load (thread overhead).

    Event loop:
        Advantages:
        Lightweight and highly scalable.
        Handles many requests with fewer resources.

        Disadvantages:
        Complex implementation (e.g., managing async I/O).
        Harder debugging and error handling.

    


3) Install and configure Apache Tomcat for JAR and WAR File
Ans:
    WAR File:
    Directly deployable in Tomcat.
    Place it in the webapps/ folder, and Tomcat auto-deploys the app.

    JAR File:
    Not directly deployable in Tomcat.
    JAR files are for standalone Java apps.
    Use a Spring Boot JAR with embedded Tomcat if deploying standalone.


4) Configure SSL Certificate in Tomcat and Nginx
    Configure SSL in Tomcat:
        Generate Keystore:
        keytool -genkey -alias tomcat -keyalg RSA -keystore keystore.jks

        Edit server.xml:
        Add/update <Connector> for HTTPS:
        <Connector port="8443" protocol="HTTP/1.1" SSLEnabled="true" 
                keystoreFile="conf/keystore.jks" keystorePass="yourpassword" 
                scheme="https" secure="true" />

    Configure SSL in Nginx:
        server {
            listen 443 ssl;
            ssl_certificate /etc/nginx/ssl/cert.pem;
            ssl_certificate_key /etc/nginx/ssl/privkey.pem;
            server_name yourdomain.com;
            
            location / {
                proxy_pass http://localhost:8080;
            }
        }


What is truststore and keystore and how to configure it
Ans:
Keystore (For server authentication):
    Create Keystore:
    keytool -genkeypair -alias myserver -keyalg RSA -keystore keystore.jks -storepass password

    Add Certificate to Keystore:
    keytool -importcert -file server.crt -alias myserver -keystore keystore.jks

    Tomcat Configuration:
    Add to server.xml:
    <Connector port="8443" SSLEnabled="true"
            keystoreFile="conf/keystore.jks"
            keystorePass="password" />


Truststore (For client authentication):
    Create Truststore:
    keytool -importcert -file client.crt -alias client-cert -keystore truststore.jks -storepass password

    Specify in Java:
    Add JVM options:
    -Djavax.net.ssl.trustStore=truststore.jks -Djavax.net.ssl.trustStorePassword=password



Truststore vs Keystore and Their Relation to SSL:
---------------------------------------------------------
In the context of SSL (Secure Sockets Layer) and encryption, 
truststore and keystore are both used to manage cryptographic keys and certificates, but they serve different purposes.

1. Keystore:
    What it is: A keystore is a storage file that holds private keys and certificates.
    Purpose: It is primarily used by a server to prove its identity by presenting a private key.

    What it contains:
    Private Key: This key is used to sign data (e.g., for digital signatures) and decrypt incoming data.
    Certificate: The public key certificate that identifies the entity and is shared publicly.

    In SSL: When an SSL server (like a web server) communicates with clients, it needs a private key and a certificate 
    (often obtained from a Certificate Authority). These are stored in a keystore.

2. Truststore:
    What it is: A truststore is a storage file that contains a list of trusted public certificates (usually the root CA certificates).
    Purpose: It is used to verify that the certificate presented by the other party (server/client) 
    in an SSL connection is trusted. 
    If a client is connecting to a server, it checks the server‚Äôs certificate against the truststore.

    What it contains:
    Public Certificates: These certificates belong to trusted certificate authorities (CAs). 
    The truststore doesn't contain private keys.

    In SSL: When a client connects to an SSL server, it checks the server's certificate against its truststore to ensure that 
    the certificate is signed by a trusted authority. If the certificate is not trusted, the SSL connection fails.


Example in SSL Communication:
    Server Side:
    The server has a keystore containing its private key and public certificate.
    When the client connects, the server sends its public certificate to the client.

    Client Side:
    The client has a truststore containing trusted root CA certificates.
    The client checks if the server‚Äôs certificate is signed by a trusted CA from its truststore.
    If both sides trust each other (via certificates in keystore and truststore), the SSL handshake succeeds, 
    and the secure connection is established.


SSL/TLS Handshake: The process of securing the connection involves several steps:
    Step 1: The client (e.g., a web browser) requests a secure connection to the server.
    Step 2: The server sends its public certificate (stored in the keystore) to the client.
    Step 3: The client verifies the server's certificate against its truststore (checks if it trusts the certificate).
    Step 4: The client and server exchange keys and generate a shared secret (called a session key).
    This shared secret will be used to encrypt/decrypt the actual data during the session.


Why Self-Signed Certificates Need to be Manually Added to the Truststore:
    Truststore: The truststore is a file or database that contains the list of trusted public certificates 
    (typically from well-known CAs) or self-signed certificates (if you choose to trust them).
    For Self-Signed Certificates: Since self-signed certificates are not issued by a trusted Certificate Authority (CA), 
    the client has no way of knowing if the certificate is trustworthy unless explicitly told. That's why:
    The self-signed public certificate must be manually added to the truststore (either on the client or in a trusted location).
    This tells the client that you trust the self-signed certificate and the server it belongs to.


Manual Trust:
    To trust the self-signed certificate, the client needs to manually add the public certificate 
    (or the certificate authority that issued it, if it's self-signed with its own CA) to its truststore.
    This ensures that the client accepts the certificate and establishes a secure SSL/TLS connection.

SSL/TLS encryption procedure is the same for both self-signed and public CA certificates, 
the difference is that self-signed certificates require manual intervention (adding them to the truststore) 
to be trusted by clients.




5) Configure Virtual Host in Apache Tomcat
    Key Points:
    Virtual Hosts are defined in the server.xml file.
    Each virtual host can serve a different web application based on the domain or subdomain.
    Host Name: The domain or subdomain used to identify a specific virtual host.
    AppBase: The directory where the web application files are stored for that virtual host.
    Example:
    You can have two applications running on the same Tomcat server:

www.example1.com -> Serves example1.war
www.example2.com -> Serves example2.war
Benefits:
Resource Efficiency: Multiple applications on one server.

Example configuration: Configure Virtual Hosts in Apache Tomcat
Locate server.xml

<Engine name="Catalina" defaultHost="localhost">
    <!-- Virtual Host 1 -->
    <Host name="www.example1.com" appBase="webapps/example1" unpackWARs="true" autoDeploy="true">
        <Alias>example1.com</Alias>
        <Context path="" docBase="example1" />
    </Host>

    <!-- Virtual Host 2 -->
    <Host name="www.example2.com" appBase="webapps/example2" unpackWARs="true" autoDeploy="true">
        <Alias>example2.com</Alias>
        <Context path="" docBase="example2" />
    </Host>
</Engine>



6) Apache Tomcat Load Balancing with MOD_JK
Apache Tomcat Load Balancing with mod_jk is a method for distributing incoming HTTP requests across 
multiple Tomcat servers to improve scalability and reliability. 
The mod_jk module connects the Apache HTTP Server with Apache Tomcat, acting as a load balancer for Tomcat instances.


7)  Apache Tomcat HTTP Request Interception Using Valves
    Apache Tomcat HTTP Request Interception Using Valves allows you to intercept and process HTTP 
    requests and responses at various stages of the request-response lifecycle within Tomcat. 
    Valves are used to add custom logic, such as logging, security, authentication, or request manipulation, 
    before or after the request reaches a servlet or before it is sent to the client.



8) Apache Tomcat - Memory Optimization - Heap & Metaspace
By tuning the Heap and Metaspace memory settings in the CATALINA_OPTS environment variable, 
you can optimize Tomcat‚Äôs performance and ensure it efficiently uses memory.

Purpose of CATALINA_OPTS:
It allows you to specify various JVM options such as heap size, garbage collection, and Metaspace settings, 
among others, which help in memory optimization for Tomcat.
These options are used when Tomcat starts up to configure how the JVM should handle memory and performance.

Heap Memory Optimization:
    -Xms: Initial heap size (amount of memory allocated when Tomcat starts).
    -Xmx: Maximum heap size (maximum memory Tomcat can use).
    export CATALINA_OPTS="-Xms512m -Xmx2g"

Garbage Collection Optimization:

    -XX:+UseG1GC: Enables the G1 garbage collector.
    -XX:MaxGCPauseMillis=200: Sets the max garbage collection pause time.
    export CATALINA_OPTS="-XX:+UseG1GC -XX:MaxGCPauseMillis=200"



9) Apache Tomcat - Connectors and Executor Thread Optimization, Enabling HTTP Response Compression, Setting Up Monitoring

Optimizing Connectors:
You can configure the HTTP Connector to adjust the number of threads, keep-alive settings, etc., 
for better performance under high load.
Example (in server.xml):
<Connector port="8080" 
           protocol="HTTP/1.1"
           connectionTimeout="20000"
           maxThreads="200"
           minSpareThreads="25"
           maxKeepAliveRequests="100"
           enableLookups="false"
           disableUploadTimeout="true"/>


2. Executor Thread Optimization
Executor threads handle HTTP requests. Optimizing these helps improve Tomcat's responsiveness.
In server.xml, define an Executor to manage threads across multiple connectors:
<Executor name="tomcatThreadPool" 
          namePrefix="httpWorker-" 
          maxThreads="200" 
          minSpareThreads="25"/>

3. Enabling HTTP Response Compression
HTTP Response Compression reduces the size of the response sent from Tomcat to clients, 
improving performance, especially for text-based content.
To enable compression, modify the HTTP Connector in server.xml:
<Connector port="8080" protocol="HTTP/1.1" 
           compression="on" 
           compressableMimeType="text/html,text/xml,text/plain,application/json,application/xml" 
           compressionMinSize="2048"/>


Tomcate Access Logging:
Enable detailed logging of HTTP requests by configuring the Access Log Valve in server.xml:
<Valve className="org.apache.catalina.valves.AccessLogValve" 
       directory="logs" 
       prefix="localhost_access_log" 
       suffix=".log" 
       pattern="%h %l %u %t &quot;%r&quot; %s %b"/>

This logs each HTTP request with details such as client IP, request, status code, and response size.


Summary:
    Connectors and Executors optimize how Tomcat handles requests by managing threads and resources.
    HTTP Response Compression reduces bandwidth usage and improves client-side load times by compressing responses.
    Monitoring using JMX, access logs, and the Manager app helps you keep track of Tomcat‚Äôs health and performance.





10) Understanding different logs in Tomcat and Nginx
Tomcat Logs:
    catalina.out: Main log for Tomcat startup, shutdown, and general errors.
    catalina.<date>.log: Logs Tomcat server activity, including errors and exceptions.
    localhost_access_log: Logs HTTP requests to the default host.
    manager.<date>.log: Logs activities of the Tomcat Manager app (deployments).
    access_log: Tracks HTTP request details like client IP and response status.

Nginx Logs:
    access.log: Logs incoming HTTP requests (IP, method, status, etc.).
    error.log: Logs errors like configuration issues or failed requests.
    slow.log: Logs requests that take too long to process (if configured).
Both servers provide essential logging for monitoring and troubleshooting.


11) What is reverse proxy ?
    A reverse proxy is a server that sits between client devices and a web server. 
    It forwards client requests to one or more backend servers and then returns the response from the backend 
    server(s) to the client.



12) Configuring L4, L7 LoadBalancer with Nginx

Used for: TCP and UDP traffic (like MySQL, database connections, etc.).
Works at: The Transport Layer (Layer 4) of the OSI model.
How it works: Nginx performs load balancing based on IP address and port without inspecting the content of 
the data being transmitted.
    For example, with MySQL, Nginx can distribute requests from clients to multiple backend MySQL servers 
    based solely on the connection's IP address and port (default 3306 for MySQL).
    Since Nginx does not inspect the packet contents, it does not require knowledge of the application-layer 
    protocol (like HTTP).



Basic TCP Load Balancing: For L4 load balancing, configure Nginx to proxy TCP traffic to backend servers.
stream {
    upstream tcp_backend {
        server backend1.example.com:8080;
        server backend2.example.com:8080;
    }

    server {
        listen 12345;  # Incoming port for TCP traffic
        proxy_pass tcp_backend;  # Forward to upstream TCP servers
    }
}



L7 Load Balancing (Layer 7 - Application Layer): 
Used for: HTTP(S) traffic (web applications, APIs, etc.).
Works at: The Application Layer (Layer 7) of the OSI model.
How it works: Nginx performs load balancing by inspecting the content of HTTP requests (e.g., URL path, headers, cookies) 
and can make decisions based on this data.
For example, Nginx can route HTTP traffic to different backend servers depending on the URL path or use advanced features like SSL termination, cookie-based session persistence, etc.



Basic HTTP Load Balancing: For L7 load balancing, configure Nginx to proxy HTTP requests to backend web servers.
http {
    upstream http_backend {
        server backend1.example.com;
        server backend2.example.com;
    }

    server {
        listen 80;  # HTTP port
        server_name example.com;

        location / {
            proxy_pass http://http_backend;  # Forward HTTP requests to upstream backend servers
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}

Key Differences:
    L4 Load Balancing is used for non-HTTP protocols (like MySQL, SSH, etc.) and makes decisions based on IP and port.
    L7 Load Balancing is used for HTTP/HTTPS traffic and makes decisions based on the application layer 
    (like URLs, headers, cookies).


Key Features of stream in Nginx:
In Nginx, the stream block is used to handle TCP and UDP traffic, which operates at Layer 4 (L4) of the OSI model. 
This block enables Nginx to act as a reverse proxy for non-HTTP protocols, 
allowing it to distribute traffic to backend servers for services that use TCP or UDP, such as databases, 
mail servers, or custom applications.

Basic Example of stream Block (TCP Load Balancing):
    stream {
        upstream tcp_backend {
            server backend1.example.com:3306;
            server backend2.example.com:3306;
        }

        server {
            listen 3306;  # Listen on TCP port 3306 (MySQL)
            proxy_pass tcp_backend;  # Forward requests to upstream backend servers
        }
    }






13) Configure Nginx HA with keepalived
1. Install Nginx and Keepalived:
    sudo apt-get install nginx keepalived

2. Configure Keepalived:
On both servers, configure Keepalived to create a virtual IP (VIP) and enable failover.

/etc/keepalived/keepalived.conf:
vrrp_instance VI_1 {
    state MASTER  # Use BACKUP on the secondary node
    interface eth0
    virtual_router_id 51
    priority 101  # Higher priority for the MASTER node
    advert_int 1
    virtual_ipaddress {
        192.168.1.100  # Virtual IP (VIP) for Nginx HA
    }
}


Enable and Start Services:
sudo systemctl enable nginx keepalived
sudo systemctl start nginx keepalived

Summary:
    Keepalived manages the failover of the Virtual IP (VIP).
    Nginx handles the load balancing, distributing traffic to backend servers.
    Keepalived ensures high availability by switching to the backup server if the primary server fails.



14) Static Load Balancing Algorithm - Round Robin, Weight Round Robin, IP Hash
Round Robin:
    Description: Distributes requests evenly across all backend servers in a circular order.
    Use case: Simple load balancing with no regard for server load.
upstream backend {
    server backend1.example.com;
    server backend2.example.com;
}


Weight Round Robin:
Description: Distributes requests based on server weights (higher weight means more traffic).
Use case: Useful when backend servers have different capacities.
upstream backend {
    server backend1.example.com weight=3;
    server backend2.example.com weight=1;
}


IP Hash:
Description: Routes requests from the same client IP to the same backend server, ensuring session persistence.
Use case: Useful for applications that require session stickiness.
upstream backend {
    ip_hash;
    server backend1.example.com;
    server backend2.example.com;
}





15) Dynamic Load Balancing Algorithm - Least Connection, Weighted Least Connection, Weighted Response time
Least Connection:
Description: Routes traffic to the server with the fewest active connections.
Use case: Useful when backend servers have varying connection loads.
upstream backend {
    least_conn;
    server backend1.example.com;
    server backend2.example.com;
}


Weighted Least Connection:
Description: Routes traffic to the server with the fewest active connections, considering each server's weight.
Use case: Useful for servers with different capacities.
upstream backend {
    least_conn;
    server backend1.example.com weight=3;
    server backend2.example.com weight=1;
}

Weighted Response Time:
Description: Routes traffic to the server with the fastest response time, considering the weight of each server.
Use case: Prioritizes faster servers while balancing traffic.
upstream backend {
    server backend1.example.com weight=3;
    server backend2.example.com weight=1;
}
# Requires third-party module for response time-based balancing





16) Nginx Redirects and Rewrites
        Redirects send clients to a new URL (e.g., 301 for permanent).
        Description: Sends an HTTP response to the client to request a new URL.

        Rewrites modify URLs internally on the server.
        Description: Changes the requested URL internally without informing the client.


17) Understanding Nginx Worker Process and Worker Connections

worker_processes 4;  # 4 worker processes

    Worker Connections:
    Description: Defines how many connections each worker process can handle simultaneously.
events {
    worker_connections 1024;  # Each worker can handle 1024 connections
}


18) How to cache static content in nginx
    1. Using expires Directive (Simple Caching):
    server {
        location /assets/ {
            root /var/www/html;
            expires 30d;  # Cache for 30 days
            add_header Cache-Control "public";  
        }
    }


    2. Using proxy_cache (Advanced Caching):
    This caches responses from a backend server or proxy.
    http {
        proxy_cache_path /tmp/cache levels=1:2 keys_zone=static_cache:10m max_size=1g inactive=60m;
        
        server {
            location / {
                proxy_pass http://backend;
                proxy_cache static_cache;
                proxy_cache_valid 200 1h;  # Cache 200 responses for 1 hour
                proxy_cache_use_stale error timeout updating;  # Serve stale cache if backend fails
            }
        }
    }


Summary:
Simple caching: Use expires to set cache duration for static content.
Advanced caching: Use proxy_cache for more control over caching behavior.




19) Compress Response in nginx, Enabling HTTP/2, Enabling Server Push
    Compression: Use gzip to reduce response sizes.
    HTTP/2: Enable http2 in the listen directive for faster communication.
    Server Push: Use the Link header to push resources to clients in HTTP/2.

20) Understanding Apache Tomcat Session Replication
Session replication in Tomcat ensures that session data is shared and available across multiple 
Tomcat instances in a cluster, enhancing application availability and reliability.

Apache Tomcat Session Replication:
    Purpose: Ensures user session data is shared across multiple Tomcat instances for high availability and fault tolerance.
    How it works: When a session is created or updated, Tomcat replicates the session to other nodes in the cluster.

Types:
    In-memory: Fast but loses data on server failure.
    Persistent: Saves session data to disk, survives restarts, but slower.





4
##Web, HTTP and Other Communication Protocols	
=====================================================
1) HTTP, HTTPS, SSL, TLS
Web protocols enable communication between clients (e.g., browsers) and servers on the internet.
The most common protocol for web communication is HTTP.

HTTP (HyperText Transfer Protocol)
    Purpose: Defines how messages are formatted and transmitted on the web.
    Key Characteristics:
        Operates at the application layer.
        Uses the request-response model.
        Stateless: Each request is independent.

SSL (up to version 3.0) is considered insecure and replaced by TLS.

How They Work Together
HTTP + TLS = HTTPS: Provides secure web browsing.
During an HTTPS session:
A TLS/SSL handshake establishes a secure channel.
HTTP messages are encrypted and transmitted over this channel.


HTTP Methods - GET, POST, PUT, PATCH, DELETE. HTTP Method Idempotency

HTTP Methods:
    GET: Retrieve data (read-only).
    POST: Send data to the server (e.g., create resources).
    PUT: Replace an entire resource.
    PATCH: Update part of a resource.
    DELETE: Remove a resource.

Example:
GET /resource/1 ‚Üí Always fetches the same data.
POST /resource ‚Üí Creates a new resource each time it's called.

In HTTP, an "idempotent method" refers to a request that can be executed multiple times with the same parameters, 
resulting in the same outcome.

Examples of idempotent methods: GET, HEAD, PUT, DELETE, OPTIONS, TRACE 
Non-idempotent method: POST - sending a POST request multiple times can create multiple resources on the server 



SSH (Secure Shell):
    SSH is a protocol used to securely connect to and manage remote systems over an encrypted network.
    It allows secure communication, file transfers, and command execution.

    Typical usage:
    ssh user@host (to log in to a remote machine).




2) HTTP Status Codes - 2xx, 3xx, 4xx, 5xx
Ans
    HTTP Status Codes
    2xx: Success
        200 OK: Request succeeded.
        201 Created: Resource created successfully.
        204 No Content: Request succeeded, no content to return.
    3xx: Redirection
        301 Moved Permanently: Resource moved to a new URL.
        302 Found: Temporary redirection.
        304 Not Modified: Cached version is still valid.
    4xx: Client Errors
        400 Bad Request: Invalid request.
        401 Unauthorized: Authentication required.
        403 Forbidden: Access denied.
        404 Not Found: Resource not found.
    5xx: Server Errors
        500 Internal Server Error: Generic server issue.
        502 Bad Gateway: Invalid response from upstream server.
        503 Service Unavailable: Server temporarily unavailable.


HTTP Request, Response Format
    HTTP Request Format
        An HTTP request consists of:
        Request Line: Specifies the method, URL, and HTTP version.
        <METHOD> <URL> <HTTP-VERSION>
        Example: GET /index.html HTTP/1.1
        Headers: Metadata about the request (key-value pairs).
        Host: example.com
        User-Agent: Mozilla/5.0
        Body (Optional): Data sent with the request (e.g., for POST, PUT).

    HTTP Response Format
        An HTTP response consists of:
        Status Line: Indicates the HTTP version, status code, and reason phrase.
        <HTTP-VERSION> <STATUS-CODE> <REASON-PHRASE>
        Example: HTTP/1.1 200 OK
        Headers: Metadata about the response.
        Content-Type: text/html
        Content-Length: 1234
        Body (Optional): The actual content (e.g., HTML, JSON).


3) HTTP Cookies vs Sessions
    Storage:
    Cookies are stored on the client-side.
    Sessions are stored on the server-side.

    Data Size:
    Cookies have a size limit (~4KB).
    Sessions can store more data, depending on the server.

    Lifetime:
    Cookies can persist after the browser is closed.
    Sessions end when the browser or session expires.

    Security:
    Cookies are less secure since they are client-stored.
    Sessions are more secure as they are server-stored.

    Use Cases:
    Cookies are used to remember user preferences.
    Sessions are used to track user login states.


4) TCP Flow Control and Congestion Controlling
TCP Flow Control
    Ensures the sender doesn't overload the receiver.
    Uses the receiver's advertised window size to limit data transmission.

TCP Congestion Control
    Prevents network overload.
    Key mechanisms:
        Slow Start: Start small, increase exponentially.
        Congestion Avoidance: Additive increase, multiplicative decrease (AIMD).
        Fast Retransmit: Quickly resend lost packets.
        Fast Recovery: Reduce speed temporarily after congestion.



TCP vs HTTP
---------------------------------
TCP is a low-level protocol that handles reliable data transmission between devices, ensuring ordered and error-free delivery.
HTTP is an application layer protocol built on top of TCP, used for requesting and receiving data on the web. 
It is stateless and focused on web communication, but relies on TCP for secure, reliable data transport.


TCP (Transmission Control Protocol):
    Transport Layer (Layer 4)
    Purpose: Ensures reliable, error-free data transmission.
    How It Works: Establishes a connection using a three-way handshake, then transfers data in segments. Ensures delivery, order, and error checking.
    Security: No built-in security; uses SSL/TLS for encryption (e.g., HTTPS).
    Use Cases: File transfer, email, video streaming, online gaming, remote access.

HTTP (Hypertext Transfer Protocol):
    Application Layer(Layer 7)
    Purpose: Web communication protocol for requesting and receiving data (HTML, JSON, etc.).
    How It Works: Request-response model; stateless, but supports persistent connections (HTTP/1.1 and beyond).
    Security: Secured with HTTPS (HTTP over SSL/TLS) for encryption and authentication.



Steps-flow: TCP handshake ‚Üí 2. HTTP request ‚Üí 3. Server processes ‚Üí 4. HTTP response ‚Üí 5. TCP connection termination.

Operational Steps of HTTP over TCP:
----------------------------------------------
    TCP Connection Establishment (Three-Way Handshake)
        Step 1: The client (e.g., a browser) sends a SYN (synchronize) packet to the server to initiate the connection.
        Step 2: The server responds with a SYN-ACK (synchronize-acknowledgment) packet to confirm the request.
        Step 3: The client sends an ACK (acknowledgment) packet to confirm the server‚Äôs response. The TCP connection is now established.

    HTTP Request
        Once the TCP connection is established, the client sends an HTTP request to the server. This includes:
        Request line: Method (e.g., GET, POST), URL, and HTTP version.
        Headers: Information like user-agent, content type, and cookies.
        Body: Optional data for POST/PUT requests.


MySQL Connection: Type and Details:
    A MySQL connection is a client-server connection used to communicate with a MySQL database server. 
    The connection can be established over a network (TCP/IP) or locally using a Unix socket file. 
    MySQL uses a client-server architecture where:

    Client: The application or user that sends queries and receives results.
    Server: The MySQL server that processes queries, performs actions, and returns results.


How MySQL Makes a Connection on Top of TCP:
    MySQL uses the TCP/IP protocol to establish a connection between the client and server. Here's a simplified process:

    TCP Handshake:
        The client sends a SYN (synchronize) packet to the MySQL server.
        The server responds with a SYN-ACK (synchronize-acknowledge) packet.
        The client sends an ACK (acknowledgment) packet back to complete the handshake and establish the connection.

    MySQL Protocol:
        After the TCP connection is established, MySQL uses its own protocol on top of TCP to manage the communication.

MySQL Protocol Steps:
    Handshake: Client and server agree on the connection parameters.
    Authentication: Client sends credentials, and the server verifies them.
    Query Processing: Client sends queries; the server processes and returns results.
    Data Transfer: Results are sent in a structured format.
    Termination: The connection is closed once the work is done.

MySQL Protocol works on top of TCP/IP just like HTTP works on top of TCP.

How MySQL Protocol Works on Top of TCP:
    TCP/IP is responsible for ensuring reliable data transfer between the client and server.
    MySQL Protocol is built on top of TCP/IP to handle MySQL-specific operations like authentication, 
    query execution, and result handling.
    It structures the data in specific formats (binary) and ensures that SQL queries and results are correctly 
    exchanged between the client and server.

Do MySQL and Oracle Use the Same Protocol?
    No, MySQL and Oracle Database do not use the same protocol. While both use TCP/IP for data transport, 
    each database system has its own unique protocol for client-server communication.

MySQL Protocol: A custom protocol designed specifically for interacting with MySQL databases. 
    It is lightweight and optimized for MySQL operations.

Oracle Protocol (SQL*Net): Oracle has its own protocol called SQL*Net (also known as Oracle Net Services) 
    for communication between Oracle databases and clients. SQL*Net is more feature-rich and complex compared 
    to MySQL's protocol, as it supports advanced features like advanced security and connection pooling.



TCP/IP:
============
1. TCP Connection Establishment:
    TCP is responsible for establishing a connection between your client (e.g., web browser) and the server.
    The client wants to connect to the server using an IP address and port number (e.g., http://192.168.1.1:80).
    TCP uses the IP address to locate the server on the network and the port (e.g., 80 for HTTP) to identify the application or service running on the server.
    A three-way handshake is initiated to establish a connection between the client and server:
    The client sends a SYN packet to the server.
    The server responds with a SYN-ACK packet.
    The client sends an ACK packet back to the server, confirming the connection.
2. IP Routing:
    Once the connection is established, the IP protocol is responsible for routing the data packets across the network to the correct destination.
    IP routing ensures that the data reaches the correct server by forwarding packets through routers and networks until it reaches the server‚Äôs IP address.
    The port number helps the server determine which service or application should handle the incoming request 
    (for example, HTTP uses port 80, HTTPS uses port 443).
3. Data Transfer:
    After the connection is established, TCP takes care of data segmentation, ensuring that data is divided into small packets and transmitted reliably to the server.
    Each packet contains both the destination IP address (for routing) and the destination port (for the correct application).
    The server uses the port to process the request (e.g., a web server listening on port 80 will handle HTTP requests).

4. Closing the Connection:
    Once the data exchange is complete, TCP ensures that the connection is properly terminated (e.g., using the FIN and ACK packets).


TCP:
    TCP cannot function on its own without IP because it needs an IP address to identify the destination machine. 
    It would have no way to know where to send or receive data.


IP:
    TCP doesn't have a built-in mechanism to route data between devices. IP provides the necessary addressing to ensure 
    that data can reach the correct machine (host).

TCP and IP work together to enable communication over the internet or any network. 
IP handles addressing and routing, and TCP ensures that data is reliably transferred to the correct destination.


TCP manages the reliability and order of data delivery, but IP ensures the data can traverse multiple networks 
and reach the correct device.
TCP cannot function without IP because IP handles addressing and routing.


Layer 4 (Transport Layer), specifically in TCP (Transmission Control Protocol), the format of the data is defined by the TCP Segment. 
A TCP segment consists of a header and data (payload).

Example TCP Segment Format (Simplified):
    Source Port	16	Port number of sender
    Destination Port	16	Port number of receiver
    Sequence Number	32	Sequence number for data ordering
    Acknowledgment Num	32	Acknowledgment number for received data
    Data Offset	4	Length of TCP header (in 32-bit words)
    Reserved	3	Reserved for future use
    Flags	9	Control flags (SYN, ACK, etc.)
    Window Size	16	Flow control information
    Checksum	16	Error checking (checksum)
    Urgent Pointer	16	Urgent data indicator (if URG flag set)
    Options (Optional)	Variable	Additional TCP options
    Padding	Variable	Padding to align the header
    Data (Payload)	Variable	Application data being transferred




Role of TCP/IP:
    TCP/IP provides the common ground (reliable data transfer, routing, and delivery) for all these protocols to function.
    Without TCP/IP, there would be no reliable mechanism to transport the application-layer data between devices.


TCP/IP creates the reliable foundation (Layer 4 connection), and different application-layer protocols 
(like HTTP, MySQL, Oracle) build on top of it to handle their unique requirements (e.g., security, managing connections, 
structured data exchange). This layered approach enables flexibility and specialization for different use cases.


TCP/IP Establishes the Layer 4 Connection=>Application Protocols Operate on Top of TCP
Examples of Application Protocols Over TCP/IP:
    HTTP/HTTPS:         Used for web communication. It adds rules for exchanging web pages securely and efficiently.
    MySQL Protocol:     Designed for database queries and responses. It manages database-specific operations like authentication, 
                        query execution, and result delivery.
    Oracle Protocol:    Similar to MySQL but tailored for Oracle databases, with its own mechanisms for data exchange and management.
    SMTP/IMAP/POP3:     Used for email communication.
    FTP:                Used for file transfers.
    Also SSH Telnet, SMPP etc.




Why Different Protocols?
    Each protocol is tailored for specific purposes:
    HTTP/HTTPS focuses on delivering web content and securing it with encryption (TLS/SSL).
    Database protocols like MySQL and Oracle handle structured query execution and ensure proper database interaction.
    Other protocols (e.g., SSH, Telnet) address terminal access and remote management.





5) Low Latency Handshake: QUIC
    QUIC (Quick UDP Internet Connections) is a transport protocol designed for low-latency connections.
    It achieves this by combining TLS encryption and transport-layer handshake into a single step, 
    reducing round trips compared to TCP.
    Ideal for real-time applications like streaming and gaming.


6) URL vs URI, and URL Encoding
URL vs URI
    URI (Uniform Resource Identifier): Identifies a resource, either by location, name, or both.
        Example: http://example.com, mailto:user@example.com, urn:isbn:0451450523.
    URL (Uniform Resource Locator): A type of URI that specifies the location of a resource and the protocol to access it.
        Example: http://example.com/page.html.
    All URLs are URIs, but not all URIs are URLs.

URL Encoding:
URL Encoding is a process of converting characters into a format that is safe to transmit in a URL.
It replaces special characters with % followed by a hexadecimal value.
    Purpose: Encodes characters in a URL to ensure they are transmitted safely over the internet.
    Use Cases:
    Encoding query parameters: https://example.com/search?q=hello%20world.
    Safeguarding data in GET requests or APIs.

A short URL is a condensed version of a long web address.
    It redirects users to the original URL while being easier to share and remember.
    Example:
    Original: https://example.com/very/long/url
    Shortened: https://bit.ly/abc123

How it works:
    User submits a long URL to a URL shortening(free or paid) service.
    The service generates a unique, shorter identifier for the URL.
    When users click the short URL, it redirects them to the original long URL stored in the service's database.


7) HTTP Long Pooling, Short Pooling, Websocket, Server Sent Event
HTTP Long Polling
    Definition: A technique where the client requests information from the server, and the server holds the 
    connection open until new data is available.
    How It Works:
        The client sends a request.
        The server delays the response until new data is available or a timeout occurs.
        After the response, the client immediately sends another request.
        Use Cases: Chat applications, live notifications.

HTTP Short Polling
    Definition: The client regularly sends requests to the server at fixed intervals to check for updates.
    How It Works:
        The client sends requests at intervals (e.g., every 5 seconds).
        The server responds immediately with the current state, even if no updates are available.
        Use Cases: Simple applications where low latency is not critical.

WebSockets
    Definition: A full-duplex communication protocol that allows continuous data exchange between 
    client and server over a single TCP connection.
    How It Works:
        The client establishes a WebSocket handshake via HTTP, then upgrades to a persistent TCP connection.
        Both client and server can send messages at any time without additional requests.
        Use Cases: Real-time games, stock price updates, live chat.

Server-Sent Events (SSE)
    Definition: A unidirectional communication protocol where the server pushes updates to the client using HTTP.
    How It Works:
        The client opens an HTTP connection to the server.
        The server sends data updates as events over the connection.
        Use Cases: Real-time notifications, dashboards, live feeds.

HTTP Streaming: Transfer Encoding: chunked
    HTTP Streaming using Transfer-Encoding: chunked is a technique where data is sent to the client in chunks 
    as it becomes available, rather than waiting for the entire response to be ready.
    Client Support: Most modern browsers and HTTP clients support chunked transfer.
    Server Configuration: Many servers (e.g., Nginx, Apache) support this by default, but it may require explicit configuration.



8) What is CORS
A Origin: Defined by the combination of:
    Protocol (e.g., http, https)
    Domain (e.g., example.com)
    Port (e.g., :8080)
    Example: https://example.com:443 is different from http://example.com:80.

    Same-Origin Policy: By default, web browsers block requests from a web page to a different origin for security reasons.
    CORS: Provides a way for servers to specify which domains (origins) are allowed to access their resources.

Common Issues:
    CORS Error: Occurs when a server does not include the appropriate CORS headers for a cross-origin request.
    Credentials Blocked: If Access-Control-Allow-Credentials is not set and credentials are included in the request.




9) HTTP Security: Content Security Policy, Strict-Transport-Security
1. Content Security Policy (CSP)
    Purpose:
    Mitigate cross-site scripting (XSS) and other injection attacks.
    Control which resources (scripts, styles, images, etc.) are allowed to load.
    How it Works:
        CSP is implemented using the Content-Security-Policy HTTP header.
        You specify directives that dictate the sources and types of content that browsers are allowed to load.

2. Strict-Transport-Security (HSTS)
Purpose:
    Enforce the use of HTTPS to prevent man-in-the-middle (MITM) attacks and downgrade attacks.
    How it Works:
        HSTS is implemented using the Strict-Transport-Security HTTP header.
        Once a browser receives this header, it only communicates with the site over HTTPS.



10) HTTP Basic Authentication
HTTP Basic Authentication is a simple authentication mechanism that encodes user credentials (username and password) 
in a Base64 format and includes them in the Authorization header of HTTP requests.

HTTP Content Negotiation:
    HTTP Content Negotiation is a mechanism that allows the client and server to communicate and decide on the most 
    appropriate representation of a resource (e.g., format, language, or encoding). 
    This is achieved through HTTP request headers and server responses.



11) What is HTTP Keep alive, Why is it needed ?
Definition:
HTTP Keep-Alive is a mechanism that allows a single TCP connection to remain open for multiple HTTP requests and responses, 
rather than opening a new connection for each request. 

Example Without Keep-Alive
    For a webpage with 10 resources:
    The client opens and closes a separate TCP connection for each resource (e.g., HTML, CSS, JS).
    This results in 10 TCP handshakes, increasing latency and resource usage.

Example With Keep-Alive
    For the same webpage with Keep-Alive enabled:
    The client reuses a single TCP connection for all 10 resources.
    Only one handshake is needed, significantly improving performance.

Reduces Latency:
    Avoids the overhead of repeatedly establishing and tearing down TCP connections.
    Faster communication because the handshake for new connections is skipped.
Saves Resources:
    Reduces CPU and memory usage on both client and server.
    Fewer TCP connections lead to less network congestion.




12) HTTP Multiplexing:
    HTTP Multiplexing, introduced in HTTP/2, revolutionizes web communication by enabling multiple 
    requests and responses to be sent over a single TCP connection simultaneously. 
    This results in improved performance, reduced latency, and more efficient use of network resources compared to HTTP/1.x. 
    It plays a significant role in enhancing the user experience for modern web applications.

Understanding HTTP 1.1, 2, 3 differences:
    HTTP/1.1 is the legacy version and is still widely used today, 
        but it has performance limitations such as head-of-line blocking and inefficient use of TCP connections.
    HTTP/2 introduced important improvements such as multiplexing and header compression, 
        offering better performance for most modern websites. 
        However, it still uses TCP, which suffers from head-of-line blocking.
    HTTP/3 takes the biggest leap by using QUIC (UDP-based), offering even lower latency, improved performance, and security. 
    It's especially advantageous in scenarios with high network congestion or unreliable connections. 
    However, it's still in the process of widespread adoption.




13) Understanding UDP,
    Use Cases for UDP
        Due to its characteristics, UDP is often used in applications where speed is more important than reliability, such as:
        Real-time communication:
        Voice over IP (VoIP), video conferencing, online gaming.
        Streaming:
        Video and audio streaming where timely delivery is prioritized over occasional packet loss.
        DNS (Domain Name System):
            DNS queries typically use UDP to speed up the process of looking up domain names.
        Broadcast and multicast:
            Broadcasting to multiple clients, as in IP television or network management.

    UDP is a fast, lightweight, and connectionless protocol used for communication in many real-time applications.
    However, the application using UDP must be capable of handling potential issues like packet loss, 
    out-of-order delivery, or duplication.



14) Others Protocol - gRPC, Apache Thrift, MQTT, AMQP
    gRPC:
    Type: RPC framework.
    Use Case: High-performance microservices communication, real-time services.
    Without explicit configuration, gRPC communication will not use HTTPS. Always enable TLS for secure communication.

    Apache Thrift:
    Type: RPC framework.
    Use Case: Cross-language services and data serialization.

    MQTT:
    Type: Publish/Subscribe messaging.
    Use Case: IoT and real-time messaging.

    AMQP:
    Type: Message queuing.


15) Understanding Chrome Developer Tools
    Chrome Developer Tools (DevTools) is a set of web development tools built into Google Chrome that helps developers 
    inspect, debug, and optimize websites.
    These tools help developers debug, test, and improve website performance directly in the browser.


16) Writing RESTful API:
        REST, an architectural style for distributed systems. It defines a set of rules for how clients and servers 
        communicate over HTTP, focusing on stateless interactions, scalability, and resource-based operations.
For an API to be considered RESTful, it must follow a few core principles of REST:
    Statelessness:
        Every request is treated independently.
    Client-Server Architecture:
        The client and the server are separate entities.  

Uniform Interface:
    RESTful APIs have a consistent, standardized set of conventions for interacting with resources, 
    using HTTP methods and status codes.
    Resources (data) are identified via URIs (Uniform Resource Identifiers).
    Clients interact with resources using standard HTTP methods: GET, POST, PUT, DELETE.

Resource-Based:
Everything is a resource (e.g., user, product, order) identified by a URI.

Representation of Resources:
Resources are transferred between client and server in various formats, typically JSON or XML

Best Practices
    Use versioning in API paths (e.g., /v1/users).
    Keep URLs noun-based (e.g., /users, /products).
    Use plural for resource names (e.g., /users instead of /user).
    Be consistent with HTTP methods and status codes.
    Implement pagination for large data sets (e.g., /users?page=1&size=10).



17) What is Ajax? Sync, Async Ajax call
AJAX (Asynchronous JavaScript and XML) is a technique used in web development to create dynamic, interactive web pages
    AJAX uses the following components:
        JavaScript: The scripting language to make the request.
        XMLHttpRequest (XHR): An API used to send and receive data asynchronously.
        JSON or XML: Common data formats used for exchange (although other formats like HTML can also be used).

Modern Alternative: Fetch API
    In modern JavaScript, the Fetch API is often used as an alternative to XMLHttpRequest. 
    It provides a cleaner, promise-based interface for making AJAX requests and supports both synchronous and asynchronous operations.
    The Fetch API is asynchronous by default and returns a promise.


Basic Javascript, DOM Manipulation, and Event Handling, Form Validation
    JavaScript allows you to create interactive web pages by manipulating the DOM and handling events.
    DOM Manipulation allows you to modify HTML content, change styles, and add/remove elements dynamically.
    Event Handling enables you to respond to user actions (e.g., clicks, keypresses) by adding event listeners to elements.
    Form Validation helps ensure that users submit valid data, such as required fields, correct email formats, and strong passwords.





##5
Basic Networking	
=============================================================
1) Understanding Network Layer, TCP/IP Stack
TCP/IP Stack:
    The TCP/IP Stack is the foundational model for network communication. It consists of four layers:
    Application Layer (Layer 4): Deals with application-specific protocols like HTTP, FTP, SMTP.
    Transport Layer (Layer 3): Ensures reliable data transfer. Protocols include TCP (Transmission Control Protocol) 
    for connection-oriented communication and UDP (User Datagram Protocol) for connectionless communication.
    Internet Layer (Layer 2): Handles routing and addressing using IP (Internet Protocol).
    Link Layer (Layer 1): Manages the physical network hardware and protocols like Ethernet.
    The TCP/IP stack is widely used for internet communication and is the foundation of most modern networking.

2) What is DNS ? How it works, What is DHCP, CIDR
    DNS (Domain Name System):
    DNS translates human-readable domain names (like www.example.com) into IP addresses (like 192.168.1.1).
    It works by using a hierarchical system with multiple levels of servers: local DNS resolver, root servers, and authoritative DNS servers.

    DHCP (Dynamic Host Configuration Protocol):
    DHCP automatically assigns IP addresses and other network configuration details (like subnet mask, gateway) to devices on a network.

CIDR (Classless Inter-Domain Routing):
CIDR is a method for allocating IP addresses and routing that replaces traditional class-based IP addressing (e.g., Class A, B, C).
It uses a prefix notation (e.g., 192.168.1.0/24), where /24 indicates how many bits are




3) Network Interface - Physical and Virtual Interface
A Network Interface is the point of connection between a computer/device and a network. 
It enables communication over the network using either physical or virtual interfaces.

Physical Interface:
    Physical Interface refers to the hardware components used to connect a device to a network.
    Examples include:
    Ethernet ports (wired network connections)
    Wi-Fi adapters (wireless network connections)
    Network Interface Cards (NICs) in computers or servers

Virtual Interface:
    Virtual Interface is a software-defined network interface that exists logically rather than physically.
    Examples include:
    Virtual LAN (VLAN) interfaces: Logical segmentation of networks.
    Virtual Network Interface Cards (vNICs): Used in virtual machines (VMs) or containers.
    Loopback interface: A special virtual interface used for internal communication within a device (e.g., 127.0.0.1 for localhost).


4) Understading IPTables, and Routing Table

IPTables:
    IPTables is a Linux tool to control network traffic via rules that specify how to handle incoming, outgoing, 
    and forwarded packets.
    Chains define rules (e.g., INPUT, OUTPUT), and tables group them (e.g., filter, nat, mangle).
    Common commands include:
        iptables -L: List rules
        iptables -A: Add rule
        iptables -D: Delete rule

Routing Table:
    A Routing Table stores network paths for directing data packets.
    It includes information about:
        Destination IP: Network destination
        Gateway: Next-hop IP
        Interface: Network interface
        Metric: Route preference
    Commands:
        route -n: View routing table
        ip route show: View routing table


L2, and L3 Devices
L2 devices handle local communication within the same network, while L3 devices manage communication between different networks.



5)NATing, Static & Dynamic Routing, BGP Routing Protocol
NATing (Network Address Translation):
    NAT is a method used to modify the source or destination IP addresses in packet headers.
    It enables multiple devices on a private network to share a single public IP address for internet access.
    Types:
        Source NAT (SNAT): Modifies the source IP.
        Destination NAT (DNAT): Modifies the destination IP (e.g., port forwarding).

Static & Dynamic Routing:
    Static Routing: Routes are manually configured by an administrator, providing fixed paths for traffic.
    Dynamic Routing: Routes are automatically learned and updated using routing protocols (e.g., RIP, OSPF, BGP).

BGP Routing Protocol:
    BGP (Border Gateway Protocol) is a dynamic, path-vector protocol used to exchange routing information 
    between different autonomous systems (ASes) on the internet.



6) Virtual Private Network, Secure Tunnel
Virtual Private Network (VPN):
    VPN is a secure connection that allows users to access a private network over the internet.
    It encrypts data traffic, ensuring confidentiality and protecting against unauthorized access.
    Common uses include:
    Remote access for employees
    Securing internet traffic on public networks

Secure Tunnel:
    A Secure Tunnel refers to an encrypted communication channel between two endpoints (e.g., between a device and a VPN server).
    It ensures that data passing through the tunnel is protected from eavesdropping and tampering.
    Common tunneling protocols include:
    IPsec (for secure internet protocol communication)
    SSL/TLS (used in VPNs like OpenVPN or SSL VPN)




7) Container Networking - Docker
Docker Networking allows containers to communicate with each other and with external systems.
Key types of Docker networks:
    Bridge: Default network, containers on the same host can communicate.
    Host: Container shares the host‚Äôs network stack.
    Overlay: Enables communication between containers on different hosts, often used in Docker Swarm or Kubernetes.
    None: No network connectivity for the container.
Docker uses network drivers to manage container-to-container and container-to-host communication.




##6
Database & ORM	
========================================================
1)DB Design and Best Practices
Ans:
Normalization: Organize data to reduce redundancy and ensure data integrity by applying normal 
forms (up to 3NF, or higher if needed).
Indexing: Use indexes to speed up query performance, especially on columns used in WHERE clauses, JOINs, and ORDER BY.
    Read vs. Write Trade-offs:
        Read-heavy workloads benefit from more indexes to speed up query performance.
        Write-heavy workloads may suffer due to the overhead of maintaining indexes during INSERT, UPDATE, or DELETE operations.

Relationships: Properly define relationships (One-to-One, One-to-Many, Many-to-Many) between entities in the database schema.

Foreign Keys: Use foreign keys to maintain referential integrity between related tables.

DataTypes: Choose appropriate data types for columns based on the data they store to optimize storage and performance.

Transactions: Ensure that critical database operations are wrapped in transactions to maintain consistency (ACID properties).

ORM Best Practices:
    Lazy Loading vs. Eager Loading: Use lazy loading for large data sets, eager loading when you need related data immediately.
    Avoid N+1 Problem: Optimize queries to avoid the N+1 query problem by using proper fetching strategies.
    Use DTOs: Use Data Transfer Objects (DTOs) for better separation of concerns and to avoid unnecessary database queries.
    Database Security: Implement access control, encryption for sensitive data, and regular backups.

    Denormalization: Consider denormalization for performance optimization in read-heavy applications, 
    but weigh the trade-offs carefully.
    Avoid Hardcoding SQL: Use parameterized queries or ORM frameworks (e.g., Hibernate, JPA) to prevent SQL injection attacks.


Candidate Key(uniqueness):
    Any column or combination of columns that can uniquely identify a row.
    A table can have multiple candidate keys.
    Example: email or phone_number.

Composite Key(uniqueness-with two or more column):
    A type of candidate key made up of two or more columns.
    Used when a single column isn‚Äôt sufficient for uniqueness.
    Example: order_id + product_id.

Key Point: All composite keys are candidate keys, but not all candidate keys are composite keys.

Composite Key has maded must two or more column(Candidate Key), but Candidate Key may konly one column.




DB Key type:
1. Non-key:
    A column that is not part of any key.
    It does not uniquely identify a row.
    Example: In a table of employees, name or age could be non-key columns.
2. Candidate Key:
    A column (or combination of columns) that can uniquely identify a row.
    There can be multiple candidate keys in a table.
    Example: email and phone_number might both be candidate keys in a user table.
3. Primary Key:
    A chosen candidate key to uniquely identify rows in a table.
    Must be unique and not null.
    Example: id is often used as the primary key.
4. Composite Key:
    A combination of two or more columns that together uniquely identify a row.
    Used when a single column is insufficient to create uniqueness.
    Example: order_id + product_id together form a composite key in an order details table.


2)DB Normalization
DB Normalization (Short Version)
Database normalization organizes data to reduce redundancy and improve integrity through normal forms (NF):
    First Normal Form (1NF)
        The simplest level of normalization, which ensures that each table has a primary key and each column has atomic values. 
        A single cell cannot contain multiple values like "Red, Blue." Split them into separate rows.
    Second Normal Form (2NF)
        Must be in 1NF.
        Eliminates partial dependencies by ensuring that non-key attributes depend only on the primary key. 
        What this means, in essence, is that there should be a direct relationship between each column and the primary key, 
        and not between other columns.
    Third Normal Form (3NF): 
        Remove transitive dependency (non-key columns should not depend on other non-key columns).
        3NF builds on 2NF by requiring that all non-key attributes are independent of each other. 
        This means that each column should be directly related to the primary key, and not to any other columns in the same table.
        If column A depends on column B, and B depends on the primary key, move A to another table.
    Boyce-Codd Normal Form (BCNF)
        This is a more strict version of 3NF that addresses additional anomalies. 
        At this normalization level, every determinant is a candidate key.
    Fourth Normal Form (4NF)
        This is a normalization level that builds on BCNF by dealing with multi-valued dependencies.
    Fifth Normal Form (5NF)
        5NF is the highest normalization level that addresses join dependencies. 
        It is used in specific scenarios to further minimize redundancy by breaking a table into smaller tables.


3) ACID Properties
ACID ensures database transactions are processed reliably:
    Atomicity: All operations in a transaction are completed; if one fails, the entire transaction is rolled back.
    Consistency: Transactions bring the database from one valid state to another, maintaining integrity.
    Isolation: Transactions are executed independently, without interference from others.
    Durability: Once a transaction is committed, its changes are permanent, even in the event of a system failure.



4) DDL, DML Query, Query Optimization, Database Indexing
    DDL (Data Definition Language):
        Defines and manages database structures.
        Examples: CREATE, ALTER, DROP.

    DML (Data Manipulation Language):
        Manipulates data within tables.
        Examples: SELECT, INSERT, UPDATE, DELETE.

    Query Optimization:
    Improves query performance by choosing the most efficient execution plan.

    Techniques: Indexing, caching, and query rewriting.
        Database Indexing:
        Speeds up data retrieval by creating a structured reference to table data.
        Types: B-tree, Hash, and Full-text indexes.




5) Joins, Aggregation, Group By, Having, where, and IN clause, SELECT statement best practices, 
Primary Key, Foreign Key, Unique Key.
Ans:
    Joins:
    Combine data from two or more tables based on a related column.
    Types: INNER JOIN, LEFT JOIN, RIGHT JOIN, FULL JOIN.

    Aggregation:
    Perform calculations on a set of values to return a single result.
    Examples: SUM(), AVG(), COUNT(), MIN(), MAX().

    Group By:
    Groups rows that have the same values in specified columns.
    Used with aggregation functions.

    Having:
    Filters groups after GROUP BY (like WHERE, but for aggregated results).

    WHERE:
    Filters records before any grouping or aggregation.
    Used for condition checks on individual rows.

    IN Clause:
    Checks if a value is within a set of specified values.
    Example: WHERE column IN (1, 2, 3).

    SELECT Statement Best Practices:
    Use specific column names instead of SELECT *.
    Use LIMIT to control the result size.
    Avoid unnecessary complex subqueries.

    Primary Key:
    A unique identifier for a table, cannot be NULL.

    Foreign Key:
    A column that links to the primary key of another table, ensuring referential integrity.

    Unique Key:
    Ensures all values in a column (or set of columns) are unique, but allows NULL values.


6) What is JPA and Hibernate ? JPA - Enity Life Cycle ? ID Generation Strategies?
Ans:
    JPA (Java Persistence API):
    A specification for managing relational data in Java applications. 
    It defines how Java objects can be persisted into a relational database.

    Hibernate:
    An open-source ORM (Object-Relational Mapping) framework that implements JPA and simplifies database interaction 
    by mapping Java objects to database tables.

    JPA - Entity Life Cycle:
    The lifecycle of an entity in JPA includes the following stages:
        New/Transient: Entity is created but not yet persisted.
        Managed: Entity is persisted and tracked by the EntityManager.
        Detached: Entity is no longer managed but still has data.
        Removed: Entity is marked for deletion.

    ID Generation Strategies:
        AUTO: Let the JPA provider choose the strategy (e.g., Hibernate uses IDENTITY or SEQUENCE).
        IDENTITY: Database auto-generates the ID (e.g., AUTO_INCREMENT in MySQL).
        SEQUENCE: Uses a database sequence to generate IDs (e.g., Oracle).
        TABLE: Uses a special table to generate IDs.



7) EntityManager vs EntityManagerFactory
    EntityManager:
        Manages the lifecycle of entities, handles CRUD operations, and queries against the database. 
        It's used for interacting with the persistence context.

    EntityManagerFactory:
        Creates EntityManager instances. It's a heavyweight, thread-safe object used to set up the persistence context 
        and is typically created once per application.

Entity Relationship - One to One, One to Many, Many To Many, ORM relationship best practices
Ans:
    Entity Relationships:
    One to One:
    One entity is related to exactly one other entity.
    Example: Person has one Passport.

    One to Many:
    One entity is related to multiple entities.
    Example: Department has many Employees.

    Many to Many:
    Multiple entities are related to multiple other entities.
    Example: Student can enroll in many Courses, and each Course can have many Students.

ORM Relationship Best Practices:
    Use @OneToOne, @OneToMany, @ManyToMany annotations correctly.
    Fetch Strategy: Choose between Lazy or Eager loading based on use case (e.g., avoid Eager loading in large datasets).
    Avoid N+1 Problem: Use JOIN FETCH to optimize queries in One to Many and Many to Many.
    Cascade Operations: Use cascade types (PERSIST, MERGE, REMOVE) judiciously to propagate changes to related entities.


8) JPA Cascading Type, JPA Fetching Strategy 
Cascading allows related entities to be automatically persisted or deleted when the parent entity is persisted or deleted. 
Common cascade types are:
    PERSIST: Cascade the persist operation to related entities.
    MERGE: Cascade the merge operation to related entities.
    REMOVE: Cascade the remove operation to related entities.
    REFRESH: Cascade the refresh operation to related entities.
    DETACH: Cascade the detach operation to related entities.
    ALL: Apply all cascade operations (PERSIST, MERGE, REMOVE, etc.).


9) JPA Fetching Strategy:
JPA defines two main fetching strategies for loading associated entities:

Lazy Loading:
        The associated entity is loaded only when it is accessed. 
        This is the default for most relationships (@OneToMany, @ManyToMany).
        @OneToMany(fetch = FetchType.LAZY)
        private Set<Order> orders;


Eager Loading:
    The associated entity is loaded immediately along with the parent entity. This can be specified with FetchType.EAGER.
    @OneToMany(fetch = FetchType.EAGER)
    private Set<Order> orders;

Lazy loading is generally preferred for performance, especially with large datasets, but be mindful of the N+1 query problem.
Use Eager loading only when you need the related data immediately.




10) JPA Annotations - @Embeddable, @Embedded, @EmbeddedId, @Transient, @Lob, @Basic, @Cacheable
Ans:
    @Embeddable:
    Marks a class whose instances can be embedded in other entities as part of their state.

    @Embedded:
    Defines an embedded object, typically used with @Embeddable class to include its fields in the parent entity.

    @EmbeddedId:
    Defines a composite primary key as an embedded object, typically a class with @Embeddable.

    @Transient:
    Marks a field to be ignored by JPA (not persisted in the database).

    @Lob:
    Marks a field to be treated as a large object (e.g., BLOB or CLOB), used for storing large data like images or text.

    @Basic:
    Specifies the default fetch strategy (LAZY or EAGER) and whether the field is required to be persisted.

    @Cacheable:
    Marks an entity as eligible for caching to improve performance by storing query results in the cache.


11) Spring Data JPA - @Query, @Modify,Specifications, Query Creation from Method Names
@Query:
Used to define custom JPQL (Java Persistence Query Language) or SQL queries for repository methods.
Example:
    @Query("SELECT e FROM Employee e WHERE e.salary > ?1")
    List<Employee> findEmployeesWithSalaryGreaterThan(double salary);

@Modifying:
Marks a method that modifies the database (e.g., UPDATE, DELETE). 
It should be used with @Query for operations that change the database state.
Example:
    @Modifying
    @Query("UPDATE Employee e SET e.salary = :salary WHERE e.id = :id")
    int updateEmployeeSalary(@Param("salary") double salary, @Param("id") Long id);

Specifications:
Provides a way to create dynamic queries using the Specification interface, allowing complex queries with conditions.


12) uery Creation from Method Names:
Spring Data JPA can automatically generate queries based on method names.
Example:
    List<Employee> findByLastName(String lastName);
    List<Employee> findBySalaryGreaterThan(double salary);
    Spring Data JPA interprets these method names to generate the corresponding SQL queries.


13) Spring Data JPA - Accessing EntityManager,  Multitenancy
        Spring Data JPA - Accessing EntityManager:
        EntityManager is used to interact with the persistence context. 
        In Spring, it's typically injected into repositories or services using @PersistenceContext.
        Example:
            @PersistenceContext
            private EntityManager entityManager;

Multitenancy:
    Multitenancy in Spring Data JPA allows a single application to support multiple tenants (e.g., customers or clients), 
    each with its own data.
        Single Database: Tenants share the same database but with separate schemas or tables.
        Separate Databases: Each tenant has its own database. Spring can be configured to manage this through 
        a custom DataSource and tenant identifier strategy.



14) JPA - Locking: Optimistic and Pessimistic Lock
Optimistic Locking:
    Assumes no conflicts. It uses a version field to check if the entity has been changed by another transaction.
    Example:
    @Version
    private Long version;
        How It Works:
        A version field (annotated with @Version) is used to track the state of an entity.
        When a transaction reads an entity, it retrieves the current version number.
        Before committing an update, JPA compares the current version in the database with the version originally read.
        If they match, the update proceeds, and the version is incremented. If not, a OptimisticLockException is thrown.

Pessimistic Locking:
    Locks the entity to prevent other transactions from changing it while the current transaction is ongoing.
    Example:
    @Lock(LockModeType.PESSIMISTIC_WRITE)
    Employee findByIdWithLock(Long id);
    Locks are acquired directly in the database when the entity is accessed.
    Other transactions attempting to access the locked entity will be blocked or fail, depending on the lock type.
        Lock types:
        PESSIMISTIC_READ: Prevents updates but allows reads.
        PESSIMISTIC_WRITE: Prevents both reads and updates.
        PESSIMISTIC_FORCE_INCREMENT: Similar to PESSIMISTIC_WRITE but also increments the version field.

Use Optimistic Locking where conflicts are rare, and the application can handle retries on failures.
Use Pessimistic Locking for critical operations where conflicts are expected and must be avoided.





15) JPA - First Level and Second Level Caching
First Level Cache:
    Built-in, automatic cache in the EntityManager for the current session.
    Stores entities that are retrieved or persisted during a session.
    Only available within the same session or transaction.

Second Level Cache:
    Cache shared across sessions, typically managed by a cache provider (e.g., Ehcache, Hazelcast).
    Stores entities that are frequently accessed and not modified often, improving performance across multiple sessions.
    Can be configured and used for specific entities.


17) JPA Auditing, JPA Listeners, JPQL, HQL, N+1 problem in ORM
Ans:
JPA Auditing:
    Automatically tracks entity changes like creation and modification times.
    Example:
    @CreatedDate
    private LocalDateTime createdDate;
JPA Listeners:
    Allows executing logic before or after entity operations (e.g., insert, update).
    Example:
    @EntityListeners(AuditingEntityListener.class)
    public class Employee { ... }


18) JPQL (Java Persistence Query Language):
A query language similar to SQL but operates on entity objects, not database tables.
Example:
SELECT e FROM Employee e WHERE e.salary > 50000


19) HQL (Hibernate Query Language):
        Similar to JPQL but specific to Hibernate, it also works with entity objects.

N+1 Problem in ORM:
    Occurs when multiple database queries are executed unnecessarily, especially when loading related entities.
    Solution: Use JOIN FETCH or Eager loading to optimize.

The N+1 problem occurs when an ORM (like Hibernate, JPA) makes one query for the main entity (1 query) and then 
N additional queries for related entities (N queries), leading to (N+1) queries instead of 1 optimized query.

How to fixed this issue and Best Practice: Use JOIN FETCH for immediate fixes, @BatchSize for batching, 
and @EntityGraph for flexible fetching!


20) Writing Native Query in Spring Data Jpa
Ans:
    Writing Native Query in Spring Data JPA:
    Native queries are SQL queries directly executed on the database. They are defined using @Query with nativeQuery = true.

Example:
    @Query(value = "SELECT * FROM employee WHERE salary > ?1", nativeQuery = true)
    List<Employee> findEmployeesWithSalaryGreaterThan(double salary);
    nativeQuery = true tells Spring Data JPA to treat the query as native SQL.
    Can be used for complex queries not easily expressed in JPQL


21) Different Transaction Isloation, Different Read Phenomenon
Transaction Isolation Levels:
    READ UNCOMMITTED:
    Allows dirty reads (reading uncommitted data).
    READ COMMITTED:
    Prevents dirty reads, but allows non-repeatable reads.
    REPEATABLE READ:
    Prevents dirty and non-repeatable reads, but allows phantom reads.
    SERIALIZABLE:
    Prevents dirty, non-repeatable, and phantom reads by fully isolating transactions.

Read Phenomena:
    Dirty Read:
    Reading data that is not yet committed (can change if the transaction is rolled back).

    Non-repeatable Read:
    A value is read, but it changes when read again within the same transaction.

    Phantom Read:
    New rows are added or removed between reads, causing inconsistent results.

Serializable:
    Description: The highest level of isolation, ensuring complete consistency by serializing transactions as if they were executed one after another.
    Phenomena Allowed: None (no Dirty Reads, Non-Repeatable Reads, or Phantom Reads).
    How It Works:
    Locks the entire range of data accessed to prevent updates, inserts, or deletes by others.
    Use Case: Applications requiring absolute consistency, such as financial systems.



Best Practices:
    Choose the isolation level based on requirements:
    Use Read Committed for general applications where consistency is needed but concurrency is high.
    Use Repeatable Read or Serializable for critical transactions requiring high consistency.
    Minimize transaction duration to reduce locking contention.

Consider database vendor implementations:
    Some databases (e.g., PostgreSQL, Oracle) implement higher isolation levels (like Serializable) using MVCC, 
    reducing locking overhead.





22) Result Transformation to DTO, Data JPA Projections

Result Transformation to DTO:
In JPA, the process of converting query results into a Data Transfer Object (DTO) is called result transformation. 
This is often done using constructor expressions or custom queries to retrieve specific data.
Example:
@Query("SELECT new com.example.dto.EmployeeDTO(e.id, e.name) FROM Employee e WHERE e.salary > :salary")
List<EmployeeDTO> findEmployeesWithSalaryGreaterThan(@Param("salary") double salary);

JPA Projections:
Projections in JPA allow retrieving specific columns (fields) of an entity or a DTO rather than the full entity. 

There are two types:
    Interface-based Projections: Using interfaces to define getter methods for selected fields. Example:
    public interface EmployeeProjection {
        String getName();
        double getSalary();
    }
    Class-based Projections: Using DTO classes to map the result.
Both techniques help improve performance by fetching only necessary data.



23) JPA/Hibernate Exceptions - LazyInitializationException, NonUniqueResultException, SQLGrammarException, 
OptimisticLockException, PersistentObjectException: Detached Entity Passed to Persist, DataAccessException.
Ans:
    LazyInitializationException:
    Occurs when an uninitialized lazy-loaded association is accessed outside the session context.

    NonUniqueResultException:
    Thrown when a query that expects a single result returns more than one.

    SQLGrammarException:
    Happens when there is a syntax error in the SQL query (e.g., invalid SQL).

    OptimisticLockException:
    Triggered when an optimistic lock conflict occurs (version mismatch while updating).

    PersistentObjectException: Detached Entity Passed to Persist:
    Occurs when a detached entity is passed to persist(), which should be merged instead.

    DataAccessException:
    A generic exception indicating issues with data access operations, often related to Spring's DAO layer.


24) Handling money in database
    Data Type:
    Use DECIMAL or NUMERIC for precision.
    Example: DECIMAL(10, 2) for two decimal places.

    Precision & Scale:
    Define total digits (precision) and digits after the decimal (scale).

    Currency Representation:
    Store currency code separately (e.g., currency_code CHAR(3)).

    Avoid Floating-Point:
    Use DECIMAL to prevent rounding issues.

    Calculations:
    Perform calculations in the app or DB, ensuring proper rounding.

    Currency Conversion:
    Use a separate table for exchange rates when handling multiple currencies.





##7	
Version Control	What is git ?
=============================================
What is Git?
A distributed version control system for tracking changes in code.
GitLab,GitHub: A web-based DevOps platform with Git repository hosting.
Both GitLab and GitHub are built around Git but add features for collaboration, automation, and deployment.

Git Branching Strategies:
Approaches for managing branches, like Git Flow or GitHub Flow.

Git Merging and Rebase
    Merge: Combines branches while preserving history.
    Rebase: Applies changes from one branch onto another, rewriting history.

"Git rebase" is a Git command that allows you to "reapply" a series of commits from one branch onto another.
Exmaple:
 Current History:
    A---B---C  (main)
         \
          D---E (feature)

Rebasing feature onto main:
git checkout feature
git rebase main
Result:
    A---B---C---D'---E'  (feature)

Comparison with Rebase:
    git merge (pull)	Maintains branch history with a merge commit.
    git rebase	Creates a linear history by replaying commits.


Git Merging Conflict Resolution
Resolving conflicts when changes in branches contradict.

Git Cherry-pick
git cherry-pick is a Git command that allows you to apply a specific commit from one branch to another branch, without merging the entire branch. 
Why Use git cherry-pick?
    To bring specific bug fixes or features into another branch without merging unrelated changes.
    To apply a commit to multiple branches (e.g., apply a hotfix to both the main branch and a release branch).
Example Scenario:
    A---B---C   (main)
         \
          D---E---F   (feature)

Let‚Äôs say commit E in the feature branch fixes a bug that you want to include in main.
Cherry-pick Commit
You can cherry-pick commit E into main like this:
# Switch to the main branch
git checkout main

# Cherry-pick the commit
git cherry-pick <commit-hash>
Replace <commit-hash> with the hash of commit E. You can find this using git log.

Resulting History
After the cherry-pick, the commit from feature is applied to main, creating a new commit with the same changes:
    A---B---C---E'   (main)
         \
          D---E---F   (feature)


Note: The cherry-picked commit (E') will have a different hash than the original commit (E) because it is applied in a different branch.



Git Tag and Stash
Tag: Marks specific commits, often for releases.
Stash: Temporarily saves changes to work on something else.

Different Git Commands
Common commands: git clone, git pull, git commit, git push, git status, git log.

What is Git HEAD Reset?
git reset changes the HEAD to point to a different commit, either keeping or discarding changes.
Types of Git Reset:
--soft: Moves HEAD to a different commit but keeps changes staged.
--mixed (default): Moves HEAD and un-stages changes (but keeps them in the working directory).
--hard: Moves HEAD, un-stages, and discards all changes in the working directory.







##8
Software Engineering	
=======================================================================
1) SOLID Principle, DRY, YAGNI, KISS
SOLID:
A set of five design principles for creating maintainable and scalable software:
    S: Single Responsibility Principle
    O: Open/Closed Principle
    L: Liskov Substitution Principle
    I: Interface Segregation Principle
    D: Dependency Inversion Principle

    1. Single Responsibility Principle (SRP)
    Definition: A class should have only one reason to change.
    Focus: Each class should handle one specific responsibility.
    Example:
    Bad: A User class handles authentication and database operations.
    Good: Separate UserAuth for authentication and UserRepo for database operations.

    2. Open/Closed Principle (OCP)
    Definition: Software entities (classes, modules, functions) should be open for extension but closed for modification.
    Focus: Add new functionality without altering existing code.
    Example:
    Use interfaces or abstract classes to allow new behaviors without changing existing ones.

    3. Liskov Substitution Principle (LSP)
    Definition: Objects of a superclass should be replaceable with objects of its subclasses without altering the correctness of the program.
    Focus: Subclasses must honor the behavior expected from the base class.
    Example:
    Bad: A subclass overrides a method and throws an exception, violating expectations.
    Good: A subclass provides the same or enhanced functionality.

    4. Interface Segregation Principle (ISP)
    Definition: A class should not be forced to implement interfaces it does not use.
    Focus: Break large interfaces into smaller, specific ones.
    Example:
    Bad: A Printer interface with methods for scan() and fax() that a basic printer doesn't need.
    Good: Separate Scanner and Fax interfaces.

    5. Dependency Inversion Principle (DIP)
    Definition: High-level modules should not depend on low-level modules; both should depend on abstractions.
    Focus: Rely on abstractions, not concrete implementations.
    Example:
    Use dependency injection to supply dependencies rather than instantiating them directly.


DRY (Don‚Äôt Repeat Yourself):
    Avoid code duplication by reusing logic and abstractions.

YAGNI (You Aren‚Äôt Gonna Need It):
    Don‚Äôt implement functionality until it is necessary.

KISS (Keep It Simple, Stupid):
    Simplify solutions to avoid unnecessary complexity.



2) SDLC Life Cycle , Hexagonal Architecture
SDLC Life Cycle:
The Software Development Life Cycle (SDLC) outlines the stages in developing software:
    Planning: Define project scope and objectives.
    Design: Architecture and system design.
    Development: Coding and implementation.
    Testing: Verify functionality and fix bugs.
    Deployment: Release to production.
    Maintenance: Ongoing updates and bug fixes.

Hexagonal Architecture:
    A design pattern focusing on isolating the core logic of an application from external systems 
    (e.g., databases, APIs) through interfaces or ports, ensuring flexibility and testability.
    Core logic interacts with external systems via Adapters.


3) Coupling vs Cohesion
Coupling:
    Refers to the degree of dependence between different modules or classes.
    Low coupling is preferred for easier maintenance and flexibility (modules should be independent).

Cohesion:
    Refers to how closely related the responsibilities of a single module or class are.
    High cohesion is preferred, meaning a class should have related functions that belong together.


4) Composition vs Association, IS-A vs HAS-A relationship

Composition vs Association:
    Composition:
    A strong "has-a" relationship where one object owns or contains another.
    Example: A Car has Engine (if the car is destroyed, the engine is too).

    Association:
    A weaker relationship where objects are related but don‚Äôt own each other.
    Example: Teacher and Student (a teacher can have many students, but students exist independently).

IS-A vs HAS-A Relationship:
    IS-A:
    Inheritance relationship where one class is a subtype of another.
    Example: Dog IS-A Animal.

    HAS-A:
    Represents a relationship where one class has an object of another class.
    Example: Car HAS-A Engine.


5) Design Patterns - Proxy, Observer, Adapter, Singletone, Factory
Ans:
Proxy:
Provides a surrogate or placeholder for another object, controlling access to it.
Example: A Proxy for a remote service.

Observer:
Defines a one-to-many dependency where one object (subject) notifies others (observers) of changes.
Example: A Subject notifying multiple Observers of an event.

Adapter:
Converts one interface to another, making incompatible interfaces compatible.
Example: Adapter converting a legacy system‚Äôs interface to work with a modern one.

Singleton:
Ensures a class has only one instance and provides a global point of access to it.
Example: A Logger class that is shared across the application.

Factory:
Creates objects without specifying the exact class of object to be created.
Example: A Factory for creating different types of Product objects.


6) Waterfall Model, Agile Model
Waterfall Model:
    A linear and sequential software development process.
    Each phase must be completed before moving to the next.
    Best for projects with well-defined requirements.

Agile Model:
    An iterative and flexible approach to software development.
    Divides the project into small, manageable parts (sprints).
    Emphasizes collaboration, customer feedback, and adapting to change.

7) Software Testing - Unit Testing vs Integration Testing, Code Review Process
    Unit Testing:
    Tests individual components or functions in isolation.
    Ensures the correctness of small, specific parts of the code.

    Integration Testing:
    Tests how different modules or systems work together.
    Ensures that combined components function correctly.

    Code Review Process:
    A practice where developers review each other's code for errors, improvements, and adherence to standards.
    Helps catch issues early, improve code quality, and ensure consistency.





##9
Basic Linux	Understanding Linux OS
============================================================
1) Understanding Command Line
SH (Shell):
    A shell is a command-line interface that allows users to interact with the operating system by typing commands.
    SH specifically refers to the Bourne Shell (/bin/sh), which was one of the first Unix shells. 
    It's basic and was the default shell on many Unix-like systems.

Bash (Bourne Again Shell):
    Bash is an enhanced version of the Bourne Shell and stands for "Bourne Again Shell".
    It includes additional features like command history, job control, improved scripting capabilities, 
    and more user-friendly options.
    Bash is the default shell on most Linux distributions and macOS (before macOS Catalina).

Key Differences:
    Bash has more features and improvements than sh, such as command-line editing, job control, and arrays.
    SH is more minimalist and compatible with older systems, whereas Bash is more feature-rich and modern.


2) Understanding File System
Linux File System/Directory:

Root Directory (/):
The top-level directory in the Linux file system.

Home Directory (/home/username):
User-specific directories where personal files and settings are stored.

Bin Directory (/bin):
Contains essential system binary executables (e.g., ls, cp).

Etc Directory (/etc):
Contains system configuration files.

 /opt directory in Linux is used for optional, third-party, or manually installed software that is not part of the default system packages.

Var Directory (/var):
Stores variable files, such as logs and databases.

Usr Directory (/usr):
Contains user programs, libraries, and documentation.

Dev Directory (/dev):
Contains device files for hardware like hard drives and terminals.

Tmp Directory (/tmp):
Stores temporary files created by applications


3) Package Management Basic
Package Manager:
A tool used to install, update, and remove software packages in Linux.

Common Package Managers:
APT (Debian/Ubuntu): sudo apt install <package>, sudo apt update, sudo apt remove <package>
YUM/DNF (Red Hat/CentOS/Fedora): sudo yum install <package>, sudo yum update, sudo yum remove <package>
Pacman (Arch Linux): sudo pacman -S <package>, sudo pacman -R <package>

Package Formats:
    .deb (Debian/Ubuntu)
    .rpm (Red Hat/CentOS/Fedora)

Repositories:
    Centralized storage of software packages that can be accessed by the package manager to install software.

Updating Packages:
    sudo apt upgrade (APT)
    sudo yum update (YUM/DNF)
    sudo pacman -Syu (Pacman)

Searching for Packages:
    apt search <package> (APT)
    yum search <package> (YUM)
    pacman -Ss <package> (Pacman)


4) Shell Scripting Introduction

Shell Scripting:
A way to automate tasks in Linux/Unix using commands written in a script file.

Basic Syntax:

A shell script typically starts with a "shebang" (#!/bin/bash) indicating the shell to use.
Commands are written as you would type them in the terminal.
Variables:
Variables store data: name="John"
Access variables with $: echo $name

Control Flow:
If statements: if [ condition ]; then ... fi

Loops: for, while loops to repeat actions.

Functions:
Define reusable code:
myfunc() { echo "Hello"; }


File Permissions:
Make scripts executable: chmod +x script.sh
Run scripts: ./script.sh

Redirection & Piping:
Redirect output to a file: echo "Hello" > file.txt
Pipe commands together: cat file.txt | grep "word"

Common Use Cases:
Automating backups, managing system tasks, processing files, and batch jobs.


5) CLI Tools & Commands - ps, top, htop, kill, netstat, nc, nmap, tcpdump, iftop, telnet, ping, vim, nano, tail, lsof, iotop, iostat
Ans

ps:
Displays current running processes.
Example: ps aux

top:
Shows system processes and resource usage in real-time.
Example: top

htop:
An enhanced, interactive version of top for process monitoring.
Example: htop

kill:
Sends a signal to terminate processes.
Example: kill <PID>

netstat:
Displays network connections, routing tables, and interface statistics.
Example: netstat -tuln

nc (Netcat):
Used for network communication (sending/receiving data).
Example: nc <hostname> <port>

nmap:
A network scanning tool to discover hosts and services.
Example: nmap <IP>

tcpdump:
Captures network traffic for analysis.
Example: tcpdump -i eth0

iftop:
Displays real-time network bandwidth usage by host.
Example: iftop

telnet:
Used for remote communication with a server.
Example: telnet <hostname>

ping:
Tests network connectivity by sending ICMP packets.
Example: ping <hostname/IP>

vim:
A powerful text editor for editing files.
Example: vim file.txt

nano:
A simple text editor for easy file editing.
Example: nano file.txt

tail:
Displays the last few lines of a file (useful for logs).
Example: tail -f /var/log/syslog

lsof
Lists open files and associated processes.
Example: lsof

iotop:
Displays real-time I/O usage by processes.
Example: iotop

iostat:
Provides statistics about CPU and I/O devices.
Example: iostat


6) SSH - Accessing Remote Server, Linux VPN, Linux Firewall, and Port Forwarding
Linux SSH - Accessing Remote Server:
    SSH (Secure Shell): A protocol used to securely access remote servers.
    Command: ssh username@hostname_or_ip
    Example: ssh user@192.168.1.10
    Key-based Authentication: Use SSH keys for secure and password-less login.

Linux VPN:
    A VPN (Virtual Private Network) allows secure connections to remote networks over the internet.
    Tools: OpenVPN, WireGuard, strongSwan for creating VPNs on Linux.
    Command for connecting to OpenVPN: sudo openvpn --config /path/to/config.ovpn

Linux Firewall:
    iptables and firewalld are common Linux firewall tools for managing network traffic.

Basic Commands:
    iptables -L: List current rules.
    firewalld: sudo firewall-cmd --zone=public --add-port=80/tcp --permanent

Port Forwarding:
    Redirect network traffic from one port to another, often used for accessing internal services.

Example with iptables:
    sudo iptables -t nat -A PREROUTING -p tcp --dport 8080 -j REDIRECT --to-port 80
    This forwards traffic from port 8080 to port 80.






##10
Distributed System	Communication
==============================================================================
1) Different Types of Communication Pattern
A distributed system consists of multiple interconnected components that communicate over a network to achieve a common goal. 
Communication between these components is vital for the system's functionality. 
There are several types of communication patterns in distributed systems:
    Request-Reply: A component sends a request to another, which processes it and replies with a response.
    Publish-Subscribe: Components (publishers) send messages to a topic or channel, and interested subscribers 
                       receive those messages asynchronously.
    Message Queues: A producer sends messages to a queue, and a consumer reads and processes them at its own pace.
    Broadcast: A message is sent to all components in the network, and all of them process the message.
    Peer-to-Peer: Each component in the system can act as both a client and a server, allowing direct communication between peers.
    Client-Server: A centralized server provides services to multiple clients, and clients interact with the server for 
    data or services.
    Each pattern addresses specific needs, such as reliability, scalability, and fault tolerance, in a distributed environment.


2) Service Discovery, Client Side Loadbalancing
Ans:
Microservices Service Discovery is the process by which microservices dynamically find and interact with 
each other in a distributed environment. 
Instead of hardcoding service locations, a Service Registry (e.g., Consul, Eureka) keeps track of available 
services and their instances. Microservices can query the registry to discover other services.

Client-Side Load Balancing means the client (e.g., a microservice) is responsible for choosing which instance of 
a service to send requests to. 
It uses the list of available service instances from the service registry and applies 
load-balancing algorithms (e.g., round-robin, random) to distribute requests evenly. 
This reduces the need for an external load balancer and can improve performance.


3) Cordination & Synchronization:
Ans:
    Coordination in distributed systems refers to managing interactions between different components or services 
    to ensure they work together effectively. 
    It ensures tasks are performed in a specific order and that the system functions as a whole.

    Synchronization is the process of ensuring that multiple components or threads operate in a timely and consistent manner, 
    preventing race conditions and conflicts. 


4) Scalability, High Availability, Resiliency, Common Failure, Upstream and Downstream Resiliency
Ans:
    Scalability: The ability of a system to handle increased load by adding resources (e.g., servers or instances) 
    without compromising performance.

    High Availability: Ensuring a system remains operational and accessible even during failures, 
    typically through redundancy and failover mechanisms.

    Resiliency: The ability of a system to recover from failures or disruptions, maintaining functionality and minimizing downtime.

    Common Failure: A failure that affects multiple components of a system simultaneously, 
    often due to shared dependencies or architecture flaws.

    Upstream Resiliency: The ability to handle failures or slowdowns from upstream services 
    (e.g., databases or external APIs) without impacting the system's performance.

    Downstream Resiliency: Ensuring that downstream services 
    (e.g., dependent microservices) can continue operating despite failures or issues in the system.


5) Event Driven Architecture, Microservice Architecture:
Ans:
    Event-Driven Architecture: A design pattern where components communicate by producing and consuming events 
    (messages) asynchronously. 
    Events trigger actions or workflows in the system, enabling loose coupling between components and better scalability.

    Microservice Architecture: A software design style where an application is composed of small, 
        independently deployable services, each responsible for a specific business function. 
        These services communicate over lightweight protocols (e.g., HTTP or messaging) and can be developed, 
        deployed, and scaled independently.

Data Management in Microservice
Ans:
    Data Management in Microservices involves handling data across independently deployed services, 
    ensuring consistency and scalability. 
    Key practices include:
        Database per Service: Each microservice owns its database to maintain autonomy and avoid tight coupling.
        Data Replication: Sharing relevant data across services to reduce dependencies and improve performance.
        Event-Driven Communication: Using events to propagate changes, ensuring eventual consistency.
        Saga Pattern: Managing distributed transactions through a sequence of compensating actions.
        API Queries: Aggregating data across services using APIs or patterns like CQRS (Command Query Responsibility Segregation).
        Caching: Improving performance by reducing repeated database calls with caching layers.
        Proper design minimizes data silos and ensures resilience and scalability.


6) CAP Theorem, PACLEC Theorem
Ans:
CAP Theorem: In distributed systems, it's impossible to achieve all three simultaneously:
    Consistency (C): All nodes see the same data at the same time.
    Availability (A): Every request receives a response, even during failures.
    Partition Tolerance (P): The system continues to operate despite network partitions. Systems must choose two out of the three.

PACELC Theorem: Extends CAP by addressing trade-offs during normal operations:
    If Partition (P): Trade-off between Availability (A) and Consistency (C).
    Else (E): Trade-off between Latency (L) and Consistency (C) in the absence of partitions.


7) Distributed Transaction, Transaction Outbox Pattern
Distributed Transaction: A transaction that spans multiple services or databases, ensuring consistency across them. 
    It often uses patterns like Two-Phase Commit (2PC) or Saga for coordination.

Transaction Outbox Pattern: Ensures reliable event publishing in distributed systems by:
        Writing the event to an "outbox" table within the same database transaction as the business data.
        A separate process asynchronously reads and publishes these events, ensuring consistency without distributed transactions.


8) SAGA Pattern, CQRS
Ans:
SAGA Pattern: A design for managing distributed transactions by breaking them into a series of smaller, 
independent steps (local transactions) coordinated via events or orchestration. 
It ensures consistency through compensating actions if a step fails.

CQRS (Command Query Responsibility Segregation): A pattern that separates write operations (commands) 
from read operations (queries), often using different models or databases for each, to improve scalability and performance.

Leader Election - Paxos, Raft:
    Paxos: A consensus algorithm for distributed systems that ensures agreement on a single value even with failures. 
    It operates through a series of proposals, promises, and acceptances to elect a leader or decide on a value.

    Raft: A simpler consensus algorithm designed for understandability. 
    It achieves leader election and log replication by electing a single leader who manages decisions, 
    ensuring consistency across nodes.


9) Data Replication - Single Leader Replication, Multi Leader Replication, Leaderless Replication
Ans:
Single Leader Replication: One leader node handles all writes and propagates updates to follower nodes. 
Ensures strong consistency but may face bottlenecks at the leader.

Multi-Leader Replication: Multiple leaders accept writes and synchronize updates across nodes. 
Offers better write availability but risks conflicts that need resolution.

Leaderless Replication: No designated leader; all nodes can accept writes. 
Uses quorum-based reads and writes to ensure eventual consistency (e.g., DynamoDB, Cassandra).


10) Maintainability - Testing, CI/CD, Monitoring, Osbservability
ans:
    Testing: Ensures code quality and functionality through unit, integration, and end-to-end tests.
    CI/CD: Automates code integration, testing, and deployment to streamline updates and reduce errors.
    Monitoring: Tracks system health, performance, and failures using tools like Prometheus and Grafana.
    Observability: Provides insights into system behavior with logs, metrics, and traces to debug and optimize effectively.


11) Casual Consistency, Eventual Consistency, API Idempotency
Ans:
    Causal Consistency: Ensures that operations with a cause-effect relationship are seen in the correct order by all nodes.

    Eventual Consistency: Guarantees that all nodes will converge to the same data state over time, given no new updates occur.

    API Idempotency: Ensures that repeated identical requests produce the same effect, 
    avoiding unintended side effects (e.g., retrying a payment should not result in multiple charges).







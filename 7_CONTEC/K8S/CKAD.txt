#################################################
#              CKAD                             #
#################################################

Certified Kubernetes Application Developer: https://www.cncf.io/certification/ckad/
Candidate Handbook: https://www.cncf.io/certification/candidate-handbook
Exam Tips: https://docs.linuxfoundation.org/tc-docs/certification/tips-cka-and-ckad
https://www.youtube.com/watch?v=wtKef83kmUA&list=PL0hSJrxggIQoKLETBSmgbbvE4FO_eEgoB

https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad-cks
FAQ

lAB
https://kodekloud.com/lessons/recap-core-concepts/



=>sudo apt-get update && apt-get install iputils-ping && sudo apt install net-tools
=================================================
#General                                
=================================================

=>kubectl explain pod
=>kubectl api-resources

=>kubectl version
=>kubectl version --short
=>kubectl get nodes

=>kubectl get pods
=>kubectl get pods -o wide
=>kubectl get -o json pod prodName

=kubectl logs myPod

=>kubectl run nginx --image=nginx --dry-run=client
=>kubectl run nginx --image=nginx --dry-run=client -o yaml
=>kubectl run myng --image=nginx --dry-run=client -o yaml>labelpod.yaml
=>kubectl create deployment --image=nginx nginx --dry-run=client -o yaml

=>kubectl run mynginx --image=nginx
=>kubectl run  bu1 --image=busybox -- sh  -c "hostname -i"
=>kubectl run logpod --image=busybox -- sh -c "ping google.com"

=>kubectl run -it ubuntu1 --image=ubuntu --restart=Never -- bash -ec "apt update; apt install mysql-server; bash"
          =while true; do echo "infinity"; sleep 1; done

=>kubectl exec -it ub1 -- bash
=>kubectl exec -it mynginx -- bash
=>kubectl exec -it mynginx -- ls -l


=>kubectl apply -f sample.yaml
=>kubectl delete -f sample.yaml
=>kubectl delete pod my-pod1 

=>kubectl describe pod mynginx



=================================================
#D1:CoreConcept               
================================================= 
pod1:
apiVersion: v1
kind: Pod
metadata:
  name: my-webserver-pod
spec:
  containers:
    - name: mynginx
      image: nginx

pod2:
apiVersion: v1
kind: Pod
metadata:
  name: my-pod1
spec:
  containers:
    - name: mycont1
      image: busybox
      command: ["sleep","3360"]
   or args: ["3600"]
   or args: ["sleep","3360"]

pod3:
apiVersion: v1
kind: Pod
metadata:
  name: busybox
spec:
  containers:
  - name: busybox
    image: busybox
    command: ["/bin/sh"]

pod4:
apiVersion: v1 
kind: Pod 
metadata: 
  name: bu1 
spec: 
  containers: 
  - name: busybox 
    image: busybox 
    command: ["sh","-ec","ping google.com"] 

pod5:
apiVersion: v1
kind: Pod
metadata:
  name: ubuntu
spec:
  containers:
  - name: ubuntu
    image: ubuntu:latest
    # Just spin & wait forever
    command: [ "/bin/bash", "-c", "--" ]
    args: [ "while true; do sleep 30; done;"]


pod6:
kind: Pod
metadata:
  name: nginx-ports
spec:
  containers:
  - image: nginx
    name: nginx-ports
    ports:
    - containerPort: 80


=>kubectl apply -f myfile.yml
=>kubectl get pods
=>kubectl exec -it my-pod1 sh


#PracticeDomain1:
-----------------------------------------------------
Q1:
apiVersion: v1
kind: Pod
metadata:
  name: kplabs-nginx
spec:
  containers:
    - name: mycontainer
      image: nginx

Q2:
apiVersion: v1
kind: Pod
metadata:
  name: kplabs-cmdargs
spec:
  containers:
    - name: cmdcontainer
      image: busybox
      command: ["sleep"]
      args: ["3500"]

Q3:
apiVersion: v1
kind: Pod
metadata:
  name: kplabs-pods
spec:
  containers:
    - name: nginx
      image: nginx
      ports: 
      - containerPort: 80


Q4:
apiVersion: v1
kind: Pod
metadata:
  name: log-ng
spec:
  containers:
    - name: log-ngcont
      image: nginx
      args:
       - /bin/sh
       - -c
       - >
         i=0;
         while true;
         do
          echo "$i: $(date)" >> /var/log/1.log;
          echo "$(date) INFO $i" >> /var/log/2.log;
          i=$((i+1));
          sleep 1;
         done


=================================================
#D2:PodDesign               
================================================= 

#Label and Selectors:
-------------------------------------------------
=>kubectl label --help

=>kubectl run pod1 --image=nginx
=>kubectl get pods --show-labels
Show Labels

=>kubectl label pod pod1 env=prod
=>kubectl label  pods --all status=runing
Add Label

=>kubectl get pods -l env=prod
Filter by label

=>kubectl label pod pod2 env-
Delete label



#ReplicaSet:
-------------------------------------------------
=>kubectl create deployment myreplica --image=nginx --replicas 3 --dry-run=client -o yaml
Generate a deployment file and Update for ReplicaSet

=>kubectl get rs
=>kubectl get replicaset
=>kubectl apply -f rpset.yaml

=>kubectl describe replicaset myrpset

=>kubectl get pods --show-labels
=>kubectl delete rs myrpset


repliSet1:
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: myrpset
spec:
  replicas: 3
  selector:
    matchLabels:
      tier: myrpset
  template:
    metadata:
      labels:
        tier: myrpset
    spec:
      containers:
      - name: myngcont
        image: nginx



#Deployment:
-------------------------------------------------
=>kubectl create deployment --help

deployment1:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mydeployment
spec:
  replicas: 3
  selector:
    matchLabels:
      tier: myproj
  template:
    metadata:
      labels:
        tier: myproj
    spec:
      containers:
      - name: myng
        image: nginx


=>kubectl apply -f mydeploy.yaml
=>kubectl create deployment mydeployment --image=nginx --replicas 3
=>kubectl get deployment
=>kubectl describe deployment mydeployment

=>kubectl create deployment mydeployment --image=nginx --replicas 3 --dry-run=client -o yaml
Generate deployment yaml file

=>kubectl delete deployment mydeployment
Delete deployment


Edit yaml file for Update the deployment, like change the image version
then check the rollout history
=>kubectl rollout --help

=>kubectl rollout history deployment.v1.apps/mydeployment
=>kubectl rollout history deployment.v1.apps/mydeployment --revision 2
Get Rollout history and check revision details

=>kubectl get deployment my-dep -o yaml
=>kubectl describe deployment mydeployment
Check which revision version currently runing 

=>kubectl rollout history deployment.v1.apps/mydeployment
=>kubectl rollout undo deployment.v1.apps/mydeployment
=>kubectl rollout undo deployment.v1.apps/mydeployment --to-revision=2
=>kubectl describe deploy mydeployment
Deployment rolback



Form axSurge and maxUnavailable:
=>kubectl get deployment my-dep -o yaml
Check masSurge and maxUnavailable
=>kubectl create deployment mydeploy --images=nginx --replica 3


=>kubectl create deployment mydeploy --image=nginx --replicas 3
=>kubectl get deployment mydeploy -o yaml
Showo details info of deployemnt


=>kubectl set image deployment mydeploy nginx=httpd
Update  deployemnt
=>kubectl edit deployment mydeploy
=>kubectl get pods
Edit deoloyement



=>kubectl set image deployment mydeploy nginx=httpd
=>kubectl set image deployment mydeploy nginx=httpd --record
=>kubectl rollout history deployment mydeploy
=>kubectl rollout undo deployment/mydeploy
Roolout/Undo the deployemnt last deployment

=>kubectl scale deployment mydeploy --replicas 1
Scele up/down deployemnt


#InP
------------------------------------------------
1)How to set a new Image to deployment as part of rolling Update
2)Need to know --record Instruction
3)You should know how to rollback a deployment
4)you should be able to scale the deployment






#Batch Job:
-------------------------------------------------

Job are two type:
1)jobs (Run to completion)
2)CronJob

simpldJob:
apiVersion: batch/v1
kind: Job
metadata: 
  name: myjob
spec:
  template:
    spec:
      containers:
        - name: myjoncont
          image: busybox
          command: ["/bin/sh"]
          args: ["-c","echo Hello Imran"]
      restartPolicy: Never


=>kubectl apply -f myjob.yml
=>kubectl logs myjob-qd2jr 
After complate the job task pod are not exit, stay with complate Status.

=>kubectl get jobs
=>kubectl delete job myjob
When delete the job all related pos will be delete

cronJob:
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: mycronjob
spec:
  schedule: "*/1 * * * *"
  jonTemplate:
    spec:
      template:
        spec:
          containers:
            - name: mycronjob-pod
              image: busybox
              args: 
              - /bin/sh
              - -c
              - date; echo Hello Imran, This is from CronJob.
          restartPolicy: OnFailure


=>kubectl get cronjob
=>kubectl get job
=>kubectl get job -w
=>kubectl delete cronjob mycronjob



#PracticeDomain02:
-----------------------------------------------------
Question 1: Labels
Create a pod named kplabs-label. The pod should be launched from nginx image. The name of container should be nginx-container. Attach following label to the pod.
env=production
app=webserver
Solution:
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    env: production
    app: webserver
  name: kplabs-label
spec:
  containers:
  - image: nginx
    name: kplabs-container



Question 2: Deployments
Create a deployment named kplabs-deployment. The deployment should be launched from nginx image. The deployment should have three replicas. The selector should be based on the label of app=nginx

apiVersion: apps/v1
kind: Deployment
metadata:
  name: kplabs-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx


Question 3: Deployments - Rolling Updates and Rollbacks
Create a deployment named kplabs-updates. The deployment should be launched from nginx image. There should be two  replicas. Verify the status of the deployment. As part of rolling update, update the image to nginx2:alpine. Verify the status of deployment. Perform a rollback to the previous version. Verify the status of deployment.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx
        name: nginx-cont




=>kubectl apply -f mydeployment.yaml
=>kubectl set image deployment my-deploy nginx-cont=nginx2:alpine --record=true
=>kubectl get pods
  If show ImagePullBackOff then its deployment update failed

=>kubectl rollout undo deployment/my-deploy
Undo deploument and rollback


Question 4: Labels and Selectors
Create a deployment named kplabs-selector. The pods should be launched from nginx image.The pods should only be launched in a node which has a label of disk=ssd. Observe the status of deployment. Add the appropriate label to the worker node and then observe the status of the deployment.

apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-select-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx-node-select
  template:
    metadata:
      labels:
        app: nginx-node-select
    spec:
      containers:
      - image: nginx
        name: node-select-cont
      nodeSelector:
        disktype: ssd

=>kubectl delete -f dep1.yaml
=>kubectl get pods
Pod will show panding status becouse disktype: ssd not found on node
Now need to add this on node 

=>kubectl get node
=>kubectl get node --show-labels
=>kubectl label nodes node01 disktype=ssd
=>kubectl get deployment


Question 5:  CronJob
Create a job named kplabs-job. The job should run every minute and should print out the current date.

apiVersion: batch/v1
kind: CronJob
metadata:
  name: mycronjob
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: mycroncont
            image: busybox
            args:
            - /bin/sh
            - -c
            - date
          restartPolicy: OnFailure

=>kubectl get pods
=>kubectl logs mycronjob

=>kubectl get cronjob
=>kubectl get job
=>kubectl get job -w
=>kubectl delete cronjob mycronjob


Question 6:  CronJob
Create a job named kplabs-cron. The job should run every minute and should run following command "curl kplabs.in/ping". Terminate the container within 10 seconds if it does not run.

apiVersion: batch/v1
kind: CronJob
metadata:
  name: mycron2
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      activeDeadlineSeconds: 15
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            command: ["curl",  "hello.in/ping"]
          restartPolicy: OnFailure


Question 7:  Deployment Configuration
Create a deployment named kplabs-configuration. The deployment should have 3 replicas of nginx image. Once the deployment is created, verify the maxSurge and maxUnavailable parameters. Edit the the maxUnavailable to 0 and maxSurge to 30% on the live deployment object. Once those two parameters are modified, change the image of the deployment to nginx:alpine. Make sure to use the record instruction on rolling updates.

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: mydeploy-label
  name: mydeploy
spec:
  replicas: 3
  selector:
    matchLabels:
      run: mydeploy-slt
  template:
    metadata:
      labels:
        run: mydeploy-slt
    spec:
      containers:
      - image: nginx
        name: mydeploy-cont

=>kubectl set image deployment mydeploy mydeploy-cont=httpd
=>kubectl set image deployment mydeploy mydeploy-cont=nginx --record









=================================================
#D3:Service and Networking               
================================================= 

Services act as a Gateway of variable amount pods in different node.

ServiceType:
  NodePort
  ClusterIP
  LoadBalancer
  ExternalName


serviceExample1:
Step 1: Creating Backend and Frontend PODS
=>kubectl run bkpod1 --image=nginx
=>kubectl run bkpod1 --image=nginx
=>kubectl run fndpod --image=ubuntu --command -- sleep 3600

=>kubectl exec mypod1 -- ls /usr/share/nginx/html

Step 2: Test the Connection between Frontend and Backend PODs
=>kubectl get pods -o wide
=>kubectl exec -it fndpod -- bash
=>apt-get update && apt-get -y install curl
Curl to backend IP



Step 3: Create a new Service (clusterIp by default)
vi myservice.yaml

apiVersion: v1
kind: Service
metadata:
   name: app-service
spec:
   ports:
   - port: 8181
     targetPort: 80

=>kubectl apply -f myservice.yaml
=>kubectl get service
=>kubectl describe service app-service

Step 4: Associate Endpoints with Service
vi myendpoint.yaml
apiVersion: v1
kind: Endpoints
metadata:
  name: app-service
subsets:
  - addresses:
      - ip: 10.244.1.3
      - ip: 10.244.1.4
    ports:
      - port: 80

=>kubectl apply -f myendpoint.yaml

Step 5: Test the Connection
=>kubectl exec -it fndpod -- bash
curl to service IP with port


Create Service with Selector:
-------------------------------------------------
Step 1: Creating Deployments
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mydeployment
  labels:
    env: backend-service
spec:
  replicas: 2
  selector:
    matchLabels:
      env: backend-service
  template:
    metadata:
      labels:
        env: backend-service
    spec:
      containers:
      - name: ngpod
        image: nginx
        ports:
        - containerPort: 80

=>kubectl apply -f mydeployment.yaml
=>kubectl get pods --show-labels

Step 2: Creating Service
apiVersion: v1
kind: Service
metadata:
   name: myselector-service
spec:
   selector:
     env: backend-service
   ports:
   - port: 80
     targetPort: 80

=>kubectl apply -f myselector-service.yaml
=>kubectl describe service myselector-service

=>kubectl scale deployment/mydeployment --replicas=5
=>kubectl describe service myselector-service

=>kubectl run manual-added-pod --image=nginx
=>kubectl label pods manual-added-pod  env=backend-service

=>kubectl describe service myselector-service
=>kubectl describe endpoints kplabs-service-selector

=>kubectl get endpoints
=>kubectl describe endpoints myselector-service




#NodePort Service
-------------------------------------------------
=>kubectl create service nodeport --help
Step 1: Create Sample POD with Label
=>kubectl run nppod --labels="type=publicpod" --image=nginx
=>kubectl get pods --show-labels

Step 2: Create NodePort service
apiVersion: v1
kind: Service
metadata:
   name: mynodeport-service
spec:
   selector:
     type: publicpod
   type: NodePort
   ports:
   - port: 80
     targetPort: 80

=>kubectl apply -f mynodeport.yaml
=>kubectl get service

Step 3: Fetch the Worker Node Public IP

=>kubectl get nodes -o wide
=>curl 192.2.145.12:32613
Copy the Public IP of Worker Node and Paste it in browser along with NodePort


=>kubectl delete pod nppod
=>kubectl delete -f mynodeport.yaml



#LoadBalancer Service
-------------------------------------------------
Step 1: Create Sample POD with Label
=>kubectl run lb-pod --labels="type=loadbalanced" --image=nginx
=>kubectl get pods --show-labels

Step 2: Create LoadBalancer service
apiVersion: v1
kind: Service
metadata:
  name: elb-service
spec:
  type: LoadBalancer
  ports:
  - port: 80
    protocol: TCP
  selector:
    type: loadbalanced
    
=>kubectl apply -f elb-service.yaml

Step 3: Verify Service Logs
=>kubectl describe service elb-service

=>kubectl delete pod lb-pod
=>kubectl delete -f elb-service.yaml



#Service generated by CLI
-------------------------------------------------
=>kubectl run mynginx --image=nginx
=>kubectl expose pod mynginx --name nginx-service --port=80 --target-port=80 --dry-run=client -o yaml
=>kubectl expose pod mynginx --name nginx-service --port=80 --target-port=80 --dry-run=client -o yaml > service2.yaml

=>kubectl expose pod mynginx --name nginx-nodeport-service --port=80 --target-port=80 --type=NodePort --dry-run=client -o yaml
=>kubectl get service
=>kubectl expose deployment mydeployment --name nginx-deployment-service --port=80 --target-port=8000
=>kubectl describe service nginx-deployment-service




#Name Space
-------------------------------------------------
=>kubectl get namespace
=>kubectl get pod --namespace kube-system
=>kubectl create namespace prod-namespace

=>kubectl run prod-ng --image=nginx --namespace prod-namespace



#Service Account
-------------------------------------------------
=>cat /run/secrets/kubernetes.io/serviceaccount/token
Pod token

=>kubectl get sa
=>kubectl get serviceaccount
=>kubectl get serviceaccount -n my-mynmspc
=>kubectl get secret -n my-mynmspc

=>kubectl get pod -o yaml
Chace current pod service account

=>kubectl get secrets -n prod-mynmspc 
=>kubectl get sa default -o yaml

=>kubectl get pod myng -o yaml

=>kubectl create sa my-saacc
=>kubectl get secret
=>kubectl run myng-sa --image=nginx --serviceaccount="mysaacc"
=>kubectl get pod
=>kubectl get pod myng-sa -o yaml

=>kubectl get pod deployment-sa-8585d89b57-46rtb -o yaml


#Network Security Policies
-------------------------------------------------

=>kubectl run mybx1 --image=busybox --sh
=>kubectl run mybx2 --image=busybox --sh
Run two Pod and ping each other


policy1:
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      run: mybx2
  policyTypes:
    - Ingress

=>kubectl apply -f my-net-poilicy





#PracticeDomain3:
-----------------------------------------------------

Q1: Create a deployment named kplabs-service. The deployment should have three replicas and the image should be based on nginx. Create a service based on NodePort. T
he service port should be 8080. The website should be accessible from port 32001 from all hosts.

=>kubectl create deployment kplabs-service --image=nginx --replicas=1 --dry-run=client -o yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: kplabs-service
spec:
  replicas: 3
  selector:
    matchLabels:
      app: kplabs-service
  template:
    metadata:
      labels:
        app: kplabs-service
    spec:
      containers:
      - image: nginx
        name: nginx


=>kubectl create service nodeport --help
=>kubectl create service nodeport my-ns --tcp=32001:8080 --node-port=32001 --dry-run=client -o yaml

apiVersion: v1
kind: Service
metadata:
  name: myservice
  labels:
    run: myservice
spec:
  type: NodePort
  ports:
  - port: 8080
    targetPort: 80
    nodePort: 32001
    protocol: TCP
  selector:
    run: kplabs-service

SSH to node and curl with nodeport

=>curl serviceIP:32001
=>curl nodeIP:32001



Q2: Rung this services and access nginx from service IP, this is with port mapping issue.
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: kplabs-service
  name: kplabs-fix
spec:
  replicas: 2
  selector:
    matchLabels:
      run: kplabs-fix
  template:
    metadata:
      labels:
        run: kplabs-fix
    spec:
      containers:
      - image: nginx
        name: kplabs-service
---
apiVersion: v1
kind: Service
metadata:
  name: fix-service
  labels:
    run: fix-service
spec:
  ports:
  - port: 8080
    targetPort: 80
    protocol: TCP
  selector:
    run: kplabs-fix

Question 3: Namespace
Create a pod named redis-pod . The pod should be part of the namespace my-namespace.
The pod should make use of redis image. Expose port 6379.

=>kubectl create namespace --help
=>kubectl create namespace my-namespace

=>kubectl run pod --help
=>kubectl run kplabs-namespace --image=redise --help
=>kubectl run redis-pod --image=redis --port=6379 -n my-namespace



Question 4: Service Account
Create a new service account named kplabs. Launch a new pod named kplabs-sa from nginx image. The pod should be launched from the kplabs service account. Verify whether the token has been mounted inside the pod.

=>kubectl create serviceaccount myseracc
=>kubectl get sa
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: kplabns-sa
  name: kplabns-sa
spec:
  containers:
  - image: nginx
    name: kplabns-sa
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
  serviceAccountName: kplabs
status: {}


Question 5: Deployments and Service Account
Create a deployment named deployment-sa. The deployment should have 2 replicas of nginx image. After the deployment has been created, check the service account associated with the pods. Modify the deployment so that all pods shall use the service account of kplabs.

=>kubectl create deployment --help
=>kubectl create deployment deployment-sa  --image=nginx --replicas=3
=>kubectl edit deployment deployment-sa

Add this two property below  securityContext: {}
      serviceAccount: kplabs
      serviceAccountName: kplabs

=>kubectl get pod deployment-sa-75dd877cbf-ddjjd -o yaml
Check updated service acc



Q6:
=>kubectl apply -f troubleshoot-deployment.yaml

apiVersion: v1
kind: Namespace
metadata:
  name: newkplabs
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: troubleshoot-deployment
  name: troubleshoot-deployment
  namespace: newkplabs
spec:
  replicas: 2
  selector:
    matchLabels:
      run: troubleshoot-deployment
  template:
    metadata:
      labels:
        run: troubleshoot-deployment
    spec:
      containers:
      - image: ninx
        name: troubleshoot-deployment

=>kubectl get deployment --all-namespaces
=>kubectl get pod -n newkplabs
=>kubectl edit deployment troubleshoot-deployment  -n newkplabs
Fixed the image name ninx to nginx



================================================= 
Section 5: Domain 4 - Configuration
================================================= 
Three Secret type:
  1)Generic
    File, directory, literal value
  2)Docker Registry
  3)TLS


=>kubectl get secret

GenericType:
=>kubectl create secret generic --help
=>kubectl create secret generic mysec --from-literal=dbpass=dbpass12345
=>kubectl create secret generic mysec1 --from-literal=key1=supersecret --from-literal=key2=topsecret
=>kubectl describe secret mysec

=>kubectl get secret mysec -o yaml
=>echo ZGJwYXNzMTIzNDU= | base64 -d

apiVersion: v1
kind: Secret
metadata:
  name: mysec2
type: Opaque
data:
  #key1: root
  #key2: 54321
  key1: cm9vdAo=
  key2: NTQzMjEK


FileType:
=>echo key1=supersec>secFile.txt
=>kubectl create secret generic mysec3 --from-file=./secFile.txt
=>kubectl get secret
=>kubectl describe secret mysec3


apiVersion: v1
kind: Secret
metadata:
  name: mysec4
type: Opaque
stringData:
  config.yaml: | 
    username: root
    password: 54321

=>kubectl get secret -o yaml


MountingSecret:
apiVersion: v1
kind: Pod
metadata:
  name: myngpod
spec:
  containers:
  - name: myngpod
    image: nginx
    volumeMounts:
      - name: mymount
        mountPath: "/etc/secmount"
        readOnly: true
  volumes: 
  - name: mymount
    secret:
      secretName: mysec1

=>kubectl apply -f pod1.yaml
=>kubectl get pod
=>kubectl exec -it myngpod -- bash
=>cd /etc/mymount/


MountingEnvVariableSecret:
apiVersion: v1
kind: Pod
metadata:
  name: pod2
spec:
  containers:
  - name: myngpod-env
    image: nginx
    env:
      - name: SECRET_USERNAME
        valueFrom:
          secretKeyRef:
            name: mysec2
            key: key1

apiVersion: v1
kind: Pod
metadata:
  name: pod4
spec:
  containers:
  - name: myngpod-env
    image: nginx
    env:
      - name: SECRET_USERNAME
        valueFrom:
          secretKeyRef:
            name: mysec4
            key: key1

=>kubectl apply -f pod1.yaml
=>kubectl get pod
=>kubectl exec -it myngpod -- bash
=>cd /etc/mymount/


ResourceLimites:
apiVersion: v1
kind: Pod
metadata:
  name: pod2
spec:
  containers:
  - name: pod2-cont
    image: nginx
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"

=>kubectl get pod2 -o wide
=>kubectl describe node node01
=>kubectl delete -f pod2.yaml

apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - image: nginx
    name: my-cont
    resources:
      requests:
        memory: "64Mi"
      limits:
        memory: "128Mi"
        cpu: "1"




#Practice Test - Domain 4
-------------------------------------------------
Question 1: Resource Quotas
Create a pod named kplabs-quota. The pod should have following configuration:
a. Should run with nginx image.
b. It should use maximum of 512 MiB of memory.
c. It should use maximum of 2 core CPU.
d. The POD should require a minimum of 128 MiB of memory before it is 
scheduled.

apiVersion: v1
kind: Pod
metadata:
  name: kplabs-quota
spec:
  containers:
  - name: kplabs-quota-cont
    image: nginx
    resources:
      requests:
        memory: "128Mi"
      limits: 
        memory: "512Mi"
        cpu: "2"



Question 2: Secrets
Create a secret named kplabs-secret. The secret should have content where user=admin and pass=12345. Create a pod from the nginx image. Mount the secret as environment variables in the pod. The username should be available as DB_USER and password should be available as DB_PASSWORD inside the pod

=>kubectl create secret generic --help
=>kubectl create secret generic mysec1 --from-literal=user=admin --from-literal=pass=12345

apiVersion: v1
kind: Pod
metadata:
  name: pod3
spec:
  containers:
  - name: myngpod-env
    image: nginx
    env:
      - name: DB_USER
        valueFrom:
          secretKeyRef:
            name: mysec1
            key: user
      - name: DB_PASSWORD
        valueFrom:
          secretKeyRef:
            name: mysec1
            key: pass







================================================= 
Section 6: Domain 5 - Observability
================================================= 

Liveness:
-------------------------------------------------
livenessProbe three type:
  http, command, tcp
=>kubectl run -it ubuntu --image=ubuntu
=>kubectl exec -it ubuntu -- service nginx status
=>echo $?
=>kubectl exec -it ubunty -- bash
  =apt-get update && apt-get install nginx -y
  =service nginx start
  =service nginx status
  =echo $?

apiVersion: v1
kind: Pod
metadata:
  name: lnpod
spec:
  containers:
  - image: ubuntu
    name: lnpod
    tty: true
    livenessProbe:
      exec:
        command: 
        - service
        - nginx
        - status
      initialDelaySeconds: 10
      periodSeconds: 5

=>kubectl apply -f pod.yaml
=>kubectl exec -it lnpod -- service nginx status
=>kubectl get pods



Readiness:
-------------------------------------------------
apiVersion: v1
kind: Pod
metadata:
  name: rdpod
spec:
  containers:
  - image: ubuntu
    name: rdpod
    tty: true
    readinessProbe:
      exec:
        command: 
        - cat
        - /tmp/healthy
      initialDelaySeconds: 10
      periodSeconds: 5


=>kubectl apply -f pod2.yaml 
=>kubectl get pods
=>kubectl exec -it rdpod -- touch /tmp/healthy
=>kubectl exec -it rdpod -- rm /tmp/healthy




Appliation logs:
-------------------------------------------------
Fache multi container podlog:
apiVersion: v1
kind: Pod
metadata:
  name: mlpod
spec:
  containers:
  - image: busybox
    name: cont1
    command: ["ping"]
    args: ["google.com"]
  - image: busybox
    name: cont2
    command: ["ping"]
    args: ["8.8.8.8"]


=>kubectl logs mlpod cont2



Monitoring Components 
-------------------------------------------------
Install Metric server:
=>kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

=>kubectl top pods
=>kubectl top nodes

=>kubectl top pods --all-namespaces




#Event
-------------------------------------------------
=>kubectl get events -n kube-system
=>kubectl get events


#Field Selector
-------------------------------------------------
=>kubectl get pods --all-namespaces --field-selector metadata.namespace!=default
=>kubectl get events --field-selector involvedObject.name=mynginx
=>kubectl get pods --field-selector ""














Question 1: Resource Quotas
---------------------------------------------------
Create a pod named kplabs-quota. The pod should have following configuration:
a. Should run with nginx image.
b. It should use maximum of 512 MiB of memory.
c. It should use maximum of 2 core CPU.
d. The POD should require a minimum of 128 MiB of memory before it is scheduled.
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: kplabs-quota
  name: kplabs-quota
spec:
  containers:
  - image: nginx
    name: kplabs-quota
    resources:
      requests:
        memory: "128Mi"
      limits:
        memory: "512Mi"
        cpu: "2"


Question 2: Secrets
Create a secret named kplabs-secret. The secret should have content where user=admin and pass=12345. Create a pod from the nginx image. Mount the secret as environment variables in the pod. The username should be available as DB_USER and password should be available as DB_PASSWORD inside the pod

=>kubectl create secret generic kplabs-secret --from-literal=user=admin --from-literal=pass=12345
apiVersion: v1
kind: Pod
metadata:
  name: kplabs-secret-pod
spec:
  containers:
  - name: mycontainer
    image: nginx
    env:
      - name: DB_USER
        valueFrom:
          secretKeyRef:
            name: kplabs-secret
            key: user
      - name: DB_PASSWORD
        valueFrom:
          secretKeyRef:
            name: kplabs-secret
            key: pass
  restartPolicy: Never





Practice Test - Domain 5
---------------------------------------------------
Question 1: Probes

Create a POD from the nginx image. Pod should be named kplabs-probe. The pod should be created in such a way that if the application inside is not responding to HTTP requests made on port 8080, then Kubernetes should restart the POD.

apiVersion: v1
kind: Pod
metadata:
  name: kplabs-probe
spec:
  containers:
  - name: liveness
    image: nginx
    livenessProbe:
      httpGet:
        path: /
        port: 8080
      initialDelaySeconds: 3
      periodSeconds: 3


Question 2: Probes
Create a POD named newprobe. Pod should run from nginx image. The Pod should run with arguments defined below. Create a probe that checks if a file on that path /tmp/myfile exists. If it does not exist, the POD should be restarted.

    - /bin/sh
    - -c
    - touch /tmp/myfile; 3600

apiVersion: v1
kind: Pod
metadata:
  name: newprobe
spec:
  containers:
  - name: liveness
    image: nginx
    args:
    - /bin/sh
    - -c
    - touch /tmp/myfile; sleep 3600
    livenessProbe:
      exec:
        command:
        - cat
        - /tmp/myfile
      initialDelaySeconds: 3
      periodSeconds: 3


=>kubectl get events --field-selector involvedObject.name=liveness-http
=>echo | kubectl get events --field-selector involvedObject.name=newprobe > myoutput.txt




================================================= 
#Section 7: Domain 6 - State Persistence
================================================= 
There are many type volume: hostPath:
apiVersion: v1
kind: Pod
metadata:
  name: mypod-vol
spec:
  containers:
  - name: mypod-cont
    image: nginx
    volumeMounts:
    - mountPath: /data
      name: podvol
  volumes:
  - name: podvol
    hostPath:
      path: /mydata
      type: DirectoryOrCreate



apiVersion: v1
kind: Pod
metadata:
  name: mypod-vol
spec:
  containers:
  - name: mypod-cont
    image: nginx
    volumeMounts:
    - mountPath: /data
      name: podvol
  volumes:
  - name: podvol
    hostPath:
      path: /root/mydata
      type: DirectoryOrCreate



#PersistentVolume and PersistentVolumeClaim
-------------------------------------------------
Persistent Volume:pv.yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: block-pv
spec:
  storageClassName: manual
  capacity:
    storage: 10Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: /tmp/data


=>kubectl apply -f pv.yaml 
=>kubectl get pv

PersistentVolumeClaim: pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc
spec:
  storageClassName: manual
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi

=>kubectl apply -f pvc.yaml
=>kubectl get pvc

PVC pod: pod-pvc.yaml
apiVersion: v1
kind: Pod
metadata:
  name: kplabs-pvc
spec:
  containers:
    - name: my-frontend
      image: nginx
      volumeMounts:
      - mountPath: "/data"
        name: my-volume
  volumes:
    - name: my-volume
      persistentVolumeClaim:
        claimName: pvc

=>kubectl apply -f pvc-pod.yaml
=>df -h
=>kubectl exec -it mycont -- bash



#ConfigMap
-----------------------------------------------

=>kubectl get configmap
=>kubectl create configmap my-dev-config --from-literal=app.mem=1024m

=>kubectl get configmap -o yaml


File Base configMap:
app.user=imran
app.pass=root
app.dburl=http://some-url.com
=>kubectl create configmap my-file-base-config --from-file=dev.properties
=>kubectl get configmap -o yaml

ConfigMap Mounted to Pod:
apiVersion: v1
kind: Pod
metadata:
  name: myconfigmap-pod2
spec:
  containers:
    - name: conmap-cont
      image: nginx
      volumeMounts:
      - name: configmap-vol
        mountPath: "/data"
  volumes:
    - name: configmap-vol
      configMap: 
        name: my-file-base-config 
  restartPolicy: Never

=>kubectl exec -it myconfigmap-pod2 -- bash
=>cd data
=>cat dev.properties




#Security Contex
-----------------------------------------------
Three Important Permission Aspects:
  runAsUser, runAsGroup, fsGroup

  =>kubectl run my-bubx --image=busybox -it sh

apiVersion: v1
kind: Pod
metadata:
  name: my-bubx2
spec:
  containers:
  - image: busybox
    name: my-bubx2
    command: ["sh", "-c", "sleep 1h"]
  securityContext: 
    runAsUser: 1000
    runAsGroup: 3000

=>kubectl apply -f pod3.yaml
=>kubectl exec my-bubx2 -it -- sh
=>cd /tmp && touch myfile.txt
=>ls -l

With fsGroup:
apiVersion: v1
kind: Pod
metadata:
  name: my-bubx
spec:
  containers:
  - image: busybox
    name: my-bubx-cont
    command: ["sh", "-c", "sleep 1h"]
    volumeMounts:
    - name: my-sec-ctx-vol
      mountPath: /mydata
  volumes:
    - name: my-sec-ctx-vol
      emptyDir: {}
  securityContext: 
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000




#Practice Test - Domain 6
-----------------------------------------------
Question 1 - ConfigMap
  Create a configmap named kplabs-config which contains all the contents of that file.
  course: kubernetes 2020
  instructor: zeal
  type: certification

Mount the configmap to a pod named configmap-pod based on nginx image in such a way that all contents are available at /etc/config/kplabs.config

Ans:
Create a properties file with this:
=>vi app.properties
=>kubectl create configmap my-file-base-config --from-file=app.properties
=>kubectl get configmap

apiVersion: v1
kind: Pod
metadata:
  name: mypod1
spec:
  containers:
    - name: conmap-cont
      image: nginx
      volumeMounts:
      - name: configmap-vol
        mountPath: "/data"
  volumes:
    - name: configmap-vol
      configMap: 
        name: my-file-base-config 
  restartPolicy: Never

Question 2 - PV and PVC

Create a persistent volume with the name kplabs-pv. The size should be 2Gi and hostpath should be /tmp/mydata. It should have access mode of ReadWriteOnce

Create a persistent volume claim that will make use of the PV created earlier.

Create a Pod named kplabs-pv-pod. The POD should have the volume mounted at /mydata directory.



Question 3 - Security Context

Create a POD named busybox-security. The pod should run a command sleep 3600.  The primary process in POD should run with UID of 1000 and GID of 2000 all newly created contents of volume should have the group ID of 3000.



Question 4 - Secrets and Environment Variables

Andrew works as a database administrator and has generated set of credentials that will be used by the application to connect to the database. Instead of giving the credentials to developers to hard-code in their application, he has requested security team to create a secret and mount it as an environment variable to the application containers.



a. Create a secret name db-creds which has following data:

user: dbreadonly
pass: myDBPassword#%
 

b. Create a pod from nginx image. The pod should be named secret-pod



c. Mount the secret to the POD in such a way that the contents of the database user are available in the form of DB_USER environment variable and database password is available in the form of DB_PASSWORD environment variable inside the container.



Question 5 - Secrets and Volumes

a. Create a secret name app-creds that has the following data:

appuser: dbreadonly
apppass: myDBPassword#%
b. Create a pod based on nginx image with the name of app-pod

c. Mount the secret to the pod so that it is available in the path of /etc/secret

Answer 1: ConfigMap

Step 1: Create a file named kplabs.config and add all the contents specified in the question.

Step 2: Create a new configmap from that file

kubectl create configmap kplabs-config --from-file ./kplabs.config

Step 3: Create a POD with ConfigMap Mounted

apiVersion: v1
kind: Pod
metadata:
  name: configmap-pod
spec:
  containers:
    - name: configmap-container
      image: nginx
      volumeMounts:
      - name: config-volume
        mountPath: /etc/config
  volumes:
    - name: config-volume
      configMap:
        name: kplabs-config
  restartPolicy: Never


Answer 2: PV and PVC

Step 1: Create a Persistent Volume

apiVersion: v1
kind: PersistentVolume
metadata:
  name: kplabs-pv
spec:
  capacity:
    storage: 2Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/tmp/mydata"
Step 2: Create a Persistent Volume Claim

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: kplabs-pvc
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
Step 3: Create a Pod with Mounted Volume

apiVersion: v1
kind: Pod
metadata:
  name: kplabs-pv-pod
spec:
    containers:
    - name: pod
      image: nginx
      volumeMounts:
      - mountPath: /mydata
        name: myvolume
    volumes:
    - name: myvolume
      persistentVolumeClaim:
        claimName: kplabs-pvc


Answer 3: Security Context



apiVersion: v1
kind: Pod
metadata:
  name: busybox-security
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 2000
    fsGroup: 3000
  containers:
  - name: busybox-container
    image: busybox
    command: [ "sleep","3600" ]


Answer 4: Secrets and Environment Variables

Step 1: Create a secret

kubectl create secret generic db-creds --from-literal=user=dbreadonly --from-literal=pass=myDBPassword#%



Step 2: Create a POD with Nginx Image and Mount The Secret

apiVersion: v1
kind: Pod
metadata:
  name: secret-pod
spec:
  containers:
  - image: nginx
    name: secret-pod
    env:
      - name: DB_USER
        valueFrom:
          secretKeyRef:
            name: db-creds
            key: user
      - name: DB_PASSWORD
        valueFrom:
          secretKeyRef:
            name: db-creds
            key: pass


Answer 5 - Secrets and Volumes

Step 1: Create a Secret

kubectl create secret generic app-creds --from-literal=appuser=dbreadonly --from-literal=apppass=myDBPassword#%

Step 2: Create Manifest Files based on Specification;

apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - image: nginx
    name: app-pod
    volumeMounts:
    - name: myvolume
      mountPath: "/etc/secret"
      readOnly: true
  volumes:
  - name: myvolume
    secret:
      secretName: app-creds




================================================= 
#Section 8: Domain 7 - Multi Continer
================================================= 

apiVersion: v1
kind: Pod
metadata:
  name: app-pod
spec:
  containers:
  - image: nginx
    name: cont1
  - image: busybox
    name: cont2
    command: 
     - sleep
     - "1h"

=>kubectl get pods
=>kubectl describe pods
=>kubectl exec -it app-pod -c cont2 -- sh

=>wget 10.244.1.2

apiVersion: v1
kind: Pod
metadata:
  name: kplabs-multicontainer
spec:
  containers:
  - name: first-container
    image: nginx
  - name: second-container
    image: mykplabs/kubernetes:nginx
  - name: third-container
    image: busybox
    command: ["sleep", "3600"]




Multi-Container POD Patterns
-----------------------------------------------

SideCare Pattern:


Ambassador Pattern( a type of sidecare pattern):

Create a configMap (haproxy.cfg)from this value:
global
    daemon
    maxconn 256

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

listen http-in
    bind *:80
    server server1 127.0.0.1:9080 maxconn 32

=>kubectl create configmap kplabs-ambassador-config --from-file ./haproxy.cfg    


apiVersion: v1
kind: Pod
metadata:
  name: ambassador-pod
spec:
  containers:
  - name: first-container
    image: mykplabs/kubernetes:nginx
  - name: haproxy-container
    image: haproxy:1.7
    ports:
       - containerPort: 80
    volumeMounts:
     - name: config-volume
       mountPath: /usr/local/etc/haproxy/haproxy.cfg
  volumes:
    - name: config-volume
      configMap:
        name: kplabs-ambassador-config

=>kubectl get pods -o wide       
=>kubectl run mybusybox -it --image=busybox -- sh
=>wget ip of ambassador-pod


Adapter Pattern
---------------------------------------------------

apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
data:
  fluentd.conf: |
    <source>
      type tail
      format none
      path /var/log/1.log
      pos_file /var/log/1.log.pos
      tag PHP
    </source>
    <source>
      type tail
      format none
      path /var/log/2.log
      pos_file /var/log/2.log.pos
      tag JAVA
    </source>
    <match **>
       @type file
       path /var/log/fluent/access
    </match>
---
apiVersion: v1
kind: Pod
metadata:
  name: counter
spec:
  containers:
  - name: count
    image: busybox
    args:
    - /bin/sh
    - -c
    - >
      i=0;
      while true;
      do
        echo "$i: $(date)" >> /var/log/1.log;
        echo "$(date) INFO $i" >> /var/log/2.log;
        i=$((i+1));
        sleep 1;
      done
    volumeMounts:
    - name: varlog
      mountPath: /var/log
  - name: count-agent
    image: k8s.gcr.io/fluentd-gcp:1.30
    env:
    - name: FLUENTD_ARGS
      value: -c /etc/fluentd-config/fluentd.conf
    volumeMounts:
    - name: varlog
      mountPath: /var/log
    - name: config-volume
      mountPath: /etc/fluentd-config
  volumes:
  - name: varlog
    emptyDir: {}
  - name: config-volume
    configMap:
      name: fluentd-config


=>kubectl apply -f mypod.yaml
=>kubectl exec -it counter -- sh

=>tail -f /var/log/1.log
=>tail -f /var/log/2.log
=>tail -f /var/log/fluent/access.20230408.b5f8ccf3468ae28ef












================================================= 
#New Update | Exam Preparation
================================================= 

Deployment:--------------------------------------
--------------------------------
=>kubectl create deployment my-deployment --image=nginx --dry-run=client -o yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: my-deployment
  name: my-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-deployment
  strategy: 
    type: Recreate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: my-deployment
    spec:
      containers:
      - image: nginx
        name: nginx
        resources: {}
status: {}


=>kubectl explain deployment.spec.strategy

=>kubectl apply -f dpl1.yaml
=>kubectl get deployment
=>kubectl get pods
=>kubectl get rs

Now change deployment dpl1.yaml with a invalid image name 
Deploy again thne:

=>kubectl apply -f dpl1.yaml
=>kubectl get deployment
=>kubectl get pods
=>kubectl get rs

Now show all pod now sutdown, now container are running
this is of Recreate stategy.
Fixed the proper deployment config (image) then pod will be OutsideOfWork


Samelair process for RollingUpdate:

apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: my-deployment
  name: my-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-deployment
  strategy: 
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: my-deployment
    spec:
      containers:
      - image: nginx
        name: nginx
        resources: {}
status: {}



#Blue Green deployment:
------------------------------------------------------


=>kubectl run blue-pod --image=nginx
=>kubectl run green-pod --image=nginx

=>kubectl label pod blue-pod app=app-v1
=>kubectl label pod green-pod app=app-v2

=>kubectl get pods --show-labels

Create a service
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec: 
  type: NodePort
  ports:
  - name: http
    port: 80
    targetPort: 80
  selector:
    app: app-v1

=>kubectl get svc
=>kubectl describe service my-service

Update service "selector" value app-v2
and deploy again, then check the end point

Or 
Cand Edit directly 
=>kubectl edi  t svc



#Canary deployment:
------------------------------------------------------
1. Create Deployment Manifests:

kubectl create deployment v1-app --image=nginx --replicas 3 --dry-run=client -o yaml
kubectl create deployment v2-app --image=httpd --replicas 1 --dry-run=client -o yaml
2. Store these manifests in v1-canary.yaml and v2-canary.yaml

3. Add a common label of deptype: canary to both of these manifest files for the pod template section

4. Create deployment in K8s

kubectl apply -f v1-canary.yaml
kubectl apply -f v1-canary.yaml
5. Verify if PODS are created with appropriate labels:

kubectl get pods --show-labels

6. Create a Canary Service

canary-svc.yaml

apiVersion: v1
kind: Service
metadata:
 name: canary-deployment
spec:
 type: NodePort
 ports:
 - name: http
   port: 80
   targetPort: 80
 selector:
   deptype: canary
kubectl apply -f canary-svc.yaml

7. Verify if Service have 4 Endpoint IPs:

kubectl describe svc canary-deployment
8. Make CURL request to see if requests are distributed among v1 and v2 apps
curl PUBLIC-IP:NODEPORT


#Custom Resource
------------------------------------------
Kubernetes Documentation Referred for Base CRD manifests:

https://kubernetes.io/docs/tasks/extend-kubernetes/custom-resources/custom-resource-definitions/

Manifests File (Step 1 and Step 2)

crd.yaml

apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: crontabs.kplabs.internal
spec:
  group: kplabs.internal
  versions:
    - name: v1
      served: true
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              properties:
                cronSpec:
                  type: string
                image:
                  type: string
                replicas:
                  type: number
  scope: Namespaced
  names:
    plural: crontabs
    singular: crontab
    kind: CronTab
    shortNames:
    - ct
crd-object.yaml

apiVersion: "kplabs.internal/v1"
kind: CronTab
metadata:
  name: my-new-cron-object
spec:
  cronSpec: "* * * * */5"
  image: my-awesome-cron-image
  replicas: 3
AWS Service Operator Manifest File:

https://raw.githubusercontent.com/awslabs/aws-service-operator/master/configs/aws-service-operator.yaml



#Authentication
----------------------------------------------
=>cat .kube/config
=>curl -k https://controlplane:6443


=>curl -k https://controlplane:6443 --header "Authorization: 
Bearer ewrwfsdlkfjdlf="
Call with token



#Authorization
----------------------------------------------

Create a Role:
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: pod-reader
rules:
- apiGroups: [""] # "" indicates the core API group
  resources: ["pods"]
  verbs: ["list"]

=>kubectl apply -f myrole.yaml 

=>kubectl get role
=>kubectl describe role pod-reader


Role banding:

apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
subjects:
- kind: User
  name: system:serviceaccount:default:myadmin
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role 
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io


=>kubectl apply -f role-banding.yaml
=>kubectl get rolebinding
=>kubectl describe rolebinding read-pods



ClusterRole:
---------------------------------------------

Create a Cluster role:
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "watch", "list"]


=>kubectl get clusterrole
=>kubectl describe clusterrole pod-role

Cluster Role banding:

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: pod-list-global
subjects:
- kind: User
  name: system:serviceaccount:default:myadmin
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io

  =>kubectl apply -f cls-role-banign.yaml
  =>kubectl get clusterrolbinding 
  =>kubectl describne clusterrolbinding pod-list-global



Cluster role to Role Banding:
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
subjects:
- kind: User
  name: system:serviceaccount:default:myadmin
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole 
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io





#Exam Preparation
----------------------------------------------------
=>kubectl api-resources

=>alias k=kubectl
Create alias for code
=>k get pods

=>k run mynginx --image=nginx --port=80 --dry-run=client -o yaml
Generate a POD  yaml file


=>k create deployment -h
How to crearte a deployment get Help
=>kubectl create deployment my-dep --image=nginx --replicas=3 --dry-run=client -o yaml





Edit Pod
=>kubectl run mybusybox --image=busybox





















================================================= 
#Debug
================================================= 
=>kubectl api-resources
Details about api and with short name

Pod Details:
-----------------------------------------------
=>kubectl describe pod -n default
=>systemctl status kubelet


Create a deployment
=>kubectl create deployment mydeployment --image=nginx --dry-run=client -o yaml
=>kubectl explain deployment.spec.strategy


Edit Pod Information
=>kubectl edit pods mybusybox
=>kubectl get pods --show-laels


























Install Kubernetes
-------------------------------------------------
1)Mamage Kubernetes Services
2)MiniKube
3)Install Kubernetes Manually

Three 03 Thing need in a typical Kubernetes server:
     1)kubectl
     2)Kubernetes Master
     3)Worker Node Agents


Extract pod definition to a file using the below command:
=>kubectl get pod <pod-name> -o yaml > pod-definition.yaml


=>kubectl create namespace test-123 --dry-run -o json/yaml
Formatting Output




=================================================
#  Pre-Requisites                                          
=================================================

Topics Covered on the Exam
-------------------------------------------------

Cluster Architecture, Installation, and Configuration (25%)
A big part of the exam will focus on the Kubernetes setup and configuration. The tutorial, “Kubernetes The Hard Way” is a very helpful tool as you prepare for this section. I’ll talk more about this tutorial later.

Workloads and Scheduling (15%)
You’ll be expected to create robust deployments..

Storage (10%)
A small section will test your knowledge about volumes and volume claims.

Troubleshooting (30%)
The biggest section of the exam will test you on troubleshooting a Kubernetes cluster. This is a task you can only improve at through practice.



Certified Kubernetes Administrator (CKA)
-------------------------------------------------
The CKA tests your ability to deploy and configure a Kubernetes cluster as well as your understanding of core concepts. Candidates have three hours to take the exam and must score 74% or higher to earn the certification.

The CKA exam tests the following areas:

8% – Application lifecycle management
12% – Installation, configuration & validation
19% – Core concepts
11% – Networking
5% – Scheduling
12% – Security
11% – Cluster maintenance
5% – Logging/monitoring
7% – Storage
10% – Troubleshooting


Certified Kubernetes Application Developer (CKAD)
-------------------------------------------------
The CKAD tests your ability to deploy and configure applications running on the Kubernetes cluster and your understanding of some core concepts. You’ll have two hours to complete the CKAD exam. Scoring a 66% or higher means you’ve passed.

For the CKAD exam, you will be tested in the following areas:

13% – Core concepts
18% – Configuration
10% – Multi-container pods
18% – Observability
20% – Pod design
13% – Services & networking
8% – State persistence









Linux
-------------------------------------------------------
https://www.youtube.com/watch?v=Q8Nh8r6_tkQ&list=PLd3UqWTnYXOnar-GXf1taqzw5Z8nAAxod&index=1
https://www.youtube.com/watch?v=mzMD5duBA-A&list=PLd3UqWTnYXOkCdIbrnfB7A51jOlsP4i3w&index=1
https://www.youtube.com/watch?v=UoJ94MirYmw&list=PLd3UqWTnYXOny6ntfCKt9S4mwDM4GDaAG&index=1



CKA
===============================================================================


Domains & Competencies
-------------------------------------------------
Storage10%
Understand storage classes, persistent volumes
Understand volume mode, access modes and reclaim policies for volumes
Understand persistent volume claims primitive
Know how to configure applications with persistent storage

Troubleshooting30%
Evaluate cluster and node logging
Understand how to monitor applications
Manage container stdout & stderr logs
Troubleshoot application failure
Troubleshoot cluster component failure
Troubleshoot networking

Workloads & Scheduling15%
Understand deployments and how to perform rolling update and rollbacks
Use ConfigMaps and Secrets to configure applications
Know how to scale applications
Understand the primitives used to create robust, self-healing, application deployments
Understand how resource limits can affect Pod scheduling
Awareness of manifest management and common templating tools

Cluster Architecture, Installation & Configuration25%
Manage role based access control (RBAC)
Use Kubeadm to install a basic cluster
Manage a highly-available Kubernetes cluster
Provision underlying infrastructure to deploy a Kubernetes cluster
Perform a version upgrade on a Kubernetes cluster using Kubeadm
Implement etcd backup and restore

Services & Networking20%
Understand host networking configuration on the cluster nodes
Understand connectivity between Pods
Understand ClusterIP, NodePort, LoadBalancer service types and endpoints
Know how to use Ingress controllers and Ingress resources
Know how to configure and use CoreDNS
Choose an appropriate container network interface plugin





ExamTips
------------------------------------------------------------------------------
After 2 years of procrastination, finally booked the CKA certification exam.

Happy to share that I passed Certified Kubernetes Administrator (CKA) Exam today with 91% score.

I can never thank enough Mr. Mumshad Mannambeth for the excellent course, keeping concepts simple yet informative. His solution walkthroughs on KodeKloud labs were so helpful. Also I thank Udemy for bringing the best lecturer to the platform.

Tips for CKA exam prep:
💡 1. Check your understanding on below competencies (source: https://t.ly/gtXI)
     -  Storage : Persistent Volumes, mountpoints, storage classes etc.
     - Troubleshooting: debugging services on nodes, debugging error logs, understanding node logs, using metrics server
     -  Workloads & Scheduling: Understanding deployments, manifest files, RBAC
     -  Cluster Architecture, Installation & Configuration: Cluster setup, Kubeadm, k8 version upgrades
     - Services & Networking: Ingress, Network policies, Network interface plugins, CoreDNS, connectivity between pods and services, various ports.   
💡2. k8 documentation:
     - Practice all tasks in the documentation (https://lnkd.in/gCsHrdjp)
     - Make a habit of checking k8 documentation for manifest formats, it comes handy during exam.
     - Only official documentation is allowed on the exam remote desktop.
💡3. Mock exams:
     - Experience the exam environment which is remote desktop, in killerKoda (https://t.ly/1wYz)
     - KodeKloud mock exams that comes with Udemy course (https://t.ly/4Vf8) to get an idea how questions would be.
     - I highly reccommed to take exam simulator by Killer.sh only before 1 week to your exam. (you will get 2 free sessions on purchase of exam), the questions you face in this are lot tougher than the real exam.
💡4. Commands:
     - Practice imperative commands for pods, deployments and services. Instead of writing manifest files from scratch.
     - Try to make use of short commands using alias.
             
💡5. Main exam:
     - CKA exam time limit of 2 hours with 17 questions, each with different weights (4%, 5%, 7%, 13%), you need to get 66% to pass the exam.
     - All 7% looks simple in plain, but you have to pay attention to each detail. It may have two or three steps in it.
     - After implementing a task, take some time to test it.
     - Don’t stick to the hard question more than 10mins. Just flag it, you can visit back after completing easy ones.
     - Always you have one free retake, if you fail first time dont worry. Practice well to score well.

💡6. Patience, Preparation and Practice :
     - It was not an easy thing to crack this test, needs a lot of patience to give time to understand and prepare notes on each concept. I took nearly a month for practicing all scenarios


Lab:
CKA-LAB:
https://kodekloud.com/lessons/core-concepts-4/
Docker-lab:
https://kodekloud.com/lessons/hands-on-labs-2/
DockerSwarmLab
https://kodekloud.com/lessons/labs-5/
PythonLab
https://kodekloud.com/lessons/quizzes/
DevPOpsLan
https://kodekloud.com/lessons/labs-6/



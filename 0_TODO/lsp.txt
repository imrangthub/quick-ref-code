#################################################
#                 L-SP                          #
#################################################
https://kodekloud.com/lessons/challenge-1-3/
https://kodekloud.com/lessons/certified-kubernetes-application-developer-mock-exam-series/

https://dev.mysql.com/downloads/installer/

tar zxvf backups.tgz

alias k='kubectl'
alias cc='clear'
alias kk='kubectl get'
alias ke='kubectl edit'
alias kkk='kubectl delete'
alias kc='kubectl create'
alias kd='kubectl describe'
alias ka='kubectl apply --force'
dr="--dry-run=client -oyaml"



Ing:
===========================
https://killer.sh/
https://killercoda.com/


endpoint service
Read about projected volumes
hpa

containerD
Askto build image using ctl and push image to docker repo

FilterSome Pod with short and redirect result

JsonPath
SAVE OUTPI  :
=>k get po | sudo tree them/logfile.log









Ing:
===========================
https://killer.sh/
https://killercoda.com/


endpoint service
Read about projected volumes
hpa


https://kodekloud.com/topic/faq-what-is-the-rewrite-target-option/


NeedExplor:
-------------------------------------------------
=>$ kubectl delete all --all

=>kubectl label po kubia-manual creation_method=manual
=>kubectl label po kubia-manual-v2 env=debug --overwrite


List the pods again to see the updated labels:
$ kubectl get po -L creation_method,env


And those that don’t have the env label:
$ kubectl get po -l '!env'

creation_method!=manual to select pods with the creation_method label with
any value other than manual



Exec to service:
$ kubectl exec kubia-3inly env

=>k get po -n ckad17-nqoss-aecs --output=custom-columns="NAME":.metadata.name,"QOS":.status.qosClass>qos_status_aecs
=>kubectl get pods -A -o=custom-columns='POD_NAME:metadata.name,IP_ADDR:status.podIP' --sort-by=.status.podIP > /root/pod_ips_ckad02_svcn


DaemonSet
=>kubectl get daemonset
Demonset every node can include NodeAffinity





KCH:Skip-Q
=================================================









Volume-Env
===========================

volume:
---------------------------
apiVersion: v1
kind: Pod
metadata:
  name: ckad-flash89-aom
spec:
  containers:
    - name: nginx
      image: nginx
      volumeMounts:
        - name: config
          mountPath: /var/log/nginx
  volumes:
  - name: config
    emptyDir:
      sizeLimit: 500Mi
  volumes:
  - name: test-volume
    hostPath:
      path: /data
      type: Directory
  volumes:
    - name: config
      persistentVolumeClaim:
        claimName: test-nfs-claim
  volumes:
    - name: config
      configMap:
        name: myconfigmap
  volumes:
    - name: secret-volume
      secret:
        secretName: dotfile-secret


env
--------------------------

apiVersion: v1
kind: Pod
metadata:
  name: envar-demo
spec:
  containers:
  - name: ng-inv
    image: nginx
    env:
    - name: APPTYPE
      value: "prod"
    - name: "HI"
      value: "hello"

    env:
      - name: APP_TYPE
        valueFrom:
          configMapKeyRef:
            name: app-config
            key: appenv.type
    envFrom:
    - configMapRef:
        name: special-config

    env:
    - name: DB_USERNAME
      valueFrom:
        secretKeyRef:
          name: dbuser-secret
          key: db-username
    envFrom:
    - secretRef:
        name: test-secret







gCommand
===========================
=>kubectl run ckad-probe-aom --image=nginx --restart=Always --labels=run=ckad-probe-aom

=>sudo apt-get update && apt-get install iputils-ping && sudo apt install net-tools
=>kubectl create quota my-quota --hard=cpu=1,memory=1G,pods=2,services=3,replicationcontrollers=2,resourcequotas=1,secrets=5,persistentvolumeclaims=10



=>kubectl create cronjob learning-every-minute  -n ckad-job --image=busybox:1.28 --schedule="* * * * *" -- 'I am practicing for CKAD certification'
=>kubectl create cronjob my-alarm -n ckad-job               --image=busybox:1.28 --schedule="0 0 * * 0" -- date
=>kubectl create cronjob simple-python-job -n ckad-job      --image=python       --schedule="*/30 * * * *" -- 'ps –eaf'
=>kubectl create cronjob learning-every-minute -n ckad-job --restart=OnFailure --image=busybox:1.28 --schedule="*/1 * * * *" -- echo 'I am practicing for CKAD certification'


=>k create clusterrole healthz-access --verb=get,post --non-resource-url=/healthz,/healthz/*



=>scp ../media/* root@node01:/web
Copey file to another

=>ps -ef | grep kube-apiserver | grep admission-plugins
=>kubectl exec -it kube-apiserver-controlplane -n kube-system -- kube-apiserver -h | grep 'enable-admission-plugins'

=>k create cronjob simple-python-job -n ckad-job --image=python --schedule="*/30 * * * *" -- 'ps –eaf'


=>kubectl create ingress world -n world --class=nginx --rule="world.universe.mine/europe*=europe:80" --rule="world.universe.mine/asia*=asia:80" 
=>kubectl create ingress ingress-ckad09-svcn -n critical-space  --rule="/pay=pay-service:8282
=>kubectl create ingress ingress-resource-svcn \
  --namespace app-space \
  --rule='/wear'='wear-service:8080' \
  --rule='/watch'='video-service:8080' \
  --annotation='nginx.ingress.kubernetes.io/rewrite-target=/' \
  --annotation='nginx.ingress.kubernetes.io/ssl-redirect=false' \
  --class=nginx


 annotations:
    "api-approved.kubernetes.io": "unapproved, experimental-only"



=>kubectl --namespace=ckad17-nqoss-aecs get pod --output=custom-columns="NAME:.metadata.name,QOS:.status.qosClass"
NAME                QOS
ckad17-qos-aecs-1   BestEffort
ckad17-qos-aecs-2   Guaranteed
=>kubectl --namespace=ckad17-nqoss-aecs get pod --output=custom-columns="NAME:.metadata.name,QOS:.status.qosClass" > /root/qos_status_aecs

Perform the connectivity test using 
=>kubectl  exec testpod -- curl backend-ckad-svcn

=>helm upgrade lvm-crystal-apd -n crystal-apd-ns lvm-crystal-apd/nginx --version=13.2.30 --set replicaCount=2

SAVE OUTPI  :
=>k get po | sudo tree them/logfile.log



=================================================
Helm:
=================================================

=>helm repo ls 
List the helm repositories.

=>helm ls -A
Deployed Helm charts releases list, Here lists all the releases of all the namespaces.


Official Helm Stable Charts: https://charts.helm.sh/stable
Prometheus Helm chart repository: https://prometheus-community.github.io/helm-charts
Rancher's Helm chart repository: https://releases.rancher.com/server-charts

=>helm repo add repoName https://charts.bitnami.com/bitnami
=>helm repo ls 
Add the repostiory to Helm.
It allows us to browse and install charts from the new repository using the Helm package manager.


=>helm search repo nginx
=>helm search hub nginx
Search Helm charts, Its return last lates version. for more

=>helm search repo bitnami/joomla -l | head -n10

When you run "helm search repo nginx", it will query the repositories you have added to your Helm configuration 
When you run "helm search hub nginx", it queries the Helm Hub and returns any matching charts related to nginx 
that are available on the Helm Hub. The Helm Hub is a public repository and can be accessed by anyone.


=>helm search repo polar | grep nginx
=>helm install nginx-server polar/nginx 
=>helm  install jom13 bitnami/joomla  --version=13.3.19
Search and Inatall for the nginx chart in a polar chart repository



cd /root/
=>helm lint ./newVersion
Validate the helm chart by using the helm lint command


=>helm uninstall oldVersioApp -n default
=>helm install -myNewApp ./new-version
=>helm install --generate-name ./new-version
Install/Uninstall application


=>helm search repo lvm-crystal-apd/nginx -l | head -n30
The helm search command searches for all the available charts in a specific Helm chart repository. 


=>helm upgrade nging ofc/nginx-ingress --version=1.41.1
=>helm upgrade lvm-crystal-apd lvm-crystal-apd/nginx -n crystal-apd-ns --version=13.2.12 --set replicaCount=2
Upgrade the helm chart and increase the replica count.

=>helm ls -n crystal-apd-ns
Look under the CHART column for the chart version for varify.


=>helm repo update myHelmChart
Now, update the helm repository with the following command: -
The above command updates the local cache of available charts from the configured chart repositories.




https://brain2life.hashnode.dev/how-to-set-helpful-aliases-for-kubernetes-commands-in-ubuntu-2004






If you have decided to write this exam, the following points will help you:
a. Complete the KodeKloud CKAD course and do the hands-on exercises properly.
b. Use internet sources to solve as many questions as you can.
c. If you are CKA certified, focus only on the delta part.
d. After purchasing the exam, use killer.sh to practice questions and familiarize yourself with the exam environment. 
   Take these questions seriously and try to solve them, or use the provided solutions to help you understand.
e. On the exam day, stay calm. The exam is not as difficult as people make it out to be, and the provided time is sufficient. 
   Try to solve the questions you know first in the first 90 minutes, 
   then use the remaining 30 minutes to tackle the more difficult questions. 
   Do not get stuck on any question as it will consume your time.
f. Use a high-spec laptop, as using a lower-spec laptop like an i5 can cause performance issues during the exam.
g. The exam environment is known to be poor, with lags and hangs, but have patience. 
   You will have sufficient time, so don't try to rush as the system may not work properly.






Example:
==============================================================================
cat stf.yaml 
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster
spec:
  selector:
    matchLabels:
      app: redis-cluster
  serviceName: "nginx"
  replicas: 6 # by default is 1
  template:
    metadata:
      labels:
        app: redis-cluster
    spec:
      terminationGracePeriodSeconds: 10
      volumes:
        - name: conf
          configMap:
            name: redis-cluster-configmap
            defaultMode: 0755
      containers:
      - name: redis
        command: ["/conf/update-node.sh", "redis-server", "/conf/redis.conf"]
        image: redis:5.0.1-alpine
        env:
          - name: POD_IP
            valueFrom: 
              fieldRef:
                fieldPath: status.podIP
        ports:
        - name: client
          containerPort: 6379
        - containerPort: 16379
          name: gossip
        volumeMounts:
        - name: data
          mountPath: /data
          readOnly: false
        - name: conf
          mountPath: /conf
          readOnly: false
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      storageClassName: "mystc"
      resources:
        requests:
          storage: 1Gi







controlplane ~ ➜  kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://controlplane:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: kubernetes-admin
  name: kubernetes-admin@kubernetes
current-context: kubernetes-admin@kubernetes
kind: Config
preferences: {}
users:
- name: kubernetes-admin
  user:
    client-certificate-data: DATA+OMITTED
    client-key-data: DATA+OMITTED

controlplane ~ ➜  cat /etc/kubernetes/manifests/kube-apiserver.yaml 
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubeadm.kubernetes.io/kube-apiserver.advertise-address.endpoint: 127.0.0.1:6443
  creationTimestamp: null
  labels:
    component: kube-apiserver
    tier: control-plane
  name: kube-apiserver
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-apiserver
    - --advertise-address=127.0.0.1
    - --allow-privileged=true
    - --authorization-mode=Node,RBAC
    - --client-ca-file=/etc/kubernetes/pki/ca-authority.crt
    - --enable-admission-plugins=NodeRestriction
    - --enable-bootstrap-token-auth=true
    - --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt
    - --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt
    - --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key
    - --etcd-servers=https://127.0.0.1:2379
    - --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt
    - --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key
    - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
    - --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt
    - --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key
    - --requestheader-allowed-names=front-proxy-client
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --requestheader-extra-headers-prefix=X-Remote-Extra-
    - --requestheader-group-headers=X-Remote-Group
    - --requestheader-username-headers=X-Remote-User
    - --secure-port=6443
    - --service-account-issuer=https://kubernetes.default.svc.cluster.local
    - --service-account-key-file=/etc/kubernetes/pki/sa.pub
    - --service-account-signing-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --tls-cert-file=/etc/kubernetes/pki/apiserver.crt
    - --tls-private-key-file=/etc/kubernetes/pki/apiserver.key
    image: registry.k8s.io/kube-apiserver:v1.27.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-apiserver
    readinessProbe:
      failureThreshold: 3
      httpGet:
        host: 127.0.0.1
        path: /readyz
        port: 6443
        scheme: HTTPS
      periodSeconds: 1
      timeoutSeconds: 15
    resources:
      requests:
        cpu: 250m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 127.0.0.1
        path: /livez
        port: 6443
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: true
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: true
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: true
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: true
  hostNetwork: true
  priority: 2000001000
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      type: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      type: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /usr/local/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-share-ca-certificates
status: {}




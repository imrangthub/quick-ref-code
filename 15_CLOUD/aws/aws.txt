#################################################
#                 AWS                          #
#################################################
https://twitter.com/i/status/1576389331484545024
=>sudo chmod 777 -R destinationFolder/*
Allow ec2 file permission

=>/mnt/efs/fs1
MetadataURL is http://169.254.169.254/latest/meta-data
  
	  
#!/bin/bash
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd
echo "<h1>Hello World from $(hostname -f)</h1>" > /var/www/html/index.html


=================================================
#General | Basic | Info      
================================================= 


ConfusingTakeaLook
------------------


HandOnRemain
----------------------------
Amazon CloudFront Hands On
CloudFormation

Video Checkout:
2)Giving permissions to federated/outside users & groups.
You can't assign role to user.

AWS Best Practices for DDoS Resiliency Application Layer Defense

Ephemeral Ports

Before->Amazon GuardDuty

S3 Bucket Policies
S3 CORS
S3 Select

DynamoDB provisoning model

Amazon Aurora Serverless




Amongst the new topics you'll learn about in this update:
================================================
-RDS Custom for Oracle and Microsoft SQL Server, RDS & Aurora Backup and Monitoring, RDS Proxy
-S3 Object Lambda, S3 Batch Operations
-Amazon EKS, AWS App Runner, DocumentDB, Neptune, Keyspaces (for Apache Cassandra), QLDB, Timestream, 
 QuickSight, Glue, Lake Formation, MSK - Managed Streaming for Apache Kafka...
-CloudWatch Metric Streams, CloudWatch Insights
-Many AWS Machine Learning services



SSM
================================================
=>aws ssm get-parameters-by-path --path /myapp/prod/ --recursive
=>aws ssm get-parameters-by-path --path /myapp/prod/ 
=>aws ssm get-parameters --name /myapp/prod/db-url /myapp/prod/db-pass
=>aws ssm get-parameters --name /myapp/prod/db-url /myapp/prod/db-pass --with-decryption


=================================================
#AWS Top View | Flow | Overview
=================================================


#AWS Global Infrastructure
-------------------------------------------------
AWS: 
  -Region
  	-AvailableZone
		-VPC 
			-Router 
			-RouteTables
			-Gateway
			-InternetGateway
			-VPCEndpoint(InterfaceEndpoints and GatewayEndpoints)
			-VPG(VPN Gateway VirtualPrivateGateway)+Site-to-Site VPN+VPNCloudHub(set it up, connect multiple VPN connections on the same VGW)
			-DCG(DirectConnectGateway for DX)
				-Subnet
					-NACL
					-NATInstance
					-NATGateway
					-EC2
						-SecurityGroup
					
				
#Security
-------------------------------------------------
SCP->ResourceBase->IdentityBase->IAMPermissionBoundry->SessionPolicy->Go!

Root User:
		-IAM User      +Permission Policy
		-User Group    +Permission Policy
		-IAM Role      +Permission Policy ->For EC2 to doing somthing
		
SCP:
	-OU			   +Permission Policy
		-User
		-Role
	  
	
	
Policy:		=>Predefined+Custome+(Optional)Condition
IAMRole:	=>Predefined+Custome

Principals: Root Users, IAM Users and Instance Principals.
PrincipleEntities: Users, Groups, Roles and Policies.



#Interfaces | EndPoints
-------------------------------------------------
AWS: 
  -Region
  	-AvailableZone
		-VPC +IGW+GWLB
			-Subnet +GWLBEndPoint
				-EC2++SecurityGroups
					++ENI++SecurityGroups
				
				

=================================================
#AWS Services Scope | Area
================================================= 
IAM
	Users, Groups, Roles, Accounts – Global
		Same AWS accounts, users, groups and roles can be used in all regions
	Key Pairs – Global and Regional
		Amazon EC2 created key pairs are specific to the region
		RSA key pair can be created and uploaded that can be used in all regions
Virtual Private Cloud
	VPC – Regional
		VPC are created within a region
	Subnet – Availability Zone
		Subnet can span only a single Availability Zone
	Security groups – Regional
		A security group is tied to a region and can be assigned only to instances in the same region.
	VPC Endpoints – Regional
		You cannot create an endpoint between a VPC and an AWS service in a different region.
	VPC Peering – Regional
		Create a VPC peering connection between your own VPCs, with a VPC in another AWS account, or with a VPC in a different Region.
		VPC Peering can now span multi-region
	Elastic IP Address – Regional
		Elastic IP address created within the region can be assigned to instances within the region only
EC2
	Resource Identifiers – Regional
		Each resource identifier, such as an AMI ID, instance ID, EBS volume ID, or EBS snapshot ID, is tied to its region and 
		can be used only in the region where you created the resource.
	Instances – Availability Zone
		An instance is tied to the Availability Zones in which you launched it. However, note that its instance ID is tied to the region.
	EBS Volumes – Availability Zone
		Amazon EBS volume is tied to its Availability Zone and can be attached only to instances in the same Availability Zone.
	EBS Snapshot – Regional
		An EBS snapshot is tied to its region and can only be used to create volumes in the same region and has to be copied from 
		One region to other if needed.
AMIs – Regional
	AMI provides templates to launch EC2 instances
	AMI is tied to the Region where its files are located with Amazon S3. For using AMI in different regions, the AMI can be copied 
	to other regions.
Auto Scaling – Regional
	Auto Scaling spans across multiple Availability Zones within the same region but cannot span across regions
Elastic Load Balancer – Regional
	Elastic Load Balancer distributes traffic across instances in multiple Availability Zones in the same region
Cluster Placement Groups – Availability Zone
	Cluster Placement groups can be span across Instances within the same Availability Zones
S3 – Global but Data is Regional
	S3 buckets are created within the selected region
	Objects stored are replicated across Availability Zones to provide high durability but are not cross region replicated unless 
	done explicitly.
Route53 – Global
	Route53 services are offered at AWS edge locations and are global
DynamoDB – Regional
	All data objects are stored within the same region and replicated across multiple Availability Zones in the same region
	Data objects can be explicitly replicated across regions using cross-region replication
WAF – Global
	Web Application Firewall (WAF) services protects web applications from common web exploits are offered at AWS edge locations 
	and are global
CloudFront – Global
	CloudFront is the global content delivery network (CDN) services are offered at AWS edge locations
Storage Gateway – Regional
	AWS Storage Gateway stores volume, snapshot, and tape data in the AWS region in which the gateway is activated
AWS Config – Regional
AWS GuardDuty – Regional





=================================================
#AWS Security, Identity, & Compliance services
================================================= 
Category:UseCases:AWSService

Identity & access management:
	Securely manage access to services and resources
	AWS Identity & Access Management (IAM)
	
	Cloud single-sign-on (SSO) service
	AWS IAM Identity Center (successor to AWS SSO)
	
	Identity management for your apps
	Amazon Cognito
	
	Managed Microsoft Active Directory
	AWS Directory Service
	
	Simple, secure service to share AWS resources
	AWS Resource Access Manager
	
	Central governance and management across AWS accounts
	AWS Organizations
	
Detection:
	Automate AWS security checks and centralize security alerts
	AWS Security Hub
	
	Protect AWS accounts with intelligent threat detection
	Amazon GuardDuty
	
	Automate vulnerability management
	Amazon Inspector
	
	Record and evaluate configurations of your AWS resources
	AWS Config
	
	Track user activity and API usage
	AWS CloudTrail
	
	Security management for IoT devices
	AWS IoT Device Defender
	
Network and application protection:
	Network security
	AWS Network Firewall
	
	DDoS protection
	AWS Shield
	
	Filter and control outbound DNS traffic for your VPCs
	Amazon Route53 Resolver DNS Firewall
	
	Filter malicious web traffic
	AWS Web Application Firewall (WAF)
	
	Central management of firewall rules
	AWS Firewall Manager
	
Data protection:
	Discover and protect your sensitive data at scale
	Amazon Macie
	
	Key storage and management
	AWS Key Management Service (KMS)
	
	Hardware based key storage for regulatory compliance
	AWS CloudHSM
	
	Provision, manage, and deploy public and private SSL/TLS certificates
	AWS Certificate Manager
	
	Rotate, manage, and retrieve secrets
	AWS Secrets Manager
	
Incident response:
	Investigate potential security issues
	Amazon Detective
	Scalable, cost-effective application recovery to AWS
	AWS Elastic Disaster Recovery
Compliance:
	No cost, self-service portal for on-demand access to AWS’ compliance reports
	AWS Artifact
	
	Continuously audit your AWS usage to simplify how you assess risk and compliance
	AWS Audit Manager


=================================================
#AWS Service List
=================================================
Compute Services
	Amazon EC2 - Secure, resizable Compute Instances (400+)
	EC2 Autoscaling - Automated compute capacity scaling
	Amazon LightSail - Easy virtual private server instances
	ElasticBeanstalk - Deploy & scale web apps (Java/Ruby/etc)
	Lambda - Serverless Compute Functions
Container Services
	ECR - Elastic Container Registry
	ECS - Elastic Container Service to deploy/manage clusters & tasks
	EKS - Elastic Kubernetes Service
	AWS Copilot - CLI to launch and manage containers
	AWS Fargate - Serverless Compute Engine for ECS/EKS Containers
Database Services
	Aurora - MySQL and PostgreSQL compatible database service
	DynamoDB - KeyValue / Document Database
	ElastiCache - Scalable in-memory database
	Neptune - Graph database for highly connected data sets
	Amazon RDS - Relational Database (MySQL/Postgres/Maria etc)
	Timestream - Serverless time series db for IoT
Network and Content Delivery
	AWS VPC - Logically isolated virtual private clouds
	API Gateway - Create and manage APIs
	CloudFront - Fast content delivery network CDN service
	Route53 - Fast DNS service
	AWS PrivateLink - Connect your on-prem network to AWS
	AWS AppMesh - Monitor, control, and debug the communications between services.
	AWS CloudMap - Resource discovery (can define custom names for your application resources,) 
	               Implementing lightweight on-premises API connectivity using inverting traffic proxy.
	AWS Direct Connect - Links your network directly to AWS to deliver consistent, low-latency performance.
	Global Accellerator - App traffic routing over the AWS network
	AWS TransitGateway - Centralised VPC and on prem connectivity
	Elastic Load Balancing - Service to evenly distribute network traffic
AWS Storage
	S3 - Object storage service
	EBS - Elastic Block Store, Persistent block
	EFS - Serverless Elastic File System(Only for Linux)
	FSx for Lustre - High performance file storage using Lustre
	FSx for Windows File System - AWS Windows file system
	S3 Glacier - Durable low cost archival storage
	AWS Backup - Policy driven data protection
	AWS Snow - Edge infrastructure for storage and compute
	AWS Storage Gateway - Hybrid on prem AWS storage 
	CloudEndure - Disaster recovery service 
Analytics Service
	Athena - Serverless SQL Query in S3.
	CloudSearch - Search Solution for Websites and Apps
	ElasticSearch - Deploy and run ElasticSearch, commonly used for log analytics.
	EMR(Elastic MapReduce, ) - Big Data Platform and Analysis, big data frameworks for complex and unstructured data.
	Kenesis - Real-time streaming data capture and analysis
	Redshift - Data Warehouse Service (gigabytes to a petabyte)uses SQL to analyze structured and semi-structured.
	QuickSight - Serverless ML BI Dashboards
	Data Exchange - Subscribe to 3rd Party Data Sets
	Data Pipeline - Transfer and process data
	Glue - Data discovery, enrichment and transfer
	AWS Lake Formation - Set up Data Lakes quickly
Application Integration Services
	Step Functions - Serverless Function Orchestration
	AppFlow - Integrate 3rd party app data,  securely transfer data between SaaS applications like 
	          Salesforce, SAP, Zendesk, Slack, and ServiceNow, and AWS services like Amazon S3 and  Redshift.
	EventBridge - Serverless Event Bus
	MQ - Message Broker Service for Apache/Rabbit MQ
	SNS - Simple Notification Messaging System
	SQS - Simple Queue Service Inter Component Messaging
	AppSync - GraphQL API Service
Cost Management Services
	AWS Cost Explorer - Visualize and manage AWS costs
	AWS Budgets - Service to set and monitor usage budgets
	AWS Cost and Usage Report - reporting to analyse AWS usage
BlockChain
	Amazon Managed Blockchain - Hyperledger & Ethereum Service
	Quantum Ledger DB (QLDB) - Fully managed financial ledger db

	
	


=================================================
#DataTransfer
================================================= 
One AWS account(or use) that want to communicate the resources in another account which can be achieved by:
	Cross-Account AssumeRole
	VPC Peering
	Resource Access Manager
	VPC endpoint service
	Transit Gateway
	
AWS DataSync:Copy Data correctly(Move data at onech).
	AWS DataSync is a secure, online service that automates and accelerates moving data between 
	on premises and AWS Storage services. 

DataSync can copy data between NFS shares,SMB shares, Hadoop Distributed File Systems (HDFS), 
self-managed object storage, 
Snowcone, S3 buckets,EFS file systems, FSx for Windows,FSx for Lustre, FSz for OpenZFS, 
and FSx for NetApp ONTAP file systems.


AWS Data Migration Service:
	AWS Data Migration Service copies data between databases, also send data to Amazon S3, 
	Amazon Kinesis and Apache Kafka.

AWS Database Migration Service (AWS DMS) is a cloud service that makes it easy to migrate 
relational databases, data warehouses, NoSQL databases, and other types of data stores. 
You can use AWS DMS to migrate your data into the AWS Cloud or between combinations of 
cloud and on-premises setups.


AWS Storage Gateway:
	AWS Storage Gateway provides a virtual storage device that stores data in the cloud 
	(on S3, Glacier, FSx, etc). Think of it as a cloud-backed H: drive with unlimited storage.


AWS Direct Connec:
	AWS Direct Connect links your office or data center to AWS via fiber. It's for high-speed, 
	permanent connectivity to the Cloud.

One end of the cable is connected to your router, the other to an AWS Direct Connect router. 
With this connection, you can create virtual interfaces directly to 
public AWS services S3 or to Amazon VPC, bypassing internet service providers in your network path.


AWS Site-to-Site VPN:
	AWS Site-to-Site VPN creates a VPN connection between your office or data center and 
	AWS via existing data connections. For example, it can create a VPN connection across your existing 
	Internet fiber connection.

A Site-to-Site VPN connection offers two VPN tunnels between a virtual private gateway or a 
transit gateway on the AWS side, 
and a customer gateway (which represents a VPN device) on the remote (on-premises) side.	

IPSec communications to create encrypted VPN tunnels between two locations. 
You cannot use AWS Site-to-Site VPN to integrate data files via the NFS interface.
	


=================================================
#Storage pricing | cost 
=================================================

	
EFS:
-------------------------------------------------
Serverless Elastic File System. for Linux Only.
Amazon EFS, you pay only for the resources that you use. 
The EFS Standard Storage pricing is $0.30 per GB per month. 



EBS:
-------------------------------------------------
EBS General Purpose SSD (gp2) volumes, the charges are $0.10 per GB-month of provisioned storage. 
Provisioned storage of 100GB for this use-case, the monthly cost on EBS is $0.10*100 = $10. 



S3:
-------------------------------------------------
A serverless, S3 Standard storage, the pricing is $0.023 per GB per month.





=================================================
#Noteable | Example | Topis | Tips | VIP
=================================================


#Resilient:স্থিতিস্থাপক
-------------------------------------------------
You can use Aurora replicas and CloudFront distribution to make the application more resilient to 
spikes in request rates.




#Availability:প্রাপ্যতা, লভ্যতা
-------------------------------------------------
If you have workloads that global client base, AWS recommends that you use Global Accelerator. 

If you have workloads hosted in a single AWS Region and used by clients in 
and around the same Region, you can use an 
Application Load Balancer or Network Load Balancer to manage your resources.



You can't enable termination protection for Spot Instances.


Network Firewall cannot directly integrate with the Application Load Balancer.
AWS WAF straightforward way of integrating with an ALB but not Network Firewall with an ALB.




AWS CodeDeploy:
	AWS CodeDeploy fully automates your software deployments, allowing you to deploy reliably and rapidly.

	AWS CodeDeploy is a fully managed developer tool that is used for deploying code from a code repository such as 
	GitHub or AWS CodeCommit. 
	You can deploy to many services including AWS services such as AWS Elastic Beanstalk, AWS Lambda, and AWS Fargate. 
	AWS CodeDeploy can be used independently or in a pipeline with AWS CodePipeline.

CodeDeploy is not meant to distribute traffic across instances.
CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, 
on-premises instances, serverless Lambda functions, or Amazon ECS services.





VPC Egress-Only  for IPv6:
	Launch the EC2 instance to a private subnet and attach an Egress-Only 
	Internet Gateway to the VPC to allow outbound IPv6 communication to the internet. 
	Use AWS Network Firewall to set up the required rules for traffic inspection and traffic filtering.
	
	
	
Internet Gateway does not limit or control any outgoing IPv6 connection.
NAT Gateway is only applicable for IPv4, not IPv6. 




AWS Proton:
	AWS Proton allows you to deploy any serverless or container-based application with increased efficiency, consistency, and control. 
	You can define infrastructure standards and effective continuous delivery pipelines for your organization. 
	Proton breaks down the infrastructure into environment and service (“infrastructure as code” templates).

AWS Proton allows customers to define application components as a stack, which creates everything needed to provision, 
deploy, and monitor an application, including compute, networking, code pipeline, security, and monitoring. 

AWS Proton associated with:
	Platform Team
	Developers
	Environment Templates
	Service Templates






Amazon Managed Service for Prometheus (AMP):
	 The Amazon Managed Service for Prometheus is only a Prometheus-compatible monitoring and alerting service that makes it easy 
	 to monitor containerized applications and infrastructure at scale.



Amazon Managed Service for Grafana (AMG):
	Amazon Managed Service for Grafana is a fully managed service with rich, interactive data visualizations to help 
	customers analyze, monitor, and alarm on metrics, logs, and traces across multiple data sources.
	
	
	

Amazon WorkDocs is more often used to easily create, edit, and share documents for collaboration and 
not for serving object data like Amazon S3.
	
 



Ensure that the database is eventually consistent and highly available:
	Configure the Auto Scaling group to spread the Amazon EC2 instances across three Availability Zones. 
	Use the AWS Database Migration Service (DMS) with a replication server and an ongoing replication 
	task to migrate the embedded NoSQL database to Amazon DynamoDB.




How ALB prevent SQL injection attacks:
	Use WAF and set up a managed rule to block request patterns associated with the exploitation 
	of SQL databases, like SQL injection attacks. Associate it with the Application Load Balancer. 
	Integrate AWS WAF with AWS Firewall Manager to reuse the rules across all the AWS accounts.




AWS Network Firewall is a managed service that makes it easy to deploy essential 
	network protections for all of your VPCs.




Route 53 Resolver DNS Firewall can only filter and regulate outbound DNS traffic from your VPC.
	It can neither do active traffic flow inspection nor block any vulnerability exploits.



Redshift(SQL Big data analyse) cluster as their data warehouse region outage or down:
	Enable Cross-Region Snapshots Copy in your Amazon Redshift Cluster.



Convert audio recordings into text using Amazon Transcribe. 
	Set up Amazon Translate to translate Hindi texts into English and use Amazon Comprehend for sentiment analysis.


Process both mission-critical data and non-essential batch jobs:
	Use ECS as the container management service then set up a combination of Reserved and 
	Spot EC2 Instances for processing mission-critical and non-essential batch jobs respectively.
    Scheduled Reserved Instances (Scheduled Instances).




S3 retrieve the required data in under 15 minutes under all circumstances 150 MB/s of retrieval throughput:
	Use Expedited Retrieval to access the financial data.
	Purchase provisioned retrieval capacity.

Expedited retrievals allow you to quickly access your data when occasional urgent requests 
for a subset of archives are required. For all but the largest archives (250 MB+), data accessed 
using Expedited retrievals are typically made available within 1–5 minutes. 

Provisioned capacity ensures that your retrieval capacity for expedited retrievals is available when you need it.




Collect and process the application log files:
Amazon S3 for storing the application log files and Elastic MapReduce(EMR) for processing the log files.




Fastest storage option with high I/O Performance for the temporary files:
	Configure RAID 0 in multiple instance store volumes.

RAID (Redundant Array of Independent Disks) is just a data storage virtualization technology 
that combines multiple storage devices to achieve higher performance or data durability.

RAID 0 configuration enables you to improve your storage volumes’ performance 
by distributing the I/O across the volumes in a stripe. 
	
This configuration can be implemented on both EBS or InstanceStore volumes. 

RAID 1 configuration is used for data mirroring. 
You need to configure RAID 0 to improve the performance of your storage volumes.




Following resources can be attach to your Transit Gateway:
	– One or more VPCs.
	– One or more VPN connections
	– One or more AWS Direct Connect gateways
	– One or more Transit Gateway Connect attachments
	– One or more Transit gateway peering connections
	


 
RDS if the primary database instance fails:
	The canonical name record (CNAME) is switched from the primary to standby instance.




For Single RDS security use SecurityGroup not Network ACL.
	Network ACL covers the entire subnet which means that other applications that use the same 
	subnet will also be affected.



A Kinesis data stream stores records from 24 hours by default to a maximum of 8760 hours (365 days).



ASG:
	With Step scaling, you choose scaling metrics and threshold values for the CloudWatch alarms that 
	trigger the scaling process as well as define how your scalable target should be scaled when a 
	threshold is in breach for a specified number of evaluation periods. Step scaling policies 
	increase or decrease the current capacity of a scalable target based on a set of scaling adjustments, 
	known as step adjustments. 



CloudWatch:
	By default, CloudWatch doesn’t monitor memory usage but only the -
	CPU utilization, Network utilization, Disk performance, and Disk Reads/Writes.

EC2 Detailed Monitoring does not provide metrics for memory usage,
just provides a higher frequency of metrics (1-minute frequency). 




AWS Transfer:
	Create an Amazon S3 bucket with encryption enabled. 
	Launch an AWS Transfer for SFTP endpoint to securely upload files to the S3 bucket. 
	Configure an S3 lifecycle rule to delete files after a month.




Storage optimized instances:
	Storage optimized instances are designed for workloads that require high, 
	sequential read and write access to very large data sets on local storage.

Memory Optimized Instances:
	Memory Optimized Instances are designed to deliver fast performance for workloads that process 
	large data sets in memory, which is quite different from handling 
	high read and write capacity on local storage.




EMR(Big Data Frameworks) previously called Amazon Elastic MapReduce:
	Amazon EMR is a managed cluster platform that simplifies running big data frameworks, such as 
	Apache Hadoop and Apache Spark, on AWS to process and analyze vast amounts of data.
	
By using these frameworks and related open-source projects, such as Apache Hive and Apache Pig, 
you can process data for analytics purposes and business intelligence workloads. 
Additionally, you can use Amazon EMR to transform and move large amounts of data into and out 
of other AWS data stores and databases.




Amazon Redshift is the most widely used cloud data warehouse:
	analyze all your data using standard SQL and your existing Business Intelligence (BI) tools. 
	It allows you to run complex analytic queries against terabytes to petabytes of 
	structured and semi-structured data, using sophisticated query optimization, columnar storage 
	on high-performance storage, and massively parallel query execution.



DynamoDB:
	DynamoDB doesn’t fully support the use of standard SQL and Business Intelligence (BI) tools, 
	unlike Amazon Redshift. It also doesn’t allow you to run complex analytic queries against 
	terabytes to petabytes of structured and semi-structured data.




Virtual Desktops:
	First, you need a VPN connection to connect the VPC and your on-premises network. 
	Second, you need AWS Directory Services to integrate with your on-premises Active Directory 
	and lastly, you need to use Amazon WorkSpace to create the needed Virtual Desktops in your VPC.




SAML 2.0:
	Before you can use SAML 2.0-based federation you must configure your organization’s IdP 
	and your AWS account to trust each other. 
	Inside your organization, you must have an IdP that supports SAML 2.0, 
	like Microsoft Active Directory Federation Service (AD FS, part of Windows Server), Shibboleth, 
	or another SAML 2.0 compatible provider.



DataSync:
	AWS DataSync is primarily used to migrate existing data to Amazon S3. 
	AWS Storage Gateway is more suitable if you still want to retain access to the migrated data 
	and for ongoing updates from your on-premises file-based applications.



Amazon EFS only supports file locking, Object lock is a feature of Amazon S3.



RDS Notification:
	Create a native function or a stored procedure that invokes a Lambda function. 
	Configure the Lambda function to send event notifications to an Amazon SQS queue for the 
	processing system to consume.





AWS Artifact:
	Use AWS Artifact to view the security reports as well as other AWS compliance-related information.
	AWS Artifact is your go-to, central resource for compliance-related information that matters to you. 
	It provides on-demand access to AWS’ security and compliance reports and select online agreements. 
	
Reports available in AWS Artifact include our Service Organization Control (SOC) reports, 
Payment Card Industry (PCI) reports, and certifications from accreditation bodies across 
geographies and compliance verticals that validate the implementation and operating effectiveness of 
AWS security controls. 
Agreements available in AWS Artifact include the Business Associate Addendum (BAA) and the 
Nondisclosure Agreement (NDA).




Create an Amazon S3 bucket with encryption enabled:
	Launch an AWS Transfer for SFTP endpoint to securely upload files to the S3 bucket. 
	Configure an S3 lifecycle rule to delete files after a month.
	There is no retention policy option on AWS Transfer for SFTP.



You can use EventBridge to run ECS tasks when certain AWS events occur.



AWS Control Tower (Multiple AWS accounts):
	AWS Control Tower service is primarily used to manage and govern multiple AWS accounts and not just S3.



ParallelCluster @(open-source cluster management tool):
	AWS ParallelCluster is simply an AWS-supported open-source cluster management tool that makes it easy 
	for you to deploy and manage High-Performance Computing (HPC) clusters on AWS.



AWS Proton @(“infrastructure as code” templates):
	AWS Proton allows you to deploy any serverless or container-based application with 
	increased efficiency, consistency, and control. 
	You can define infrastructure standards and effective continuous delivery pipelines for your organization. 
	Proton breaks down the infrastructure into environment and service.



Filter policies in SNS @(SNS Queue Filter):
	Create one Amazon SNS topic and configure the Amazon SQS queues to subscribe to the SNS topic. 
	Set the filter policies in the SNS subscriptions to publish the message to the 
	designated SQS queue based on its quote request type.





AWS Organizations and AD @(IAMIdentityCenter):
	On the master account, use AWS Organizations to create a new organization with all features turned on. 
	Invite the child accounts to this new organization.
	Configure AWS IAM Identity Center (AWS Single Sign-On) for the organization 
	and integrate it with the company’s directory service using the Active Directory Connector
	 
	Amazon Cognito is used for single sign-on in mobile and web applications. 
	You don’t have to use it if you already have an existing Directory Service to be used for authentication.
	 
User->OnPermDirectoryService(MS AD)->ActiveDirectoryConnector(ADTrust)->AWS IAMIdentityCenter(SSO)->access
	->AWSConsole
	->BusinessCloueApp
	->SAMLApplication





DynamoDB and AWS Backup: @(backups to another AWS account for disaster recovery):
	Create a DynamoDB gateway endpoint. Associate the endpoint to the appropriate route table. 
	Use AWS Backup to automatically copy the on-demand DynamoDB backups to another AWS account for disaster recovery.

	Point-in-Time Recovery (PITR) feature is not capable of restoring a DynamoDB table to a 
	particular point in time in a different AWS account.

DynamoDB on-demand backups cannot be copied to a different account or Region. 

To create backup copies across AWS accounts and Regions and for other advanced features, use AWS Backup.

Auto Scaling is not enabled in a DynamoDB table which is created using the AWS CLI.




Storage Gateway:
	Amazon Storage Gateway is used only for creating a backup of data from your on-premises server 
	and not from the Amazon services.

	Use AWS Storage Gateway to backup the data directly to Amazon S3 Glacier Deep Archive.
	Snowball Edge can’t directly integrate backups to S3 Glacier.




Roure53 pre-requirment when routing traffic:
	A registered domain name.
	The S3 bucket name must be the same as the domain name.
	No need The S3 bucket must be in the same region as the hosted zone.




Minimize the impact of DDoS attacks:
	Configure Amazon CloudFront distribution and set Application Load Balancer as the origin. 
	Create a rate-based web ACL rule using AWS WAF and associate it with Amazon CloudFront.

By using AWS WAF, you can configure web access control lists (Web ACLs) for your CloudFront distributions 
or Application Load Balancers to filter and block requests based on request signatures. 





Department base bill:
	Tag resources with the department name and enable cost allocation tags.




MySQL database needs to replicated in  S3 as CSV files:
	Create a full load and change data capture (CDC) replication task using AWS Database Migration Service (AWS DMS). 
	Add a new Certificate Authority (CA) certificate and create an AWS DMS endpoint with SSL.

When using Amazon S3 as a target in an AWS DMS task, both full load and change data capture (CDC) 
data is written to comma-separated value (.csv) format by default.




Snowball:
	AWS Snowball devices can upload the files to  S3. the primary goal is one-time migration of data to AWS 
	which can be accomplished by using AWS Snowball devices.



WorkDocs simply enables you to share content, provide rich feedback, and collaboratively edit documents.



ENI:
	If the instance fails, you (or more likely, the code running on your behalf) can attach 
	the network interface to a hot standby instance.
 
 
 
 
Detected Unauthorized person using Cameras, security team alerted via SMS:
	Use Amazon Kinesis Video to stream live feeds from the cameras. 
	Use Amazon Rekognition to detect unauthorized personnel. 
	Set the phone numbers of the security as subscribers to an SNS topic.

 
 
 
 
Amazon Fraud Detector:
	Amazon Fraud Detector is a fully managed service that identifies potentially fraudulent online activities 
	such as online payment fraud and fake account creation.

AWS Trusted Advisor only provides best practice recommendations. It cannot define rules for your AWS resources.





EBS volumes live configuration Change:
	EBS volumes support live configuration changes while in production, which means that you can modify 
	the volume type, volume size, and IOPS capacity without service interruptions.
	An EBS volume is off-instance storage that can persist independently from the life of an instance.



 
SQS and Amazon Simple Workflow Service (SWF) services for decoupled architecture in AWS. 
You can’t create a VPC peering for your on-premises network and AWS VPC.





AWS Control Tower:
	AWS Control Tower provides a single location to easily set up your new well-architected multi-account 
	environment and govern your AWS workloads with rules for security, operations, and internal compliance.
	
AWS Control Tower provides three methods for creating member accounts:
	– Through the Account Factory console that is part of AWS Service Catalog.
	– Through the Enroll account feature within AWS Control Tower.
	– From your AWS Control Tower landing zone’s management account, using Lambda code 
	  and appropriate IAM roles.

AWS Control Tower automatically implements guardrails using multiple building blocks such as 
AWS CloudFormation to establish a baseline, AWS Organizations service control policies (SCPs) 
to prevent configuration changes, and AWS Config rules to continuously detect non-conformance.





Systems Manager Parameter:
	Systems Manager Parameter Store doesn’t rotate its parameters by default.
	Use AWS Secrets Manager to store and encrypt the database credentials, API keys, and other secrets. 
	Enable automatic rotation for all of the credentials.

KMS is primarily used for encryption and not for hosting your credentials.





SQS @(retention period ):
	In Amazon SQS, you can configure the message retention period to a value from 1 minute to 14 days. 
	Default is 4 days. Once the message retention limit is reached, messages are automatically deleted.





Amazon Kinesis Data Firehose is a fully managed service for delivering real-time streaming data. 
Although it can stream data to an S3 bucket, it is not suitable to be used as a queue for a batch application.

Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. 
It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, 
and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you are already using today.





Amazon Redshift(data warehouse):
	Amazon Redshift is a fast( near real-time), scalable data warehouse that makes it simple and cost-effective 
	to analyze all your data across your data warehouse and data lake. 
	Redshift delivers ten times faster performance than other data warehouses by using machine learning, 
	massively parallel query execution, and columnar storage on a high-performance disk.



RealTime EC2 Log Processing:
	Create a Kinesis Data Stream and use AWS Lambda to read records from the data stream real-time.
	
Kinesis Data Firehose  near RealTime.
	Amazon Athena and Amazon Redshift(Analytics / BI / Data Warehouse) not RealTime processing.
Redshift is a relational database and best suited for tabular data; Athena is better for semi-structured and unstructured data.	
	




RDS Mysql: increase the disk space without impacting:
	Modify the DB instance settings and enable storage autoscaling.
	RDS Storage Auto Scaling automatically scales storage capacity in response to growing database workloads, with zero downtime.




ELB LogProcessing with EMR:
	Amazon S3 for storing ELB log files and Amazon EMR for analyzing the log files.
	You can also run other popular distributed frameworks such as Apache Spark, HBase, Presto, and Flink in Amazon EMR, 
	and interact with data in other AWS data stores such as Amazon S3 and Amazon DynamoDB.



The “Trust Relationship” policy simply defines which Principals can Assume the IAM Role and under which conditions.





Error:EC2ThrottledException:
	Your Lambda function automatically scales based on the number of events it processes. 
	If your Lambda function accesses a VPC, you must make sure that your VPC has sufficient ENI capacity 
	to support the scale requirements of your Lambda function. 





Route53:
	You can use Route 53 health checking to configure active-active and active-passive failover configurations. 

Active-Active Failover:
	In active-active failover, all the records that have the same name, the same type (such as A or AAAA), and the same routing policy 
	(such as weighted or latency) are active unless Route 53 considers them unhealthy. 
	Route 53 can respond to a DNS query using any healthy record.
	Active-Active Failover no parimary or secondary resource.

Active-Passive Failover:
	Use an active-passive failover configuration when you want a primary resource or group of resources to be available 
	the majority of the time and you want a secondary resource or group of resources to be on standby in case all the 
	primary resources become unavailable.






Aurora  Backup:
	Create an AWS Backup plan to take daily  Aurora snapshots with a retention period of 90 days.
	Maximum backup retention period for Aurora automated backup is only 35 days.



Aurora Instance class to Aurora Serverless:
	Use AWS Database Migration Service (AWS DMS) to migrate a new Aurora Serverless database.
	You can set up a DMS task for either one-time migration or ongoing replication.




AWS and On-Permiss Dedicated connection (With multi AWS acc):
	Create a new Direct Connect gateway and integrate it with the existing Direct Connect connection. 
	Set up a Transit Gateway between AWS accounts and associate it with the Direct Connect gateway.

VPC peering is not supported in a Direct Connect connection. VPC peering does not support transitive peering relationships.
 
VPN connection traverses the public Internet and doesn’t use a dedicated connection.




CloudFront Origin Access Identity (OAI) a feature ensures that  CloudFront can serve S3 content.
 
 
 

By default Network ACLs allow all inbound and outbound traffic.
By default Security group includes an outbound rule that allows all outbound traffic, no inbound rules. 




Kinesis Data Streams:
	Collect and process large streams of data records in real-time.
	The producers continually push data to Kinesis Data Streams, and the consumers process the data in real-time. 
	Consumers (such as a custom application running on Amazon EC2 or an Amazon Kinesis Data Firehose delivery stream) 
	can store their results using an AWS service such as  DynamoDB,  Redshift,  S3.


 
AWS Data Exchange is a data marketplace service. 
AWS Data Exchange is on a mission to increase speed to value for third-party data sets in the cloud.
 
 
 
Need to use a service that can store and retrieve objects through 
standard file storage protocols for quick recovery:
	  Use the AWS Storage Gateway file gateway to store all the backup data in Amazon S3.
	  You cannot directly access the volume gateway using Amazon S3 APIs.
	 
	 
	 
S3:
	Can access S3 buckets file using an S3 URL or through their CloudFront distribution:
	A better solution is to set up an origin access identity (OAI) then use Signed URL or Signed Cookies 
	in your CloudFront web distribution for Restrict access file.

S3 does not public event messages to Amazon MQ. You should use an Amazon SQS instead.

S3 supports 3 destinations where it can publish events:
	1. SNS topic
	2. SQS queue
	3. AWS Lambda






Retrieve a subset of data from a large CSV file stored in an S3: 
	Perform an S3 Select operation based on the bucket's name and object's key.
	
Metadata is not needed when querying subsets of data in an object using S3 Select. 
Tags just provide additional information to your object, not needed when querying with S3 Select although this can be useful 
for S3 Batch Operations. 
 
 
 
 
 
S3 Cross-account Permissions to copy objects from a source bucket in Account A to a destination bucket in Account B:
	– Attach a bucket policy to the source bucket in Account A.
	– Attach an AWS Identity and Access Management (IAM) policy to a user or role in Account B.
	– Use the IAM user or role in Account B to perform the cross-account copy.
	 
	 
 
Aurora DB cluster:
	A reader endpoint for an Aurora DB cluster provides load-balancing support for read-only connections to the DB cluster.
	Cluster endpoint (also known as a writer endpoint) simply connects to the current primary DB instance for that DB cluster.



Kinesis stream Retation periond(1 to 365):
	A Kinesis data stream stores records from 24 hours (1 day ) by default to a maximum of 8760 hours (365 days).
 
 
 
By default, Fargate tasks are given a minimum of 20 GiB of free ephemeral storage, 
	which meets the storage requirement in the scenario.



Interface endpoint vs Transit Gatewa:
	You pay an hourly rate for every provisioned Interface endpoint.
	AWS Transit Gatewa: VPCs and on-premises networks through a central hub.




RDS read-replica:
	RDS Replicas asynchronous replication and create read replicas within a Region or between Regions.




Tags:
	All AWS resources be tagged with a standard naming convention:
	Use an AWS Config rule to detect non-compliant tags.
	 



S3 Retrival within 15 minutes under all circumstances:
	If you require access to Expedited retrievals under all circumstances, you must purchase provisioned retrieval capacity.




ALB SSL MultipleCertificate:
	Upload all SSL certificates of the domains in the ALB using the console and bind multiple certificates to the 
	same secure listener on your load balancer. 
	ALB will automatically choose the optimal TLS certificate for each client using Server Name Indication (SNI).

Wildcard certificate can only handle multiple sub-domains but not different domains.
 



S3 decrypted by the Lambda function call:
	Attach the kms:decrypt permission to the Lambda function’s execution role. 
	Add a statement to the AWS KMS key’s policy that grants the function’s execution role the kms:decrypt permission.



The /32 denotes one IP address, and the /0 refers to the entire network.



AWS DataSync(moving data between on-premises and AWS storage services like S3,EFS):
	AWS DataSync does not work with Amazon EBS volumes.
	
	DataSync can copy data between Network File System (NFS) shares, Server Message Block (SMB) shares, self-managed object storage,
	AWS Snowcone, S3 buckets,Amazon EFS file systems, and Amazon FSx for Windows File Server file systems.

 


CloudFormation template:
	Needs to ensure that the required components are properly running before the stack creation proceeds:
	
	Configure a CreationPolicy attribute to the instance in the CloudFormation template. 
	Send a success signal after the applications are installed and configured using the cfn-signal helper script.

	UpdatePolicy attribute is primarily used for updating resources and for stack update rollback operations.
	
	UpdateReplacePolicy attribute is primarily used to retain or in some cases, back up the existing physical instance 
	of a resource when it is replaced during a stack update operation.



 

Avoid losing recently submitted requests:
	Use an Amazon SQS queue to decouple the application components and scale-out the EC2 instances based upon the 
	SqS ApproximateNumberOfMessages metric in Amazon CloudWatch.



Launch an  Group for each department. 
Create an IAM Policy that enforces MFA authentication with the least privilege permission. 
Attach the IAM Policy to each Group.




SCP:
	SCP can only be attached to the organization root, to an organizational unit (OU), or directly to an account, 
	but not directly in the IAM User. 

	IAM role Cannot directly associate with IAM user.
An IAM role is an IAM identity that you can create in your account that has specific permissions. An IAM role is similar to an IAM user.
	
Users and Groups use only Policies, You cannot attach Roles to it.

IAM User     = Single Account with credentials for login, e.g. JohnDoe
IAM Role     = Single Account without credentials, created for AWS Resources to "Assume".
IAM Group    = A collection of IAM Users.

IAM Policy   = Resource Access Rules.
Policies are added to Users, Roles, or Groups, to give them the permissions specified in the policy.




Secrets Manager Parameter vs Systems Manager Parameter:
	Secrets Manager there is a cost associated with using Store encrypted parameters with rotation. 
	If you are storing mostly application parameters, then the Systems Manager Parameter Store is a better fit
	with (AWS KMS) for the encryption.





You can’t have an Amazon S3 managed encryption key(SSE-S3) for client-side encryption.
– Set up Client-Side Encryption with a customer master key stored in AWS Key Management Service (AWS KMS).
– Set up Client-Side Encryption using a client-side master key.




Below are the valid EC2 lifecycle instance states:
	pending – The instance is preparing to enter the running state. 
		An instance enters the pending state when it launches for the first time, or when it is restarted after being in the stopped state.
	running – The instance is running and ready for use.
	stopping – The instance is preparing to be stopped. 
		Take note that you will not billed if it is preparing to stop however, you will still be billed if it is just preparing to hibernate.
	stopped – The instance is shut down and cannot be used. The instance can be restarted at any time.
	shutting-down – The instance is preparing to be terminated.
	terminated – The instance has been permanently deleted and cannot be restarted. 
		Take note that Reserved Instances that applied to terminated instances are still billed until the 
		end of their term according to their payment option.



VPC IP address allowed block(16-28) size in is between a /16 netmask (65,536 IP addresses) and /28 netmask (16 IP addresses)




EC2 Faster Boot:
	Migrate the application EC2 instance to an EC2 instance with hibernation enabled.
It is not possible to enable or disable hibernation for an instance after it has been launched.




50TB data transfer from on permiss:
	Request an Import Job to Amazon S3 using a Snowball device in the AWS Snowball Console.




GlobalRealTimeDataProcessing:
	Integrate CloudFront with Lambda@Edge in order to process the data in close geographical proximity to users 
	and respond to user requests at low latencies. 
	Process real-time streaming data using Kinesis and durably store the results to an Amazon S3 bucket.

CloudFront and Route 53 just do Geoproximity routing only not process date.
	By using Lambda@Edge and Kinesis together, you can process real-time streaming data so that you can track and analyze 
	globally-distributed user activity on your website and mobile applications, including clickstream analysis.





By using a Curl or Get Command to get the latest metadata information from http://169.254.169.254/latest/meta-data/
Like PrivatePublicIp





DynamoDB Streams:
	Enabling DynamoDB Streams to capture table activity and automatically trigger the Lambda function.

CloudWatch Alarms only monitor service metrics, not changes in DynamoDB table data.





Log file processing:
	S3 for storing the application log files and Amazon Elastic MapReduce(EMR | big data frameworks) for processing the log files.




SQS:
	Amazon (Default setting)SQS queue no order mentain of message as send or receive and 
	SQS does not guarantee that no duplicates will be sent.
	 
A Kinesis data stream is a set of shards that has a sequence of data records, and each data record has a sequence number 
and guarantee no duplicates.




AWS Data Pipeline:
	AWS Data Pipeline a cloud-based data workflow service that helps you process and move data between different 
	AWS services and on-premises data sources. 

It is not suitable for collecting data from distributed sources such as users, IoT devices, or clickstreams.




Hundred of EC2 instances Log Process:
	Install the Unified CloudWatch Logs agent in each instance which will automatically collect and push 
	data to CloudWatch Logs. Analyze the log data using CloudWatch Logs Insights.
	CloudWatch Logs Insights enables you to interactively search and analyze your log data in Amazon CloudWatch Logs. 




S3StaticResourcePublicAcc:
	Grant public read access to the object when uploading it using the S3 Console.
	Configure the S3 bucket policy to set all objects to public read.
	
An IAM Role, in itself, cannot directly make the S3 objects public or change the permissions of each individual object.





Differences between Fault Tolerance and High Availability is that:
	Fault tolarance refers to the minimum number of running instances is .like Need 4 and runing 4
	If Need 4 and runing 2 Its High available.





Dashboard for continuous detection of policy non-conformance and non-compliant 
resources across the enterprise and AWS multi-account strategy best practices ?

AWS Control Tower:
	Use AWS Control Tower to launch a landing zone to automatically provision and configure new accounts through an Account Factory. 
	Utilize the AWS Control Tower dashboard to monitor provisioned accounts across your enterprise. 
	Set up preventive and detective guardrails for policy enforcement.


AWS Control Tower offers a straightforward way to set up and govern an AWS multi-account environment, 
following prescriptive best practices. 

AWS Control Tower orchestrates the capabilities of several other AWS services, including AWS Organizations, AWS Service Catalog, 
and AWS Single Sign-On, to build a landing zone in less than an hour.
 
It offers a dashboard to see provisioned accounts across your enterprise, guardrails enabled for policy enforcement, 
guardrails enabled for continuous detection of policy non-conformance, and non-compliant resources organized by accounts and OUs.

When users perform work in any AWS account in your landing zone, they’re always subject to the guardrails 
that are governing their account’s OU.

The AWS Organizations service neither has the capability to build a landing zone nor a built-in dashboard ,
for continuous detection of policy non-conformance and non-compliant resources across the enterprise.






ElasticBeanstalk environments have limited resources; for example, ElasticBeanstalk does not create a VPC for you.
 
 
 
 
Increase acc time of Websit remove slow ness:
	– Use Amazon CloudFront with website as the custom origin.
	– Use Amazon ElastiCache for the website’s in-memory data store or cache.



Redshift is primarily used for OLAP (Online Analytical Processing).
Amazon RDS Read Replica of OLTP (Online Transactional Processing).



NAT gateway:
	You must specify an Elastic IP address to associate with the NAT gateway when you create it. 
	The Elastic IP address cannot be changed once you associate it with the NAT Gateway.



Regional Failover and High available:
	In a secondary region, create a global table of the DynamoDB table and replicate, auto-scaling group and application load balancer.
	Use Route 53 DNS failover to automatically route traffic to the resources in the secondary region. 
	Set up the AWS Well-Architected Tool to easily get recommendations for improving your workloads based on the AWS best practices.

A global secondary index can only be created in the region where its parent table resides.
 



 
When you create or update a distribution in CloudFront, you can add an origin access identity (OAI) and automatically update 
the bucket policy to give the origin access identity permission to access your bucket.

Alternatively, you can choose to manually change the bucket policy or change ACLs, which control permissions 
on individual objects in your bucket.
 
 
 



VPNs peering multiple regions:
	To interconnect all of the company’s on-premises networks, VPNs, and VPCs into a single gateway, 
	which includes support for inter-region peering across multiple AWS regions.

	Set up an AWS Transit Gateway in each region to interconnect all networks within it. 
	Then, route traffic between the Transit gateways through a peering connection.

If you attach a transit gateway peering connection, the transit gateway must be in a different Region.




Athena:
	Athena is an interactive query service that makes it easy to analyze data directly in S3 using standard SQL.
	Athena helps you analyze unstructured, semi-structured, and structured data stored in Amazon S3. 
	Examples include CSV, JSON, or columnar data formats such as Apache Parquet and Apache ORC. 
	You can use Athena to run ad-hoc queries using ANSI SQL without the need to aggregate or load the data into Athena.





RabbitMQ cluster:
	A cluster deployment is a logical grouping of three RabbitMQ broker nodes behind a Network Load Balancer, 
	each sharing users, queues, and a distributed state across multiple Availability Zones (AZ).



DataSync:
	AWS DataSync simplifies, automates, and accelerates copying large amounts of data to and from AWS storage services 
	over the internet or AWS Direct Connect. 
	
You deploy an DataSync agent to on-premises hypervisor or in Amazon EC2. To copy data to or from an on-premises file server.
To set up transfers between Snowcone device and AWS storage, use the DataSync agent AMI that comes pre-installed on your device.




To connect programmatically to an AWS service, you will need to use an AWS Direct Connect service endpoint.
No data transfer cost between S3 and EC2 in the same AWS Region.




LDAP to IAM:
	IAM policy is not enough to integrate your LDAP service to IAM. You need to use SAML, STS, or a custom identity broker.
	
	If your identity store is not compatible with SAML 2.0 then you can build a custom identity broker application 
	to perform a similar function.
	Develop an on-premises custom identity broker application and use STS to issue short-lived AWS credentials.
	


Elastic Fabric Adapter EFA not work for Windows:
	The OS-bypass capabilities of EFAs are not supported on Windows instances. 
	If you attach an EFA to a Windows instance, the instance functions as an Elastic Network Adapter without the added EFA capabilities.




Amazon S3 Anslysis tools:
	S3 Select
		Amazon S3 Select is designed to help analyze and process data within an object in Amazon S3 buckets, faster and cheaper.
	Amazon Athena
		Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL expressions.
		Simply point to your data in Amazon S3, define the schema, and start querying using standard SQL expressions. 
	Amazon Redshift Spectrum
		Redshift also includes Redshift Spectrum, allowing you to directly run SQL queries against exabytes of unstructured 
		data in Amazon S3. No loading or transformation is required, and you can use open data formats, 
		including Avro, CSV, Grok, ORC, Parquet, RCFile, RegexSerDe, SequenceFile, TextFile, and TSV.




Redshift disaster recovery:
	Enable Cross-Region Snapshots Copy in your Amazon Redshift Cluster.
	automated snapshots is not enough and will not be available in case the entire AWS region is down.
	You can configure Amazon Redshift to copy snapshots for a cluster to another region. 
	To configure cross-region snapshot copy, you need to enable this copy feature for each cluster and configure 
	where to copy snapshots and how long to keep copied automated snapshots in the destination region. 

When a cross-region copy is enabled for a cluster, all new manual and automatic snapshots are copied to the specified region.





High I/O performance for the EC2 temporary files:
	Configure RAID 0 in multiple instance store volumes. RAID 1 configuration is used for data mirroring. 




S3 upload encryption obj:
	Create an S3 bucket policy that denies permissions to upload an object unless the request includes 
	the s3:x-amz-server-side-encryption": "AES256" header. 
	
	Enable server-side encryption with Amazon S3-managed encryption keys (SSE-S3) and rely on the built-in key rotation feature 
	of the SSE-S3 encryption keys.





Deactivating and deleting any IAM user access key that is over 90 days old:
	Amazon EventBridge cannot directly check for IAM events that show the age of IAM access keys.
	
	Use the AWS Config managed rule to check if the IAM user access keys are not rotated within 90 days. 
	Create an Amazon EventBridge (Amazon CloudWatch Events) rule for the non-compliant keys, and define a target to invoke 
	a custom Lambda function to deactivate and delete the keys.





AWS Health:
	AWS Health provides ongoing visibility into your resource performance and the availability of your AWS services and accounts. 
	You can use AWS Health events to learn how service and resource changes might affect your applications running on AWS. 
	
	AWS Health provides relevant and timely information to help you manage events in progress. 
	AWS Health also helps you be aware of and to prepare for planned activities.
	
	Use EventBridge to detect and react to AWS Health events. Then, based on the rules that you create, 
	EventBridge invokes one or more target actions. 
	
	
Your account Healt/events page shows all events from the past 90 days.
AWS Service Health Dashboard shows public events that may affect several customers in particular regions. 
It doesn’t show events related to specific EC2 instances on individual AWS accounts.






Comprehend Medical and Textract:
	Use Amazon Textract to extract the text from the PDF reports. Integrate Comprehend Medical with the existing Lambda function 
	to identify the PHI from the extracted text.
	
	The PII (Personally Identifiable Information) redaction feature of the Amazon Textract Medical service is not enough to 
	identify all the Protected Health Information (PHI) in the PDF reports. Take note that PII is quite different from PHI.





Max IOPS for volume is 10 GiB (50:1):Set the IOPS to 500 then maintain a low queue length.

	An io1 volume can range in size from 4 GiB to 16 TiB. 
	You can provision from 100 IOPS up to 64,000 IOPS per volume on Nitro system instance families and up to 32,000 on 
	other instance families. The maximum ratio of provisioned IOPS to the requested volume size (in GiB) is 50:1.
	
	For example, a 100 GiB volume can be provisioned with up to 5,000 IOPS. 
	On a supported instance type, any volume 1,280 GiB in size or greater allows provisioning up to the 64,000 IOPS 
	maximum (50 × 1,280 GiB = 64,000).

The volume queue length is the number of pending I/O requests for a device.






EBS Multi-attach Not multi AZ:
	Multi-attach feature can only be enabled on EBS Provisioned IOPS io2 or io1 volumes. 
	In addition, multi-attach won’t offer multi-az resiliency because this feature only allows an EBS volume to be attached on 
	multiple instances within a availability zone (AZ).

EBS provides three volume types to best meet the needs of your workloads: 
	General Purpose (SSD), 
	Provisioned IOPS (SSD), 
	and Magnetic.





AWS Config:
	Configure AWS Config to trigger an evaluation that will check the compliance for a user’s password periodically.

AWS Control Tower is used to simplify the creation of new accounts with preconfigured constraints. 
It isn’t used to automate application deployments. Moreover, AWS Config is commonly used for 
monitoring the changes of AWS resources and not the custom resources for serverless or 
container-based applications in AWS.






Enable S3 server access logging:
	Server access logging provides detailed records for the requests that are made to a S3 bucket.
	
	Track and log every request access to their S3 buckets including the requester, bucket name, request time, request action, 
	referrer, turnaround time, and error code information, Enable server access logging for all required Amazon S3 buckets.

AWS CloudTrail logs provide a record of actions taken by a user, role, or an AWS service in Amazon S3, 
while S3 server access logs provide detailed records for the requests that are made to an S3 bucket.

AWS CloudTrail alone won’t give detailed logging information for object-level access.






Migrate all of its VM workloads to the AWS cloud:
	Install the AWS Replication Agent on each of the on-premises VMs to continuously replicate the servers to AWS. 
	Use AWS Migration Service (AWS MGN) to launch test instances and perform cutover once testing is completed.
	
AWS MGN(Application Migration Service)is the primary migration service recommended for lift-and-shift migrations to AWS.


The AWS Application Discovery Service is primarily used to track the migration status, 
This service is not capable of doing the actual migration.






Enhanced Monitoring:
	RDS Enhanced Monitoring metrics shown in the Process List:
	RDS Process,RDS child Process,OS Process.

Enhanced Monitoring metrics are useful when you want to see how different processes or threads on a DB instance use the CPU.

RDS provides metrics in real-time for the operating system (OS) that your DB instance runs on. 
You can view the metrics for your DB instance using the console or consume the Enhanced Monitoring JSON output






Where can you safely import the SSL/TLS certificate of your application?
	IAM Certificate store, 
	AWS Certificate Manager.
	
If you got your certificate from a third-party CA, import the certificate into ACM or upload it to the IAM Certificate store.

ACM lets you import third-party certificates from the ACM console, as well as programmatically. 
If ACM is not available in your region, use AWS CLI to upload your third-party certificate to the IAM Certificate store.


Audit Trail for SSE-KMS Key Uses:
	Envelope encryption, Encryption with AWS KMS-Managed Keys (SSE-KMS).

	Customer-Provided Keys (SSE-C),Amazon S3-Managed Keys (SSE-S3): these two do not provide you with an audit trail 
	that shows when your CMK was used and by whom, unlike Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS).






Two AWS services are issuing and deploying X.509 Certificates:
ACM Private CA—
	Certificates issued by a private CA are trusted only within your organization, not on the internet.
	With ACM Private CA, you can create your own CA hierarchy and issue certificates with it for authenticating internal users, 
	computers, applications, services, servers, and other devices and for signing computer code.

ACM Public CA—
	ACM public certificates for enterprise customers who need a publicly trusted secure web presence using TLS. 
	You can deploy ACM certificates into AWS Elastic Load Balancing, CloudFront, API Gateway, and other integrated services. 
	
	AWS Certificate Manager (ACM), you can import certificates that you obtained outside of AWS.
	Multiple certificates with the same domain name can be imported, but they must be imported one at a time.





Secure Connected RDS for MySQ:
	Use IAM DB Authentication and create database accounts using the AWS-provided AWSAuthenticationPlugin plugin in MySQL.

You can authenticate DB instance using IAM database authentication. IAM database authentication works with MySQL and PostgreSQL. 
AWS-provided plugin that works seamlessly with IAM to authenticate your IAM users. 





Allows or blocks web requests:
	A geo match condition lists countries that your requests originate from.

Using AWS WAF: 
	Create a web ACL with a rule that explicitly allows requests from approved IP addresses declared in an IP Set.
	Add another rule  geo match condition that blocks requests that originate from a specific country.
	
If you want to prioritize resources for users in a particular country, you could include a geo-match condition in 
	two different rate-based rules. 
Set a higher rate limit for users in the preferred country and set a lower rate limit for all other users.


If you are using the CloudFront geo restriction feature to block a country from accessing your content, 
any request from that country is blocked and is not forwarded to AWS WAF Classic. 

So if you want to allow or block requests based on geography plus other AWS WAF Classic conditions, 
you should not use the CloudFront geo restriction feature. Instead, you should use an AWS WAF Classic geo match condition.


ALB listener rule, It only determines how the load balancer routes the requests to its registered targets.
You can’t configure a geo match condition in an Application Load Balancer. 







AWS Trusted Advisor:
	AWS Trusted Advisor is an online tool that provides real-time guidance and resources best practices. 
	It inspects your AWS environment and makes recommendations for saving money, improving system performance and reliability, 
	or closing security gaps.

AWS Cost Explorer:
	AWS Cost Explorer a tool that enables you to view and analyze your costs and usage.
	It has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time.





SimpleDB vs DynamoDB:
	SimpleDB is a highly available and scalable NoSQL database, it has a limit on the request capacity or storage size 
	for a given table, unlike DynamoDB.

	DynamoDB is use this to have an ACID-compliant database, it is not capable of handling complex queries and highly 
	transactional (OLTP) workloads.





RDS vs Aurora:
	RDS not scalable to handle the growth of the database. 
	Aurora is the better choice as its underlying storage can grow automatically as needed.




Virtual Desktops:
	VPN connection to connect the VPC and your on-premises network. 
	Second, you need AWS Directory Services to integrate with your on-premises Active Directory and a
	Amazon Workspace to create the needed virtual desktops in your VPC.





Enhanced Networking vs ParallelCluster:
	Enable Enhanced Networking with Elastic Network Adapter (ENA) on the Windows EC2 Instances.
	Enhanced networking provides higher bandwidth, higher packet per second (PPS) performance, and consistently lower 
	inter-instance latencies. There is no additional charge for using enhanced networking.
	 
ParallelCluster:
	AWS ParallelCluster is just an AWS-supported open-source cluster management tool that makes it easy for you to deploy and manage 
	High-Performance Computing (HPC) clusters on AWS. 

It not provide higher bandwidth, higher packet per second (PPS) performance, and lower inter-instance latencies, unlike ENA or EFA.





ALB  health check with HTTP and HTTPS.
NLB and CLB health check with TCP is only.




IAM roles are global:
	Assign the existing IAM role to instances in the new region. IAM roles are global services that are available to all regions.





Block the IP addresses at subnet layer using Network Access Control List (ACLs):
	You can associate a network ACL with multiple subnets; however, a subnet can be associated with only one network ACL at a time. 
	When you associate a network ACL with a subnet, the previous association is removed.

Create a Web ACL rule in AWS WAF to block the specified country. Associate this rule to the Application Load Balancers. 






A static Anycast IP address is primarily used by AWS Global Accelerator to enable organizations to route traffic seamlessly 
to multiple regions and improve availability and performance for their end-users.






AppSync:
	AWS AppSync is a serverless GraphQL and Pub/Sub API service that simplifies building modern web and mobile applications. 
	It provides a robust, scalable GraphQL interface for application developers to combine data from multiple sources, 
	including Amazon DynamoDB, AWS Lambda, and HTTP APIs.
	
Develop the application using the AWS AppSync service and use its built-in custom domain feature. 
Associate an SSL certificate to the AWS AppSync API using the AWS Certificate Manager (ACM) service to enable HTTPS communication.

When you configure an AWS AppSync API, Its provisioned two endpoints:
	AWS AppSync GraphQL endpoint:
	AWS AppSync real-time endpoint:





SQS Short or Long polling:
	The ReceiveMessageWaitTimeSeconds is the queue attribute that determines whether you are using Short or Long polling. 
	By default, its value is zero which means it is using Short polling. 
	If it is set to a value greater than zero, then it is Long polling.
	
The default visibility timeout for a message is 30 seconds. The maximum is 12 hours in SQS.






Step scaling:
	With step scaling, you choose scaling metrics and threshold values for the CloudWatch alarms that trigger the scaling process 
	as well as define how scalable target should be scaled when a threshold is in breach for a specified number of evaluation periods. 

Step scaling policies increase or decrease the current capacity of a scalable target based on a set of scaling adjustments, 
known as step adjustments. 
 
Scaling up and down multiple times:
	Change the cooldown period of the Auto Scaling group and set the CloudWatch metric to a higher threshold.
 
 
 
 
 
Aurora failure on the primary database instance for failover:
	Aurora will attempt to create a new DB Instance in the same Availability Zone as the original instance 
	and is done on a best-effort basis.

If you have an Amazon Aurora Replica in the same or a different Availability Zone, when failing over, 
Amazon Aurora flips the canonical name record (CNAME) for your DB Instance to point at the healthy replica, 
which in turn is promoted to become the new primary. Start-to-finish failover typically completes within 30 seconds.

If you are running Aurora Serverless and the DB instance or AZ becomes unavailable, 
Aurora will automatically recreate the DB instance in a different AZ.

If you do not have an Amazon Aurora Replica (i.e., single instance) and are not running Aurora Serverless, 
Aurora will attempt to create a new DB Instance in the same Availability Zone as the original instance. 

For Single instance, no read repllica, Aurora will first attempt to create a new DB Instance in the same Availability Zone 
as the original instance. If unable to do so, Aurora will attempt to create a new DB Instance in a 
different Availability Zone and not the other way around.
 
 
 
 
 
 
Test new version of Application with  50/50 request:
	Use an Application Elastic Load balancer with Weighted Target Groups to divert and proportion the traffic between the 
	on-premises and AWS-hosted application.
	OR
	Use Route 53 with Weighted routing policy to divert the traffic between the on-premises and AWS-hosted application. 

Network Load balancer doesn’t have Weighted Target Groups.
 
 
 
 
IP addresses from one of the following CIDR blocks:
– 10.0.0.0/8 (RFC 1918)
– 100.64.0.0/10 (RFC 6598)
– 172.16.0.0/12 (RFC 1918)
– 192.168.0.0/16 (RFC 1918)


 
 
 
 
 
 
 
Heterogeneous migrations a two step process.:
	Heterogeneous database migration in which you need to transform your on-premises Oracle database to PostgreSQL in AWS:
	
	First, use the AWS Schema Conversion Tool to convert the source schema and application code to match that of the target database, 
	and then use the AWS Database Migration Service to migrate data from the source database to the target database.



 
Route53:
	If you have multiple web servers running on EC2 instances behind an Elastic Load Balancing load balancer, 

	Route 53 will route all traffic addressed to your website (e.g. www.tutorialsdojo.com) to the load balancer 
	DNS name (e.g. elbtutorialsdojo123.elb.amazonaws.com).

CNAME records cannot be created for your zone apex. 
You should create an alias record at the top node of a DNS namespace which is also known as the zone apex. 

For example, if you register the DNS name tutorialsdojo.com, the zone apex is tutorialsdojo.com. 
You can’t create a CNAME record directly for tutorialsdojo.com, but you can create an alias record for tutorialsdojo.com 
that routes traffic to www.tutorialsdojo.com.




Most AWS services use VPC Interface Endpoint, VPC Gateway Endpoint only for S3 and DynamoDB.
  
  
 
AWS Storage Gateway vs DataSync:
	Integrate or replicate the data->AWS Storage Gateway
	Migrate or move data->DataSync 

Set up AWS DataSync to move the existing health records from the on-premises network to the AWS Cloud. 
Launch a new Amazon S3 bucket to store existing and new records. 

Enable AWS CloudTrail with Data Events and Amazon S3 Object Lock in the bucket.

Amazon Storage Gateway:
	File Gateway (NFS)
	Volume Gateway (iSCSI)
	Tape Gateway (VTL)

A File Gateway is a type of Storage Gateway used to integrate your existing on-premise application with the Amazon S3. 
It provides NFS (Network File System) and SMB (Server Message Block) access to data in S3.


Archive on S3 and frequently accessed data locally on their on-premises server:
Use the Amazon Storage Gateway – Cached Volumes.

Volume Gateway stores and manages on-premises data in Amazon S3  either cache mode or stored mode.
Point-in-time backups of your volumes stored as EBS snapshots and come in two different operational modes: stored and cached.





SQS:
	SQS has automatically deleted the messages that have been in a queue for more than the maximum message retention period.
	The default message retention period is 4 days max 14 days.





S3 Time Constraint Transitioning:
	Set a lifecycle policy in the bucket to transition to S3 – Standard IA after 30 days
	Set a lifecycle policy in the bucket to transition the data from Standard storage class to Glacier after one week (7 days).

Only change the storage class of your objects 
	From S3 Standard storage class to STANDARD_IA or ONEZONE_IA storage after 30 days. 
	This limitation does not apply to INTELLIGENT_TIERING, GLACIER, and DEEP_ARCHIVE storage class.

The following constraints apply from Standard storage class to STANDARD_IA or ONEZONE_IA:
	1)not transition objects that are smaller than 128 KB to the STANDARD_IA or ONEZONE_IA.
	2)Objects must be stored for at least 30 days in the current storage class before you can transition them to STANDARD_IA or ONEZONE_IA.
	3)(in versioned buckets), you can transition only objects that are at least 30 days noncurrent to STANDARD_IA or ONEZONE_IA storage.





EBS Encryption at rest:
	using your own keys in AWS Key Management Service (KMS) and using Amazon-managed keys in AWS Key Management Service (KMS).




Step scaling:
	Step scaling applies “step adjustments” which means you can set multiple actions to vary the scaling 
	depending on the size of the alarm breach. 
	
When you create a step scaling policy, you can also specify the number of seconds that it takes for a newly launched instance to warm up.






AWS Systems Manager Run Command:
	AWS Systems Manager is a useful and powerful tool that allows organizations to operate complex infrastructure at scale, 
	both safely and securely.

	Systems Manager provides an operations console and APIs for centralized application and resource management in hybrid environments.

	AWS Systems Manager Run Command lets you remotely and securely manage the configuration of your managed instances. 
	A managed instance is any Amazon EC2 instance or on-premises machine in your hybrid environment that has been 
	configured for Systems Manager.

You can use Run Command from the AWS console, the AWS Command Line Interface, AWS Tools for Windows PowerShell, or the AWS SDKs. 
Run Command is offered at no additional cost.





 
AWS has an example of the implementation of Quota Monitor CloudFormation template that you can deploy on your AWS account. 
The template uses an AWS Lambda function that runs once every 24 hours.






Trusted Advisor:
	The AWS Trusted Advisor Service limit publishes- service limits metric to CloudWatch; 
	thus, you can configure an alarm and send a notification to Amazon SNS. 

	You can also create an AWS Lambda function to read data from specific Trusted Advisor checks. 
	A Lambda function invocation can be scheduled using AWS EventBridge (Amazon CloudWatch Events) to automated the process.




Use ECS as the container management service then set up a combination of Reserved and Spot EC2 Instances for processing 
mission-critical and non-essential batch jobs respectively.




During peak hours, many employees are experiencing slow connectivity issues:
	Associate the VPCs to an Equal Cost Multipath Routing (ECMR)-enabled Transit gateway and attach additional VPN tunnels.
	The maximum tunnel for a VPN connection is 2-two.
	 
	 
 
 



CloudTrail log processing:
	CloudTrail stores the log files to S3 and not in Glacier.
	By default, CloudTrail event log files are encrypted using Amazon S3 server-side encryption (SSE). 

You can also define Amazon S3 lifecycle rules to archive or delete log files automatically. 
If you want notifications about log file delivery and validation, you can set up Amazon SNS notifications.

Upload the data to S3 and set a lifecycle policy to transition data to Glacier after 0 days.
 
 
 
 
 
CloudHSM:
	Amazon strongly recommends that you use two or more HSMs, in separate Availability Zones, 
	in any production CloudHSM Cluster to avoid loss of cryptographic keys.





Access logs on the Application Load Balancer:
	Elastic Load Balancing provides access logs that capture detailed information about requests sent to your load balancer.
	Enable access logs on the Application Load Balancer. 

Integrate the ECS cluster with Amazon CloudWatch Application Insights to analyze traffic patterns and simplify troubleshooting.





Amazon FSx Windows File Server can scale out storage to hundreds of petabytes of data with tens of GB/s of throughput performance 
and millions of IOPS. 
Amazon EFS can only handle Linux workloads.





EKS cluster authentication:
	Kubernetes cluster and have role-based access control (RBAC) access to IAM users and roles for cluster authentication.
	single-digit millisecond latency:

Launch the application to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. 
Create node groups in Wavelength Zones for the Amazon EKS cluster via the AWS Wavelength service. 
Apply the AWS authenticator configuration map (aws-auth ConfigMap) to your cluster.

AWS Wavelength:
	AWS Wavelength combines the high bandwidth and ultralow latency of 5G networks with AWS compute and storage services 
	so that developers can innovate and build a new class of applications.

An Amazon EKS connector agent is only used to connect your externally hosted Kubernetes clusters and to allow them to be 
viewed in your AWS Management Console.
 
 
 
 
 
 
Network Firewall:
	Create a firewall using the AWS Network Firewall service at the VPC level then add custom rule groups for inspecting 
	ingress and egress traffic. Update the necessary VPC route tables.
	
Firewall must be created at the VPC level and not at the subnet level.
Network ACLs to control access to your subnets.
Security group for your EC2.	 
 
 
 
 
EC2 Terminating log save:
	Add a lifecycle hook to your Auto Scaling group to move instances in the Terminating state to the Terminating:Wait state 
	to delay the termination of unhealthy Amazon EC2 instances. 
	
Configure a CloudWatch Events rule for the EC2 Instance-terminate Lifecycle Action Auto Scaling Event with an associated Lambda. 
Trigger the CloudWatch agent to push the application logs and then resume the instance termination once all the logs are sent 
to CloudWatch Logs.





To collect logs from your Amazon EC2 instances and on-premises servers into CloudWatch Logs, AWS offers two options:
	Recommended – The unified CloudWatch agent.
	Supported, but deprecation – The older CloudWatch Logs agent(only Linux servers ).
	
Using  CloudWatch agent to collect metrics and logs from Amazon EC2 instances and on-premises servers.
Unified CloudWatch agent enables you to: 
	Collect internal system-level metrics from Amazon EC2 instances across operating systems also EC2 logs.
	
CloudWatch Agent enables you to collect and export host-level metrics and logs on instances running Linux or Windows server.





Dedicated physical server that doesn’t use virtualization,NFS protocol:
	Use an AWS Storage Gateway hardware appliance for your compute resources. 
	Configure File Gateway to store the application data and create an S3 bucket to store a backup of your data.

Among the AWS Storage Gateway storage solutions, only File Gateway can store and retrieve objects in S3 using the protocols NFS and SMB.

File Gateway is used to store and retrieve Amazon S3 objects through NFS and SMB protocols.

EFS for rapidly changing data and 1000 Linux servers.






There are two options for Volume Gateway iSCSI block :
	Cached Volumes – you store volume data in AWS, with a small portion of recently accessed data in the cache on-premises.
	Stored Volumes – you store the entire set of volume data on-premises and store periodic point-in-time backups (snapshots) in AWS.




By default, IAM users don’t have permission to create or modify Amazon EC2 resources or perform tasks using the EC2 API. 
(This means that they also can’t do so using the Amazon EC2 console or CLI.)
To allow IAM users to create or modify resources and perform tasks, you must create IAM policies that grant IAM users.






Messages are processed within a specific time period:
	Use a AMI to set up an Auto Scaling group and configure a target tracking scaling policy based on the
	SQS ApproximateAgeOfOldestMessage metric.

CPUUtilization metric is not meant for time-sensitive messages where you need to ensure that the messages are processed 
within a specific time period.

The ApproximateAgeOfOldestMessage metric is useful when applications have time-sensitive messages and you need to ensure 
that messages are processed within a specific time period. 





Due to S3 data volume, most queries take a long time to complete:
	Transform the JSON data into Apache Parque format. 
	Ensure that the user has an lakeformation:GetDataAccess IAM permission for underlying data access control.






ECS service’s memory and CPU utilization:
	Create an AWS Auto Scaling policy that scales out the ECS service when the service’s memory utilization is too high.
	Create an AWS Auto Scaling policy that scales out the ECS cluster when the cluster’s CPU utilization is too high.

ECS service and ECS container instance  metric are:

ECS Container Instances Metric:
	CPU Utilization
	Disk Reads
	Disk Read Operations
	Disk Writes
	Disk Write Operations
	Network In
	Network Out
	Status Check Failed (Any)
	Status Check Failed (Instance)
	Status Check Failed (System)
	
ECS Service Metric:
	ECSServiceAverageCPUUtilization—Average CPU utilization of the service.
	ECSServiceAverageMemoryUtilization—Average memory utilization of the service.
	
	
	
	
ALBRequestCountPerTarget—Number of requests completed per target in an Application Load Balancer target group.
By default, data records in Kinesis are only accessible for 24 hours from the time they are added to a stream.




ElasticBeanstalk, where does it store the application files and server log files?
	Application files are stored in S3. The server log files can also optionally be stored in S3 or in CloudWatch Logs.



CloudFront app Hig availability:The scenario uses an EC2 instance as an origin or CloudFront. 
	Provision two EC2 instances deployed in different Availability Zones and configure them to be part of an origin group.
	To achieve high availability in an EC2 instance, we need to deploy the instances in two or more Availability Zones. 
	You also need to configure the instances to be part of the origin group to ensure that the application is highly available.



S3 File Gateway presents  NFS and SMB protocols.
	Use an AWS Storage File gateway with enough storage to keep data from the last 48 hours. 
	Send the backups to an SMB share mounted as a local disk.

Owner full access to all uploaded objects in the S3 bucket by oterh user:
	Create a bucket policy that will require the users to set the object’s ACL to bucket-owner-full-control.





Amazon Pinpoint:
	Pinpoint is a flexible, scalable marketing communications service that connects you with customers over email, SMS, 
	push notifications, or voice.
	Amazon Pinpoint can send event data to Kinesis Data Firehose, which streams this data to AWS data stores such as 
	Amazon S3 or Amazon Redshift. 
	Amazon Pinpoint can also stream data to Kinesis Data Streams, which ingests and stores multiple data streams 
	for processing by analytics applications.

	The Amazon Pinpoint event stream includes information about user interactions with applications (apps) that you connect to 
	Amazon Pinpoint. 
	
It also includes information about all the messages that you send from campaigns, through any channel, and from journeys. 
This can also include any custom events that you’ve defined. 
Finally, it includes information about all the transactional email and SMS messages that you send.




With Application Load Balancers, cross-zone load balancing is always enabled.
With Network Load Balancers and Gateway Load Balancers, cross-zone load balancing is disabled by default. 

After you create the load balancer, you can enable or disable cross-zone load balancing at any time.

When you create a Classic Load Balancer, the default for cross-zone load balancing depends on how you create the load balancer. 
With the API or CLI, cross-zone load balancing is disabled by default. 
With the AWS Management Console, the option to enable cross-zone load balancing is selected by default.






On-Demand Capacity Reservations enable you to reserve compute capacity for EC2 instances in a specific Availability Zone for any duration. 
This gives you the ability to create and manage Capacity Reservations independently from the billing discounts offered 
by Savings Plans or Regional Reserved Instances.

When you create a Capacity Reservation, you specify:
	– The AvailabilityZone in which to reserve the capacity
	– The number of instances for which to reserve capacity
	– The instance attributes, including the instance type, tenancy, and platform/OS
 
On-Demand instances cannot reserve compute capacity at all.




Capacity error placement group :
	It is recommended that you launch the number of instances that you need in the placement group in a single launch request 
	and that you use the same instance type for all instances in the placement group.

	If you receive a capacity error when launching an instance in a placement group that already has running instances, 
	stop and start all of the instances in the placement group, and try the launch again. 

Restarting the instances may migrate them to hardware that has capacity for all the requested instances.





AWS Organization allows you to create SCPs that centrally control AWS service across multiple AWS accounts.





Reduce Cost:
	Deploy all the EC2 instances in the same Availability Zone. If you recall, data transferred between 
	EC2,  RDS,  Redshift,  ElastiCache instances, and Elastic Network Interfaces in the same Availability Zone is free. 

Instead of using the public network to transfer the data, you can use the private network to reduce the overall data transfer costs.

Could be charged with inter-Availability Zone data transfers if the instances are distributed across 
different availability zones.


You won’t be able to connect to your Amazon S3 bucket if you are using a private subnet unless you have a VPC Endpoint.
Private subnet connect S3 using vpc Endpoint.






Authenticate the users using Redis AUTH by creating a new Redis Cluster with both the 
	--transit-encryption-enabled and --auth-token parameters enabled.




In-flight data between your web servers and RDS should be secured:
	Force all connections to your DB instance to use SSL by setting the rds.force_ssl parameter to true. 
	Once done, reboot your DB instance.
	
	Download the Amazon RDS Root CA certificate. Import the certificate to your servers and configure your application to 
	use SSL to encrypt the connection to RDS.

There are 2 ways to use SSL to connect to your SQL Server DB instance:
	– Force SSL for all connections.
	– Encrypt specific connections.





RDS multiAZL:
– Increased database availability in the case of system upgrades like OS patching or DB Instance scaling.
– Provides enhanced database durability in the event of a DB instance component failure or an Availability Zone outage.

RDS synchronously replicates within same regin:
	RDS synchronously replicates the data to a standby instance in a different Availability Zone (AZ) that is in the same region.

By using cross-Region read replicas in Amazon RDS, you can create 
MariaDB, MySQL, Oracle, PostgreSQL, or SQL Server read replica in a different Region. (asynchronous replication)






Cross-account access to S3 objects:
	– IAM policies and resource-based bucket policies             for programmatic-only access to S3 bucket objects.
	– IAM policies and resource-based Access Control Lists (ACLs) for programmatic-only access to S3 bucket objects.
	– Cross-account IAM roles                                     for programmatic and console access to S3 bucket objects.

Not all AWS services support resource-based policies. 
Therefore, you can use cross-account IAM roles to centralize permission management when providing cross-account access 
to multiple services.





OpenSearch:
	Create an Amazon Comprehend analysis job. Index the sentiment along with the transcript to an Amazon OpenSearch cluster. 
	Visualize the results using the OpenSearch Dashboard.

The Amazon OpenSearch dashboard is a more suitable service to use than Grafana since the sentiment data is already processed 
by an Amazon OpenSearch cluster.





To enable the cross-region replication feature in S3, the following items should be met:
	The source and destination buckets must have versioning enabled and must be in different AWS Regions.
	Amazon S3 must have permission to replicate objects from that source bucket to the destination bucket on your behalf.





Deploy a conversational chatbot using Amazon Lex. 
Define conversation flow for specific user intentions. Integrate AWS Lambda functions as code hooks to perform actions 
based on user requests.

Comprehend is a natural language processing (NLP) service that uses machine learning to find insights and relationships in texts. 
It is not used to build chatbot applications.





Ingest/Consume the data using Amazon Kinesis Data Streams and create an AWS Lambda function to store the data in Amazon DynamoDB.

Amazon Redshift only  sub-second response times. 
Amazon DynamoDB Accelerator (DAX), microsecond response times.

Amazon Kinesis Data Firehose only supports  S3,  Redshift,  Elasticsearch, and an HTTP endpoint as the destination.






CloudFront Cache-Control:
	The Cache-Control and Expires headers control how long objects stay in the cache. 
	The Cache-Control max-age directive lets you specify how long (in seconds) you want an object to remain in the cache before 
	CloudFront gets the object again from the origin server. 

The minimum expiration time CloudFront supports is 0 seconds for web distributions and 3600 seconds (1Hr) for RTMP distributions.






Enable IAM cross-account access for all corporate IT administrators in each child account.
By setting up cross-account access in this way, you don’t need to create individual IAM users in each account. 

In addition, users don’t have to sign out of one account and sign into another in order to access resources that are 
in different AWS accounts.





AWS Consolidated Billing:
	Use AWS Consolidated Billing by creating AWS Organizations to link the divisions’ accounts to a parent corporate account.

You can use the consolidated billing feature in AWS Organizations to consolidate payment for multiple AWS accounts or
multiple AISPL accounts. 
With consolidated billing, you can see a combined view of AWS charges incurred by all of your accounts.


Tag Editor simply allows you to add, edit, and delete tags to multiple AWS resources at once for easier identification and monitoring.






Amazon Aurora replicas vs RDS replicas:
	The read replication latency of less than 1 second is only possible if you would use Amazon Aurora replicas.

Aurora replicas are independent endpoints in an Aurora DB cluster, best used for scaling read operations and increasing availability. 
You can create up to 15 replicas within an AWS Region.

RDS Read Replicas can only provide asynchronous replication in seconds and not in milliseconds.




High-frequency read and write operations handrad of ECS:
	ECS to access file system data across your fleet of Amazon ECS tasks.
	Amazon Elastic File System (Amazon EFS) provides simple, scalable file storage for use with your Amazon ECS tasks. 
	Launch an Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode and set the performance mode to Max I/O. 
	
	Configure the EFS file system as the container mount point in the ECS task definition of the Amazon ECS cluster.

EFS offers two performance modes:
	– General Purpose mode
	– Max I/O mode.
	
There are two throughput modes to choose from for your file system:
	– Bursting Throughput
	– Provisioned Throughput

Bursting Throughput mode won’t be able to sustain the constant demand of the global application. 
Need  Provisioned Throughput mode.


	
	
	
	
Cannot directly set a DynamoDB table as a container mount point:
	In the first place, DynamoDB is a database and not a file system which means that it can’t be “mounted” to a server.
 
 
 
 
 
Enable the EBS Encryption By Default feature for the AWS Region.
	Encryption By Default feature is a Region-specific setting and thus, you can’t enable it to selected EBS volumes only.

EBS encryption:
	– Encryption by default is a Region-specific setting. If you enable it for a Region, you cannot disable it for individual 
      volumes or snapshots in that Region.
	
	– When you enable encryption by default, you can launch an instance only if the instance type supports EBS encryption.
	– Amazon EBS does not support asymmetric CMKs.

Amazon EBS does not support asymmetric CMKs. To encrypt an EBS snapshot, you need to use symmetric CMK.

Amazon Elastic File System (EFS) doesn’t natively work with Amazon S3.
Amazon FSx for Lustre works natively with Amazon S3, a high-performance POSIX interface. 

 




Global Accelerator:
User->AWSEdgeNet->GlobalAcc->NLB/ALB/EC2

	Use AWS Global Accelerator create an endpoint with static IP for User and connect each AWS Region, then 
	Associate the Elastic Load Balancer from each region.
	
AWS Global Accelerator is a service that improves the availability and performance of your applications with local or global users. 
It provides static IP addresses that act as a fixed entry point to your application endpoints in a single or multiple AWS Regions, 
such as your Application Load Balancers, Network Load Balancers, or Amazon EC2 instances.

With AWS Global Accelerator, you can add or remove endpoints in the AWS Regions, run blue/green deployment, and A/B test 
without needing to update the IP addresses in your client applications. 

If you have multiple resources in multiple regions, you can use AWS Global Accelerator to reduce the number of IP addresses. 





Enhanced Networking:
	EC2 provides enhanced networking capabilities through the Elastic Network Adapter (ENA). 
	To use enhanced networking, you must install the required ENA module and enable ENA support.

	When you need a consistently lower inter-instance latencies.
	When you need a higher packet per second (PPS) performance and single root I/O virtualization (SR-IOV).





CloudFormation, a template:
In CloudFormation, a template is a JSON or a YAML-formatted text file that describes your AWS infrastructure:
	– Format Version
	– Description
	– Metadata
	– Parameters
	– Mappings
	– Conditions
	– Transform
	– Resources (required)
	– Outputs
	
	
	


EBS:
lessthen 1 minute.
What are types of EBS?
	General Purpose SSD.                =>Small to Medium db, boot volume, brodrang of work load.
	Provisioned IOPS SSD.               =>Consistent, low-letency performance and I/O Intensive app like Large Relationa or NoSQL DB.
	Magnetic:                           =>Data access infrequently, app where loest storage cont inportant.
	 ThroughputOptimized HDD/Cold HDD. (Latest low-cost Magnetic Storage)
     Previous generation Magnetic. (Old)


Amazon EBS Volume Types lists:
	General Purpose SSD: Maximum 10,000 IOPS/Volume
	Provisioned IOPS SSD: Maximum 20,000 IOPS/Volume
	Throughput Optimized HDD: Maximum throughput 500 MiB/s (Optimized for throughput rather than IOPS, good for large, contiguous reads)


Amazon EBS offers three types of Provisioned IOPS SSD volumes:
	Provisioned IOPS SSD (io2) volumes
	Provisioned IOPS SSD (io2) Block Express volumes
	Provisioned IOPS SSD (io1) volumes

IO2 volumes can deliver maximum of 500 IOPS per 1 GB where as IO1 volumes can deliver maximum of 50 IOPS per 1GB.
	io1 volume 1,280 GiB in size or greater (50 × 1,280 GiB = 64,000 IOPS)
	io2 volume 128 GiB in size or greater (500 × 128 GiB = 64,000 IOPS)
	
	50:1 for io1
	500:1 for io2
	
i2 instances=>deliver 350,000 random read IOPS and 320,000 random write IOPS.
i3 instances=>can deliver up to 3.3 million IOPS at a 4 KB block and up to 16 GB/second of sequential disk throughput.


	 
EBS Multi-attach only be enable on EBS Provisioned IOPS io1/io2 volumes not General purpose SSD.
EBS Multi-attach won’t offer Multi-AZ resiliency, this only allow EBS volume to be attached on Multiple intance within a single AZ.
 

AMI are categorized two type storage backed by(Store-Backed AMI):
	1) EBS.
	2) Instance Store.
	
AMI with EBS volume, created from an Amazon EBS Snapshot.
AMI is and Instance-Store volume, created from and template stored in Amazon S3.
	
Data of Instance store volumes persist only dureing the life of the instance.


EC2 instances support two types for block level storage: EC2 Instances can be launched using either EBS or 
Instance Store volume as root volumes and additional volumes.

EC2 instances can be launched by choosing between AMIs backed by EC2 instance store and AMIs backed by EBS.

Key points for Instance store backed Instance
	Boot time is slower then EBS backed volumes and usually less then 5 min.

EBS lessthen 1 minute.	
InstanceStore:
Lessthen 5 minute.
	There are three types of instance store volumes: ephemeral, non-volatile memory (NVMe) SSD, and TRIM

	



Network load balancer support Layer 4 traffic, and TCP,UDP,TLS protocol, ALB not support UDP.



Restart EC2 for error:
	 Look at CloudWatch logs for keywork or error, create a custom metric.
	 Then Create a CloudWatch alarm for that custom metric which invokes an action to restart the EC2.
You can create alarms that auto stop,terminate,reboot or recover EC2 instance using CloudWatch alarms action.

Flow logs are using VPC, not on specific EC2 instance.






AWS Server-Side Encryption:
	SSE-s3			=> Auto key rotates, No Audit trails show.
	SSE-KMS(CMKs)   => Auto key rotates, Protecton access, Audit trails show.
	SSE-C           => Auto key rotates, No Audit trails show.
	
	
	
	
Queue Message cant be duplicates tolerate:
	Use SQS FIFO or SWF (Simple Work Flow Services)
Altering Visibility timeout of SQS not guarantee message duplication.




Highly Scalable system with cost-effective:
	use AutoScaling SQS and EC2 for highly scalable distrubute system.
	
	
	
	
	
	
	
Get notify before 30 days of expration of SSL Certificates:
Two Way:
	First One: AWS ACM built-in certificate expiration event,which is raised throw Amazon EventBridge, to invoke a Lambda function.
	The funcation now can send notification using SQS or Security hub.
	
	Second one: Recent Lunch DaysToExpiry metric to schedule a batch search to expiring certificats and to log all finding.
	And Send Notification on SQS.
	
CloudWatch Event are truned into action using Amazon Eventbridge.
AWS health event are generated for ACM certificates that are eligibnle for renwwal.

EventProducer=>Event=>EventBridge=>rule=>ActionOnAWSServices(Lambda, Kisinsis, SQS)

AWS Ceritficate manager automatically generated AWS Health events. manually crateing a custom AWS Config rule to check
for SSL exprie is unnecessary. 
also AWS Config already provide a built-in acm-certiticate-expriration-check manage rule that can used, not need manually cration.






AutoScaling provides scaling plans for : EC2, SpotFleets,ECS Tasks (ECS Services or ECS Containers Instance), 
										 DynamoDB table and Index, Aurora Replics.
ECS Instance metrics:
	CPU Utilization
	DiskRead/Writes
	Network In/Out etc.
	
ECS Services metrics:
	ECSServiceAvaragesCPUUtilization
	ECSServicAvarageMemoryUtilization
	ALBRequestCoountPerTarget
	
AutoScaling not support any metrics from ALB.






RDS Mult-AZ deployment provide enhanced availability and durability for DB instance.
In case of Infrastructure failure or AZ fail:
	RDS perform an automatic failover to the standby Instance(Read Replica for Aurora. Endpoint remains same after failover.

RDS synchronously replicates the data to a standby instance in different AZ in same region not in a different region.





HPC, Natively workign with S3, POSIX interface=>FSx for Luster.
EFS, EBS, FSx for Windows: Not working with S3 easy way.

EFS=>NFS
FSx for Win=>SMB






AWS resource access share to different AWS account using cross-account acccess.
No need individual IAM user in each account.

AWS Organization Consolidate bill feature allow payment for multiple aws account or multiple AISPL acc.
Its for combined view of aws charge all account also get cost report for each member.

AWS Trusted advisor is an provides real-time guidance for best practices. Its not assist in maintaining goverence
over  AWS account.






Company Need to resuce IP address that need to regularly whitelist on corporate firewal:
	Use AWS Global Acclerator and Create and endpoint group for each AWS Region. Associate the ALB for each region to 
	the corresponding endpoin group.

Global Acclerator inporove application availabilithy and performance for local or global user.
It provide static IP that act as a fixed entry point to application endpoint in a single or multiple AWS Region
which application may backend by ALB,NLB or EC2.

For multiple resources in multiple region, use AWS Global Acclerator to reduce the number of IP address.
By Creating and endpoint group, you can add all of EC2 from a single region in that group.

No multiple endpoint for all the available AWS Region, better create one endpoint group for all region.

If multiple region rsourc then not use ALB for route traffic to multiple region Instead use AWS Global Acclearator.






Inspect Traffic In/Out of VPC: Use Network Firewall and add custom rule groups for inspecting traffic.

Only Traffic Mirroring filters can not inspect the actual packet within traffic, Its just copy network traffic
From and ENI.






Multiple Site-to-Site VPN connection slow for VPC and remote Network suring peak hours:
	Associate VPCs to and Equal Cost Multipath Routing ECMR-enable TransitGateway and attach additional VPN tunnels.
AWS transit Gateway enable you to scale the IPsec VPN throughput with equal-cost multi-pah ECMP routing support over 
multple VPN Tunnels.


At a time A VPC can only have have a single virtual private gateway attached to it, No multiple VPG not allow. 1 VPC = 1VPG
Maximum tunnel for a VPC connection is two by limit.




Amazon web services have mainly two dedicated managed services for workflow implementation.
	Simple Workflow Service (SWF)
	Step Functions


Simple Workflow Service (Amazon SWF) is a web service that makes it easy to coordinate work across distributed application components.
Amazon SWF, on the other hand, is a cloud-based service, allows common programming languages to be used, and lets developers 
control where tasks are processed.

A task is an invocation of a logical step in an Amazon SWF application. Amazon SWF interacts with workers which are programs 
that retrieve, process, and return tasks.


AWS Step Functions is a visual workflow service that helps developers use AWS services to build distributed applications, 
automate processes, orchestrate microservices, and create data and machine learning (ML) pipelines.
Your workflow can be visualized by state machines describing steps, their relationships, and their inputs and outputs.

Step Functions is a managed service, so users don't have to deploy or maintain any infrastructure for either the workflow management 
or the tasks themselves. 

SWF also manages workflow state in the cloud. However, unlike Step Functions, a user has to manage the infrastructure 
that runs the workflow logic and tasks.





VPC Inter-region private communication (VPC peering):
	Setup a VPC peering connection between VPCs.
	Re-config the route table targete and destination of the instance subnet.
	
VPC endpoint not needed becos VPCEndpoint are region specific only. Not support inter-region communicaton.

In VPC peering enables route traffic between them using private IPv4 or IPv6 like there in a single private network.
VPC peering cand own VPC, other account VPC, VPC can be different region.
Inter-region vpc peering encryps traffic, never travel public network.





Low inter-instance latencies with Windows server (SR-IOV):
	Enable Enhanced Netwoiking with ElasticNetwork Adapter (ENA) on the Windows EC2 instance.

Enhanced Netwoiking privides high bandwdith, higher packet per second (PPS) performance and consistently lower inter-instance latencies.
With No cost. using single root I/O vertulazation (SR-IOV), 100Gbps.

Elastic Fabric Adapter EFA  not support OS-bypass capabilitess for Windows Instance it will work as ENA.

AWS ParalledClusterr just a AWS-support open-source cluster management tools, Its for deploy manage HPC.
Its not provided high branwith,PPS and lower inter-instance latencies as ENA or EFA.




Config DNS zone apex record to point load balancer:
	Create and A record aliesed to the load balancer DNS name.

Use and Alias record pointing to the DNS name of Loadbalancer not IP, since the IP address of the Load balancer can change at any time.

CNAME record cannot be creaed for your zone apex, create alies record at the top node of DNS as zone apex.





Track AWS resources uses for quotas unexpectdly:
	Writge and Lambda function that refreshs tha AWS Trusted Advisor Service Limits checks and set it to run every 24 houts.
	Capture the events using Amazon EventBridge (CloudWatch Event) and use an SNS topic as the target for notifications.
	
	
AWS Trusted Advisor provide best practices from hundreds of thousands of AWS customer.
Trusted Advisor inspects your AWS environment make recommendatins for save money, inprove system availability, security Gap.

AWS has and example of the implemenation of Quota Monitoring CloudFormaton template that cand deploy on AWS account.
The Template uses a Lambda funcaton that runs onece every 24 hour and refresh Trusted advisor service Limits check quota throw API call.
CloudWatch event capture the status events from Trusted advisor, send status to targets SQS, SNS, lambda for Slack notification.
Trusted advisor services limit publish services limit metric to CloudWatch, config alarm and send notification to SNS or Lembda.

Trusted dAdvisor APIs are only available for Business, Enterprise On-Ramp or Support plans. (DescribeTrustedAdvisorChecks API)
Its Return all avalilable Trusted advisor check info, so its will be dificult to extract only "service limits" info from thsi api.






From S3 to Standard IA and OneZone IA need to stay data in current class more 30 days, not for Intelligence,Glacier or DepArch.
For surprice check for audit then need to with in 1 minute then use Glaicer. Ite  provide quick acc (1-5mm).
Deep Archive need several hours.

If you dont know the acccess time schedule or frequently change then use Intelligence class for save cost.

S3 proivides 3500(PUT) request per second to add data and 5500 read data (GET) default. Per prefix.
For parallel permormance to scale more request use prefix, S3 scale performance per prix.






Encrypted at rest, full control over the encryption key, immedit remove material from the AWS KMS, audit using CloudTrails:
	use Aws key Management Service to Create a CMK in a custom key store and store the non-extractable key material in CloudHSM.

A Custom key (KMS) store CloudHSM. For immeditely remove the key meterial from AWS KMS use a custom key Store.

Use Custom key Store (CloudHSM) for:
	Direct control.
	Immediatly remove key metatial from KMS and independently.
	Audit all use of keys independently from of KMS and CloudTrail.
	
AWS-owned CMK and AWS-manageed CMK are manage by AWS.





Many Employee need to granted to a S3 for there personal document:
	Config and IAM role and IAM Policy to access S3 Bucket.
	Setup a Federation proxy or and Identity provider and use AWS Security Token Service to generate Temp Token.
	
	
	


Prevent S3 photo link used by other company:
	Remove S3 public read access and use pre-signed URLs with expriy dates.
	




Prevent backend system from traffic spikes:
	Enable throttling limits and result caching in API Gateway.
API Gateway provide throttling (rate limit 1000 request per second), and caching to API call by TTL also invalid the cache.

	
	
	
	

A logging system for all change madb to AWS resource in all Region also provide and event history of api calls in MConsole and CLI:
	Setup CloudTrail trail in S3 using cli and pass --is-multi-region-trail and --include-global-service-event parameter.
	With KMS encryption MFA and bucket policy.
Not CloudWatch use CloudTrails.


CloudTrails record all activity of and account by MConsole, SDK,CLI and other AWS Services by user,role and services.
ClousTrails trails all region by default when create trail using MConsole, but in CLI need to pass parameter  --is-multi-region-trail.

By Default CloudTrails cover the activities of regional services(EC2,S3,RDS etc) not for global services.
For Global services (IAM CloudFront,WAF, Route53) in CLI mode add parameter --include-global-service-event parameter.







Aurora Custome endpoint:
	A Custome endpoint For different purpose (Read Only or read-write ) you can map each connect to a specific instance or a 
	Group of Instance.Base on usecase, of your requirment.

Aurora Cluster endpoint (also call writer endpoint) made from primary DB instance what is best for product traffic not for Repoting.
Use Custome endpoint for Repoting.

Create a custome endpoint in Aurora base on the specified criteria for product traffic and another custome end point for repoting.
Aurora involved a cluster of DB Instance not single instance. Each conn is handled by specific DB Instance.





Availabel in case of Oracle Database failure in future:
	Create Oracle database in RDS with Multi-AZ deployment.

Oracle RMAN and RAC are not supported in RDS.






Linux and Windows EC2 monitor for memory and disk Utilization metrics:
	Install CloudWatch agent to all EC2, View the custome metrics in CloudWatch console.
	
Enhanced Monitoring is a feature of RDS and By Default stored metrics for 30 days in CloudWatch logs.
And 
Detailed Monitoring for EC2. Detailed monitoring delivers metrics in 1-minute intervals, rather than 5-minute intervals.	






Handel Unpredictable transactional workload and autoscales capacity and peak load scales DB:
	Lunch and Autora Serverless DB cluster then set the minumum and maximum capacity for the cluster.
	
Aurora Serverless is and on-demand, auto-scaling configuration for Aurora.
Non-Serverless DB cluster of Autora called provisioned DB Cluster.

Both Provision DB and Serverless carry same of feature like: scale, permormance dustributed all two are same.

But Provisioning DB cluster for where you can predicatable workload and you cand adjust the capacity manually base on workload.
Where Serverless for un-predicatable workload.

	
	
	
	

Both historical record and frequently data are store on on-permises storage system what is going low capacity 
	Need to move Historical data:
	Use AWS DataSync to move historical data to AWS, choose S3Glacier Deep Archive to destination.

Storage Gateway mainly prividing low-latency access to data by caching frequently acc data on-premises and Archive data on Cloud Storage.
Storage Gateway optimizes data transfer to AWS by sending only change data and compressing data.








What needs outside of VPC for site-to-site VPN Conn:
	An Inter-routeable IP(Public IP/Static) of the customer gateway external interface for on-permises network.
	
Required For communication with own network using VPN:
	Attach a VPG virtual private gateway to VPC
	Create a custom route table
	Update SecurityGroup
	A public IP on-permises side
	A Customer Gateway on on-permise side(physical or software)

	
IPv6 not support by EC2 classic.

Fault tolerance for DirectConnectConnection to VPC:
	Establish a hardware VPN over Internet bwtween VPC and on-permises.
	Establish another DirectConnectConnection and Private Virtual Interface in same AWS region as VPC1.
	
CustomerNetwork=>DirectConnectConnection=>VIF=>DirectConnectGateway=>VGW=>VPC.

A virtual interface (VIF) is necessary to access AWS services, either public or private. 
	A public virtual interface enables access to public services, such as Amazon S3. 
	A private virtual interface enables access to your VPC.
	
	
	





A large portion of traffice from Philipnd and Indai will be route to resourde ap-northest-1 region:
	Use Reoute53 Geoproximity Routing.
	
Route53 Routing:
	Latency Routing:      Provide lowest latenct for resources, not guarantee user and resource will be same location.
	Geoproximity Routing: Route traffic using user and resource GeoLocation also with a Bias value for more/less traffic to a resource.
	Geolocation Routing:  GeoLocation of user base routing. Serve resource from the DNS queres origin from.
	Weighted Routing:     Multi resource associat with single domain name and set how much traffic to go each resource.
	
	
	
	

Publish events when an object is deleted or a versioned object is permanently deleted:
	Create a SNS topic and SQS. add and S3 Event notification confg on bucket to publish S3:ObjectCreated:* and 
	S3:ObjectRemoved:Delete event type to SQS and SNS.
	
s3:ObjectRemoved:Delete event for send nofification for version/non version permanently deleted.
ObjectRemoved:DeleteMarkerCreated: a new version created.

S3 can publish notifications for the following events:
	1. New object created events
	2. Object removal events
	3. Restore object events
	4. Reduced Redundancy Storage (RRS) object lost events
	5. Replication events

S3 supports the following destinations where it can publish events:
	1. SNS topic
	2. SQS queue
	3. Lambda
S3 does support Amazon MQ as a destination to publish events.

To avoid loging loop, use two buckets, or configure the trigger to only apply to a prefix used for incoming objects.




S3 protecting data at rest:
	Server-Side Encryption – You request Amazon S3 to encrypt your object before saving it on disks in its data centers and 
	decrypt it when you download the objects.
		Use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)
		Use Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)
		Use Server-Side Encryption with Customer-Provided Keys (SSE-C)
		
	Client-Side Encryption – You can encrypt data client-side and upload the encrypted data to Amazon S3. 
	In this case, you manage the encryption process, the encryption keys, and related tools.
		Use Client-Side Encryption with AWS KMS–Managed Customer Master Key (CMK)
		Use Client-Side Encryption Using a Client-Side Master Key

SSE-S3 is S3 managed key is fully managed by AWS and also rotates the key automatically and 
Customer master key (CMK) in AWS KMS that you can manage, rotate, and audit or alternatively, use a client-side master key 
that you manually maintain.








Concerned about the over-provisioning of the resources by ASG:
	Use target tracking scaling.
	
With a target tracking scaling policy, you can increase or decrease the current capacity of the group based on a 
target value for a specific metric. This policy will help resolve the over-provisioning of your resources.
	

Simple scaling: 
	Need to wait for the cooldown period to complete before initiating additional scaling activities. 
	
Target tracking or step scaling policies can trigger a scaling activity immediately without waiting for the 
cooldown period to expire.

Scheduled scalingis: 
	Mainly used for predictable traffic patterns. You need to use the target tracking scaling policy to optimize the 
	cost of your infrastructure without affecting the performance.






For Role-based access control. Currently, the roles are already assigned using groups in the corporate Active Directory:
	 AWS Directory Service AD Connector
	 IAM Roles

Take note that you can assign an IAM Role to the users or groups from your Active Directory once it is integrated with your 
VPC via the AWS Directory Service AD Connector.







AWS Fargate to run a batch job whenever an object is uploaded to S3:
	 Set up EventBridge rule to detect S3 object PUT operations and set the target to the ECS cluster to run a new ECS task.

EventBridge rule for detect all services level event.
It uses data from your own applications, integrated SaaS applications, and AWS services. 

EventBridge rule can runs an Amazon ECS task against a event, ECS tasks directly as targets for the CloudWatch Event rule.





 
Application is slow during the start of the day but then works normally after a couple of hours:
	Configure a Scheduled scaling policy for the Auto Scaling group to launch new instances before the start of the day.

The scheduled action tells Amazon EC2 Auto Scaling to perform a scaling action at specified times.
To create a scheduled scaling action, you specify the start time when the scaling action should take effect, and the new 
minimum, maximum, and desired sizes for the scaling action. 

At the specified time, Amazon EC2 Auto Scaling updates the group with the values for minimum, maximum, and desired size 
specified by the scaling action. 
 




Notify the development and operations team about the created or deleted S3 objects:
	Create an Amazon SNS topic and configure two Amazon SQS queues to subscribe to the topic. 
	Grant Amazon S3 permission to send notifications to Amazon SNS and update the bucket to use the new SNS topic.	

Take note that Amazon S3 event notifications are designed to be delivered at least once and to one destination only. 
You cannot attach two or more SNS topics or SQS queues for S3 event notification. 
Therefore, you must send the event notification to Amazon SNS.






Amazon storage services should Hot and Cold storage:
	Use Amazon FSx For Lustre and Amazon S3 for hot and cold storage respectively.

Although EFS supports concurrent access to data, it does not have the high-performance ability that is required for 
machine learning workloads.
FSx For Windows File Server does not have a parallel file system, unlike Lustre.

Hot storage refers to the storage that keeps frequently accessed data (hot data). 
Warm storage refers to the storage that keeps less frequently accessed data (warm data). 
Cold storage refers to the storage that keeps rarely accessed data (cold data). 
	
Amazon FSx For Lustre is a high-performance file system for fast processing of workloads. Lustre is a popular open-source 
parallel file system which stores data across multiple network file servers to maximize performance and reduce bottlenecks.

Amazon FSx for Windows File Server is a fully managed Microsoft Windows file system with full support for the SMB protocol, 
Windows NTFS, Microsoft Active Directory (AD) Integration.

Amazon Elastic File System is a fully-managed file storage service that makes it easy to set up and scale file storage in 
the Amazon Cloud. 

Amazon S3 is an object storage service that offers industry-leading scalability, data availability, security, and performance.







Improve DynamoDB performance by distributing the workload evenly and using the provisioned throughput efficiently:
	 Use partition keys with high-cardinality attributes, which have a large number of distinct values for each item.

Remember that the more distinct partition key values your workload accesses, the more those requests will be spread across the 
partitioned space. 

Conversely, the less distinct partition key values, the less evenly spread it would be across the partitioned space, 
which effectively slows the performance

A composite primary key will provide more partition for the table and in turn, improves the performance.
	 
	 
	 

	 
There are three main parts in a distributed messaging system:
	1. The components of your distributed system (EC2 instances)
	2. Your queue (distributed on Amazon SQS servers)
	3. Messages in the queue.	 







EBS:
	Although an EBS Volume can be attached to multiple EC2 instances, Instance and EBS must be in same AZ. 
	What we need is high-available storage that can span multiple availability zones.

EFS:
	Multiple Amazon EC2 instances can access an Amazon EFS file system at the same time, allowing Amazon EFS to provide a common 
	data source for workloads and applications running on more than one Amazon EC2 instance.
EFS only supports Linux workloads.

Amazon EFS provides two modes of throughput: Provisioned and Bursting. 
EFS provides two classes of storage: One Zone and Standard. EFS Lifecycle.

EFS file systems can be accessed by Amazon EC2 Linux instances, Amazon ECS, Amazon EKS, AWS Fargate, 
and AWS Lambda functions via a file system interface such as NFS protocol.
Mult-AZ

FSx for Lustre: 
	For machine learning model, Which scales to hundreds of gigabytes every second and sub-millisecond latencies.
	FSx for Lustre is designed to support any Linux workload and is POSIX-compliant.
FSx for Lustre automatically encrypts your information in-transit and at-rest, and is ISO, SOC, and PCI-DSS compliant.

Amazon FSx for Lustre also integrates with Amazon S3.
FSx for Lustre can only be used by Linux-based instances.
Mult-AZ

FSx for NetApp ONTAP:
	FSx for ONTAP delivers NFS, SMB and iSCSI storage powered by NetApp’s advanced data management system.
	Multiprotocol file and block storage support.
	High availability across multi-AZs.
Mult-AZ








DynamoDB event notified via email:
	 Enable DynamoDB Stream and create an AWS Lambda trigger, as well as the IAM role which contains all of the permissions that 
	 the Lambda function will need at runtime. The data from the stream record will be processed by the Lambda 
	 function which will then publish a message to SNS Topic that will notify the subscribers via email.

Remember that the DynamoDB Stream feature is not enabled by default. 
	 
	 





Wants a high-performing solution to migrate this workload to the AWS cloud to take advantage of the cloud’s high availability:
	 Migrate the Oracle database to Amazon RDS for Oracle in a Multi-AZ deployment by using AWS Database Migration Service (AWS DMS).
	 Rehost the on-premises .NET application to an AWS Elastic Beanstalk Multi-AZ environment which runs in multiple Availability Zones.

DMS:
AWS Database Migration Service (AWS DMS) is a cloud service that makes it easy to migrate relational databases, data warehouses, 
NoSQL databases, and other types of data stores. 
You can use AWS DMS to migrate your data into the AWS Cloud or between combinations of cloud and on-premises setups.

With AWS DMS, you can perform one-time migrations, and you can replicate ongoing changes to keep sources and targets in sync.
Migrate to a different database engine use Schema Conversion Tool (AWS SCT).


AWS ElasticBeanstalk reduces management complexity without restricting choice or control. 
	You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, 
	load balancing, scaling, and application health monitoring.
	Elastic Beanstalk supports applications developed in Go, Java, .NET, Node.js, PHP, Python, and Ruby.


AWS Application Migration Service (AWS MGN) to migrate the on-premises Oracle database server to a new Amazon EC2 instance.
Amazon RDS supports standard Oracle databases so it would be better to use AWS DMS for the database migration, not AWS MGN.







Users take a lot of time to log into their website and HTTP 504 errors:
	Customize the content that the CloudFront web distribution delivers to your users using Lambda@Edge, which allows your 
	Lambda functions to execute the authentication process in AWS locations closer to the users.
	
	Set up an origin failover by creating an origin group with two origins. Specify one as the primary origin and the other 
	as the second origin which CloudFront automatically switches to when the primary origin returns specific HTTP status code 
	failure responses.
	 
	 



Query data that resides in multiple AWS accounts from a central data lake:
	 Use AWS Lake Formation to consolidate data from multiple accounts into a single account.
A data lake enables you to break down data silos and combine different types of analytics.

AWS Lake Formation is integrated with AWS Glue which you can use to create a data catalog that describes available datasets and 
their appropriate business applications.
Cross-account sharing which is free with AWS Lake Formation.





AWS resources centrally manage and share with multiple account:
	Use the AWS Resource Access Manager (RAM) service to easily and securely share your resources with your AWS accounts. 
	Consolidate all of the company's accounts using AWS Organizations.

AWS Organizations is an account management service that lets you consolidate multiple AWS accounts into an organization that you 
create and centrally manage.

AWS Control Tower simply offers the easiest way to set up and govern a new, secure, multi-account AWS environment. 
This is not the most suitable service to use to securely share your resources across AWS accounts or within your Organization. 
You have to use AWS Resources Access Manager (RAM) instead.





Aurora data-modifying info forwarded to a distributed processing system:
	Create a native function or a stored procedure that invokes a Lambda function. Configure the Lambda function to send event 
	notifications to an Amazon SQS queue for the processing system to consume.


RDS events only provide operational events such as DB instance events, DB parameter group events, DB security group events, and 
DB snapshot events. 
What we need  data-modifying events (INSERT, DELETE, UPDATE) which can be achieved thru native functions or stored procedures.






Use VPC endpoints to route all access to S3 and DynamoDB via private endpoints.

Transit Gateway simply connects your VPC and on-premises networks through a central hub. 
It acts as a cloud router that allows you to integrate multiple networks.





RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone.
RDS Read Replica provides an asynchronous replication instead of synchronous.

DynamoDB do not have a Read Replica approach.
Global tables replicate your DynamoDB tables automatically across  Regions.





Monitor how the different processes or threads on a DB instance use the CPU, including the percentage of the 
CPU bandwidth and total memory consumed by each proces:
	Enable Enhanced Monitoring in RDS.

By default, Enhanced Monitoring metrics are stored in the CloudWatch Logs for 30 days. To modify the amount of time the 
metrics are stored in the CloudWatch Logs, change the retention for the RDSOSMetrics log group in the CloudWatch console.

Differences between CloudWatch and Enhanced Monitoring Metrics:  
	CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance, and 
	Enhanced Monitoring gathers its metrics from an agent on the instance. 

To get the specific percentage of the CPU bandwidth and total memory consumed by each database processes:
	Use Enhanced Monitoring metrics.
 
 
 
 
 
Move the files that are older than 2 years to a more cost-effective and scalable solution:
	The requirement is to move the files that are older than 2 years or 730 days, use  S3 Glacier after 2 years or S3 Standard-IA.
	
Maximum days for the EFS lifecycle policy is only 90 days. 





You can also sell your unused instance for Standard RIs but not Convertible RIs on the Reserved Instance Marketplace.
You can reserve capacity to a specific AWS Region (regional Reserved Instance) or specific 
Availability Zone (zonal Reserved Instance) only. 
You cannot reserve capacity to multiple AWS Regions in a single RI purchase.





Need a DB with unpredictable transactional workloads throughout:
	Launch an Amazon Aurora Serverless DB cluster then set the minimum and maximum capacity for the cluster.

Aurora without Aurora Serverless (provisioned DB clusters) works well when the database workload is predictable, 
because you can adjust capacity manually based on the expected workload.




Mitigate multi-region failure lessthen 1m for RTO and RPO:
	Amazon Aurora Global Database.
	
Amazon Aurora Global Database is designed for globally distributed applications, allowing a single Amazon Aurora database 
to span multiple AWS regions. It replicates your data with no impact on database performance, 
enables fast local reads with low latency in each region, and provides disaster recovery from region-wide outages.

RDS Multi-AZ deployment is only applicable inside a single region and not in a multi-region setup.





Launch a new file gateway that connects to your on-premises data center using AWS Storage Gateway. 
Upload the documents to the file gateway and set up a lifecycle policy to move the data into Glacier for data archival.

File gateway provides access to objects in S3 as files or file share mount points. With a file gateway, you can do the following:
	- You can store and retrieve files directly using the NFS version 3 or 4.1 protocol.
	- You can store and retrieve files directly using the SMB file system version, 2 and 3 protocol.
	- You can access your data directly in Amazon S3 from any AWS Cloud application or service.
	- You can manage your Amazon S3 data using lifecycle policies, cross-region replication, and versioning. 

You can think of a file gateway as a file system mount on S3.

AWS Storage Gateway supports S3 Standard, S3 Standard-IA, S3 One Zone-IA and Amazon Glacier storage classes.







RDS database can only be accessed using the profile credentials specific to your EC2 instances via an authentication token:
	Enable the IAM DB Authentication.
	
IAM database authentication provides the following benefits:
	Network traffic to and from the database is encrypted using Secure Sockets Layer (SSL).
	You can use IAM to centrally manage access to your database resources, instead of managing access individually on each DB instance.
	For applications running on Amazon EC2, you can use profile credentials specific to your EC2 instance to access your database

Although STS is used to send temporary tokens for authentication, this is not a compatible use case for RDS.


	 
 
Client-side encryption is the act of encrypting data before sending it to Amazon S3 are two way:
- Use an AWS KMS-managed customer master key.
- Use a client-side master key.

When using an AWS KMS-managed customer master key to enable client-side data encryption, you provide an 
AWS KMS customer master key ID (CMK ID) to AWS. 

When you use client-side master key for client-side data encryption, your client-side master keys and your unencrypted data 
are never sent to AWS. 





Enable Cross-origin resource sharing (CORS) configuration in the bucket.
	Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact 
	with resources in a different domain.




Secure the session data in the portal by requiring them to enter a password before they are granted permission to execute Redis commands:
	 Authenticate the users using Redis AUTH by creating a new Redis Cluster with both the 
	 --transit-encryption-enabled and 
	 --auth-token parameters enabled.
	 
	 
	 
	 

Database hostname-credentials, API credentials that prevent other developers access DEV, SIT, UAT, and PROD environments:
	Create a new KMS key and use it to enable encryption helpers that leverage on AWS Key Management Service to store and 
	encrypt the sensitive information.
	
Although Lambda encrypts the environment variables in your function by default, the sensitive information would still be 
visible to other users who have access to the Lambda console. This is because Lambda uses a default KMS key to encrypt 
the variables, which is usually accessible by other users. 

The best option in this scenario is to use encryption helpers to secure your environment variables.





Use the AWS Systems Manager Parameter Store to keep the database credentials and then encrypt using AWS KMS. 
	Create an IAM Role for your Amazon ECS task execution role (taskRoleArn) and reference it with your task definition, 
	which allows access to both KMS and the Parameter Store. 

Within your container definition, specify secrets with the name of the environment variable to set in the container 
and the full ARN of the Systems Manager Parameter Store parameter containing the sensitive data to present to the container.

Amazon Elastic Container Service (ECS) Anywhere is just a feature of Amazon ECS that enables you to easily run and manage 
container workloads on customer-managed infrastructure.




A report of all compliance-related documents for their account:
	Use AWS Artifact to view the security reports as well as other AWS compliance-related information.
 

AWS Artifact is your go-to, central resource for compliance-related information that matters to you. 
It provides on-demand access to AWS’ security and compliance reports and select online agreements. 

Reports available in AWS Artifact include our Service Organization Control (SOC) reports, Payment Card Industry (PCI) reports,
Business Associate Addendum (BAA) and the Nondisclosure Agreement (NDA).

	 
	 
	 
	 
	 
Even though AWS WAF can help you block common attack patterns to your VPC such as SQL injection or cross-site scripting, this is 
still not enough to withstand DDoS attacks. It is better to use AWS Shield.

Create a rate-based rule in AWS WAF and associate the web ACL to an Application Load Balancer.
a regular rule only matches the statement defined in the rule. If you need to add a rate limit to your rule, you should create a 
rate-based rule.

AWS Network Firewall is a managed service that is primarily used to deploy essential network protections for all of your VPCs 
and not particularly to your Application Load Balancers.






Storage solution to a specific Amazon VPC only:
	Configure an Amazon S3 Access Point for the S3 bucket to restrict data access to a particular Amazon VPC only.
	Create a new Amazon S3 bucket with the S3 Object Lock feature enabled. Store the documents in the bucket and set the 
	Legal Hold option for object retention.
Access points are named network endpoints that are attached to buckets.	 
S3 Multi-Region Access Points to provide a global endpoint that applications.	 

Before you lock any objects, you have to enable a bucket to use S3 Object Lock. 
When you create a bucket with Object Lock enabled, you can't disable Object Lock or suspend versioning for that bucket.
 
Object Versioning feature must also be enabled too in order for this to work. 
In fact, you cannot manually disable the Object Versioning feature if you have already selected the Object Lock option.





 
Amazon Macie generates two categories of findings: policy findings and sensitive data findings. 
	A policy finding is a detailed report of a potential policy violation or issue with the security or privacy of an  S3 bucket.
	A sensitive data finding is a detailed report of sensitive data in an S3 object.

Amazon Macie is an ML-powered security service that helps you prevent data loss by automatically discovering, classifying, 
and protecting sensitive data stored in Amazon S3. Amazon Macie uses machine learning to recognize sensitive data such as 
personally identifiable information (PII) 
  
Amazon Kendra is just an enterprise search service that allows developers to add search capabilities to their applications. 




 
Asynchronously process the request:
	Replace the Kinesis Data Streams with an Amazon SQS queue. Create a Lambda function that will asynchronously process the requests.

AWS Lambda supports the synchronous and asynchronous invocation of a Lambda function. 

Kinesis Data Streams is a real-time data streaming service that requires the provisioning of shards. Amazon SQS is a cheaper option 
because you only pay for what you use. Since there is no requirement for real-time processing in the scenario given, replacing 
Kinesis Data Streams with Amazon SQS would save more costs.


AWS Step Functions is a serverless orchestration service that lets developers create and manage multi-step application workflows 
in the cloud.
AWS Step Functions is a visual workflow service.
Step F.unctions is a managed service, so users don't have to deploy or maintain any infrastructure

Amazon SWF is a fully managed workflow service for building scalable, resilient applications.
User has to manage the infrastructure that runs the workflow logic and tasks.

If you require external signals (deciders) to intervene in your processes, or you would like to launch child processes that 
return a result to a parent, then you should consider Amazon SWF.








A report that summarizes the total billing accrued by each department:
	Tag resources with the department name and enable cost allocation tags.

After you or AWS applies tags to your AWS resources (such as  EC2  or  S3 buckets) and you activate the 
tags in the Billing and Cost Management console, AWS generates a cost allocation report as a comma-separated value (CSV file) 
with your usage and costs grouped by your active tags.

AWS Budgets only allows you to be alerted and run custom actions if your budget thresholds are exceeded.

Cost and Usage Report (CUR) provid cost by AWS services.






Architect has decided to move the historical records to AWS :
	Use AWS DataSync to move the historical records from on-premises to AWS. Choose Amazon S3 Glacier Deep Archive to be the 
	destination for the data.


Getting started with DataSync is easy: deploy the DataSync agent, connect it to your file system, select your AWS storage resources, 
and start moving data between them. You pay only for the data you move(online).
You can use DataSync to migrate active data sets or archives to AWS.


Amazon Managed Service for Prometheus is a Prometheus-compatible monitoring and alerting service. 
This service makes it easy for you to monitor containerized applications and infrastructure at scale but not stream live feeds.







Set up AWS Proton for deploying container applications and serverless solutions. 
Create components from the AWS Proton console and attach them to their respective service instance.

AWS Proton allows you to deploy any serverless or container-based application with increased efficiency, consistency, and control. 
You can define infrastructure standards and effective continuous delivery pipelines for your organization. 

Proton breaks down the infrastructure into environment and service (“infrastructure as code” templates).
With a component, a developer can add supplemental resources to their application.

SQS and  SWF are the services that you can use for creating a decoupled architecture in AWS.





Create an Amazon EMR cluster and store the processed data in Amazon RedShift.
	Amazon EMR (previously known as Amazon Elastic MapReduce) is an Amazon Web Services big data tool for processing and analysis.

	Amazon EMR is a managed cluster platform that simplifies running big data frameworks, such as Apache Hadoop and Apache Spark, on 
	AWS to process and analyze vast amounts of data. 


	Amazon Redshift is the most widely used cloud data warehouse. 
	It makes it fast, simple and cost-effective to analyze all your data using standard SQL and your existing 
	Business Intelligence (BI) tools.

To leverage big data processing frameworks, you need to use Amazon EMR. The cluster will perform data transformations (ETL) 
and load the processed data into Amazon Redshift for analytic and business intelligence applications.
 
Glue is just a serverless ETL service that crawls your data, builds a data catalog, performs data preparation, data transformation, 
and data ingestion. It won't allow you to utilize different big data frameworks effectively, unlike Amazon EMR.
  






MySQL database that needs to be replicated in Amazon S3 as CSV file:
	Create a full load and change data capture (CDC) replication task using AWS Database Migration Service (AWS DMS). 
	Add a new Certificate Authority (CA) certificate and create an AWS DMS endpoint with SSL.




Compliance requirements in these two locations, you want the Japanese users to connect to the servers in the 
ap-northeast-1 Asia Pacific (Tokyo) region, while the Swedish users should be connected to the servers in the eu-west-1 EU (Ireland).
	Use Route 53 Geolocation Routing policy.
	



Route 53 Weighted Routing policy:
		It just lets you associate multiple resources with a single domain name (tutorialsdojo.com) or 
		subdomain name (forums.tutorialsdojo.com) and choose how much traffic is routed to each resource. 
		
		
		

On-premises web service clients can only access trusted IP addresses whitelisted on their firewalls:		
	 Associate an Elastic IP address to a Network Load Balancer.
	 You can't assign an Elastic IP address to an Application Load Balancer.

	
	
	
Secure, Reliable and Scalable Access to Applications From Anywhere.
Amazon AppStream 2.0 is a fully managed application streaming service that provides users with instant access to their desktop 
applications from anywhere. 

AppStream 2.0 manages the AWS resources required to host and run your applications, scales automatically, 
and provides access to your users on demand.






Preventing database calls from traversing the public internet. An automated cross-account backup for the DynamoDB table:
	Create a DynamoDB gateway endpoint. Associate the endpoint to the appropriate route table. Use AWS Backup to automatically 
	copy the on-demand DynamoDB backups to another AWS account for disaster recovery.

DynamoDB on-demand backups cannot be copied to a different account or Region.
	
To create backup copies across AWS accounts and Regions and for other advanced features, you should use AWS Backup.	
Point-in-Time Recovery (PITR) feature is not capable of restoring a DynamoDB table to a particular point in time in a different 
AWS account.





(Simple Email Service) SES is a cloud-based email sending service designed to send notifications and transactional emails.
Use SNS instead of SES  when you want to monitor your EC2 instances.	
	
	


Here are the prerequisites for routing traffic to a website that is hosted in an Amazon S3 Bucket:
- An S3 bucket that is configured to host a static website. The bucket must have the same name as your domain or subdomain. 
- A registered domain name. You can use Route 53 as your domain registrar, or you can use a different registrar.
- Route 53 as the DNS service for the domain. 





Use Amazon Rekognition to detect images with graphic nudity or violence in Amazon S3. 
Create an Interface VPC endpoint for Amazon Rekognition with the necessary policies to prevent any traffic from traversing the 
public Internet.

To connect your VPC to Amazon Rekognition, you define an interface VPC endpoint for Amazon Rekognition. An interface 
endpoint is an elastic network interface with a private IP address that serves as an entry point for traffic destined to a supported 
AWS service.

Amazon GuardDuty is primarily used as an intelligent threat detection solution and not a networking service.

Amazon Detective is commonly used to analyze, investigate, and quickly identify the root cause of potential security issues in your 
AWS workloads, as well as for detecting suspicious activities. 

AWS Audit Manager just continuously audits your AWS usage to simplify how you assess risk and compliance with regulations and industry 
standards.

Amazon Monitron is simply a service that detects abnormal conditions in industrial equipment such as fans, compressors, motors, etc. 






DNS failover to a static website:
	 Use Route53 with the failover option to a static S3 website bucket or CloudFront distribution.




Automated backup of all of the EBS Volumes for your EC2:
	 Use Amazon Data Lifecycle Manager (Amazon DLM) to automate the creation of EBS snapshots.

You can use Amazon Data Lifecycle Manager DLM to automate the creation, retention, and deletion of snapshots taken 
to back up your Amazon EBS volumes.
 
 
 
 

If your application is composed of several individual services, ALB can route a request to a 
service based on the content of the request such as Host field, Path URL, HTTP header, HTTP method, Query string, or Source IP address.

ALBs can also route and load balance gRPC traffic between microservices or between gRPC-enabled clients and services.
Network Load Balancers do not support gRPC.

A Gateway Load Balancer operates as a Layer 3 Gateway and a Layer 4 Load Balancing service. gRPC protocol is at Layer 7. 





Huge amounts of data and perform quick and flexible queries on it:
	Amazon RedShift

You can use Redshift to analyze all your data using standard SQL and your existing Business Intelligence (BI) tools. 


Amazon Athena can be used to access the information from the file resided over S3 by creating a table on top of it.

Amazon EMR is a way of accessing the Hadoop system like HDFS, Hive, Pig, spark from AWS.No SQL, Need data engineer, OpenSource Frameworks.

Amazon Redshift is data warehouse, which is based on columnar architecture and it has a plug in to add, which is Redshift spectrum, 
to access the files on top S3 as similar to Amazon Athena.
Redshift Traditional data warehouse,SQL, AWS Manage Services, no data engineering team.






Increase network availability by allowing the traffic flow to resume in another instance if the primary instance is terminated:
	Create a secondary elastic network interface and point its private IPv4 address to the application’s domain name. 
	Attach the new network interface to the primary instance. If the instance goes down, move the secondary network interface to 
	another instance.
	
	



Using an Elastic Load Balancer is an ideal solution for adding elasticity to your application. Alternatively, you can also 
create a policy in Route 53, such as a Weighted routing policy, to evenly distribute the traffic to 2 or more EC2 instances.





EBS volume in an Availability Zone, it is automatically replicated within that region only, and not on a separate AWS region, 
to prevent data loss due to a failure of any single hardware component.

EBS volumes can only be attached to an EC2 instance in the same Availability Zone.
EBS Volume snapshots are actually sent to Amazon S3.





In Route 53, which record types will you use to point the DNS name of the Application Load Balancer?
Alias with a type "AAAA" record set and Alias with a type "A" record set.





In Auto Scaling, the following statements are correct regarding the cooldown period:
	It ensures that the Auto Scaling group does not launch or terminate additional EC2 instances before the 
	previous scaling activity takes effect.
	Its default value is 300 seconds - 5m.
	It is a configurable setting for your Auto Scaling group.





Monitor the available swap space of each EC2:
	Install the CloudWatch agent on each instance and monitor the SwapUtilization metric.





CloudWatch Alam is primarily used for monitoring CloudWatch metrics.
CloudWatch Events service is commonly used to deliver a near real-time stream of system events that describe changes in some 
Amazon Web Services (AWS) resources.





Data access from S3 with their strict compliance standards, unauthorized access or suspicious access patterns in S3:
	Use Amazon GuardDuty to monitor malicious activity on S3.





Generate an endpoint policy for trusted S3 buckets.
When you create a Gateway endpoint, you can attach an endpoint policy that controls access to the service to which you are connecting.





AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources.
Config dashboard shows the compliance status of your rules and resources. You can verify if your resources 
comply with your desired configurations and learn which specific resources are noncompliant.

AWS Trusted Advisor only provides best practice recommendations. It cannot define rules for your AWS resources.


CloudTrail can track changes and store a history of what happened to your resources, this service still cannot enforce rules 
to comply with your organization's policies.






Each organization unit (OU) must be able to launch new accounts with preapproved configurations from the security team:
	Set up an AWS Control Tower Landing Zone. Enable pre-packaged guardrails to enforce policies or detect violations.

AWS Control Tower provides a single location to easily set up your new well-architected multi-account environment and 
govern your AWS workloads with rules for security, operations, and internal compliance. 
you can select and apply pre-packaged policies enterprise-wide or to specific groups of accounts.






Application takes several minutes to become fully operational:
	Migrate the application to an EC2 instance with hibernation enabled.

While the instance is in hibernation, you pay only for the EBS volumes and Elastic IP Addresses attached to it; there are 
no other hourly charges (just like any other stopped instance).


CloudEndure Migration is just a highly automated lift-and-shift (rehost) solution that simplifies, expedites, 
and reduces the cost of migrating applications to AWS. 






The company require consistent and dedicated access to these network:
	Create a new Direct Connect gateway and integrate it with the existing Direct Connect connection. 
	Set up a Transit Gateway between AWS accounts and associate it with the Direct Connect gateway.
	
AWS Transit Gateway provides a hub and spoke design for connecting VPCs and on-premises networks. 
You can attach all your hybrid connectivity (VPN and Direct Connect connections) to a single Transit Gateway 
consolidating and controlling your organization's.

By attaching a transit gateway to a Direct Connect gateway using a transit virtual interface, you can manage a single connection 
for multiple VPCs or VPNs that are in the same AWS Region.







What service must be used to easily capture, transform, and load streaming data into S3, ElasticSearch, and Splunk?
	Amazon Kinesis Data Firehose

Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. 
It can capture, transform, and load streaming data into  S3,  Redshift,  Elasticsearch Service, and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you are already using today.

Amazon SQS lets you easily move data between distributed application components and helps you build applications in which messages are processed independently (with message-level ack/fail semantics), such as automated workflows. Amazon Kinesis Data Firehose is primarily used to load streaming data into data stores and analytics tools.
SQS can't capture, transform, and load streaming data into Amazon S3,

AWS Data Exchange is  is just a data marketplace service.






To save costs, From Reserved instances as soon as possible:
	Go to the AWS Reserved Instance Marketplace and sell the Reserved instances.
	Terminate the Reserved instances as soon as possible to avoid getting billed at the on-demand price when it expires.
	 
Stopping the Reserved instances as soon as possible if false because It is also possible that there are associated 
Elastic IP addresses, which will incur charges. You have to terminate.





S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and your S3 bucket. 
Transfer Acceleration leverages Amazon CloudFront’s globally distributed AWS Edge Locations. 
As data arrives at an AWS Edge Location, data is routed to your  S3 bucket over an optimized network path.






AWS Fargate is a serverless compute engine for containers that works with both ECS and EKS.

Amazon EKS is more suitable to run the Kubernetes management infrastructure and not Docker. 
It not remove the need to provision and manage servers nor let you specify and pay for resources per application, unlike Fargate EKS.






Collect logs and then easily perform log analysis:
	 S3 for storing ELB log files and EMR for analyzing the log files.
	 
Amazon EMR is the industry-leading cloud big data tools managed Hadoop framework and solution for petabyte-scale data 
processing, interactive analytics, and machine learning using open-source frameworks such as Apache Spark, Apache Hive, and Presto.







Launch a real-time analytics service:
	Create a Kinesis Data Stream and use AWS Lambda to read records from the data stream.

Although Amazon Kinesis Data Firehose captures and loads data in near real-time, AWS Lambda can't be set as its destination.





You can create read replicas within a Region or between Regions for your 
RDS for MySQL, MariaDB, PostgreSQL, and Oracle database instances encrypted at rest with AWS Key Management Service (KMS).





S3 is composed of buckets, object keys, object metadata, object tags, and many other components as shown below:
	S3 bucket name is globally unique, and the namespace is shared by all AWS accounts.
	S3 object key refers to the key name, which uniquely identifies the object in the bucket.
	S3 object metadata is a name-value pair that provides information about the object.
	S3 object tag is a key-pair value used for object tagging to categorize storage.
	 
 
 



	 
Ensure that the required components are properly running before the CloudFormation stack creation proceeds:
	Configure a CreationPolicy attribute to the instance in the CloudFormation template. 
	Send a success signal after the applications are installed and configured using the cfn-signal helper script.
	
In CloudFormation template Use the CreationPolicy attribute when you want to wait on resource configuration actions 
before stack creation proceeds. 

In such cases, you can add a CreationPolicy attribute to the instance and then send a success signal to the instance 
after the applications are installed and configured.





Docker It is compulsory that the application has access to 5 GB of ephemeral storage:
	Deploy the application to an Amazon ECS cluster that uses Fargate tasks.
By default, Fargate tasks are given a minimum of 20 GiB of free ephemeral storage. 
	
	 



A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them privately. 
Instances in either VPC can communicate with each other as they are in the same network. 

You can create a VPC peering connection between your own VPCs,  another AWS account, or different Region.





Amazon Aurora DB cluster to Autora serverless:
	Changing the Aurora instance class from Provisioned to Serverless is not possible.
	Use AWS Database Migration Service (AWS DMS) to migrate to a new Aurora Serverless database.
AWS Database Migration Service helps you migrate your databases to AWS with virtually no downtime. 
You can set up a DMS task for either one-time migration or ongoing replication. 


Take a snapshot involves a long period of downtime since you have to stop the application until the new cluster is created.

Add an Aurora Replica to the cluster and set its instance class to Serverless,While this method is valid, 
the database becomes unavailable for writing for a short period of time during failover.




You can launch an EBS-backed EC2 instance and attach several Instance Store volumes but remember that there are some 
EC2 Instance types that don't support this kind of setup.

ENI will stay attached even if you stopped your EC2 instance.
EIP will actually remain associated with your instance even after stopping it.


Since only EBS-backed instances can be stopped and restarted, it is implied that the instance is EBS-backed. 
Remember that an instance store-backed instance can only be rebooted or terminated, and its data will be erased if the 
EC2 instance is either stopped or terminated.

If you stopped an EBS-backed EC2 instance, the volume is preserved, but the data in any attached instance store volume will be erased. 
Keep in mind that an EC2 instance has an underlying physical host computer. 
If the instance is stopped, AWS usually moves the instance to a new host computer. 
Your instance may stay on the same host computer if there are no problems with the host computer.
 
In addition, its Elastic IP address is remove from the instance if it is an EC2-Classic instance. 
Otherwise, if it is an EC2-VPC instance, the Elastic IP address remains associated.






MySQL database hosted on Amazon RDS is running out of disk storage:
	Modify the DB instance settings to enable autoscaling.





Aurora as the Amazon RDS database need 90-day backup retention:
	Create an AWS Backup plan to take daily snapshots with a retention period of 90 days.

Aurora maximum backup retention period for automated backup is only 35 days.

AWS Backup makes protecting your AWS storage volumes, databases, and file systems simple by providing a central place where you 
can configure and audit the AWS resources you want to backup, automate backup scheduling, set retention policies, 
and monitor all recent backup and restore activity.





You are limited to provision a maximum of 20 instances per region or 
On-Demand Instances per your vCPU-based On-Demand Instance limit, 
20 Reserved Instances, and requesting Spot Instances per your dynamic Spot limit per region. 

New AWS accounts may start with limits that are lower than the limits described here.

vCPU-based On-Demand Instance limit is set per region and not per Availability Zone. 






The company’s solutions architect must implement a solution that checks for untagged AWS resources.
	Use an AWS Config rule to detect non-compliant tags.
	
	
	
	
Developers are unable to remove or modify any rules in AWS Config.
	 Add the developers' AWS account to an Organization Unit (OU). Attach a service control policy (SCP) to the OU that 
	 restricts access to AWS Config.
	 
SCPs alone is not sufficient to grant permissions to the accounts in your organization. No permissions are granted by an SCP. 
An SCP defines a guardrail or sets limits on the actions that the account's administrator can delegate to the IAM users and roles 
in the affected accounts.

In the scenario, even if a developer has admin privileges, he/she will be unable to modify Config rules if an SCP does not permit it.

Configure an AWS Config rule, This solution just monitors changes on AWS Config rules; 
it does not restrict permissions, which is what's needed in the scenario. 

The AWS Control Tower service is commonly used to set up and govern a secure multi-account AWS environment. 
This service is not used to restrict access from invoking an action to a specific resource, such as AWS Config.







Use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) :
	with a master key that it regularly rotates. 
	S3 server-side encryption uses one of the strongest block ciphers available, 256-bit Advanced Encryption.

	 
Use Server-Side Encryption with Customer Master Keys (CMKs) Stored in AWS Key Management Service (SSE-KMS):
	use envelope encryption,SSE-KMS also provides you with an audit trail that shows when your CMK was used and by whom. 
	Additionally, you can create and manage customer-managed CMKs or use AWS managed CMKs that are unique to you, your service, 
	and your Region.

Use Server-Side Encryption with Customer-Provided Keys (SSE-C):
	You manage the encryption keys and Amazon S3 manages the encryption, as it writes to disks, and decryption when you access 
	your objects.


SSE-S3 and SSE	-C do not provide  audit trail that shows when your Key was used and by whom,unlike SSE-KMS.
	 
	 
	 



Unified CloudWatch agent, and an older CloudWatch Logs agen:
	Collect both logs and advanced metrics with the installation and configuration of just one agent.
	
Unified agent collect metrics and logs from  EC2, hybrid, and on-premises servers running both Linux and Windows
Unified agent also enables the collection of additional system metrics, for in-guest visibility.
	
CloudWatch Logs Insights enables you to interactively search and analyze your log data in CloudWatch Logs.	
	 
	 
	 


Duplicating resources in another region:
	AWS CloudFormation
You can create a template that describes all the AWS resources that you want (like  EC2 or RDS ), 
AWS CloudFormation takes care of provisioning and configuring those resources for you with VPC.

AWS ElasticBeanstalk is incorrect. 
	Elastic Beanstalk is a high-level service that simplifies the creation of application resources such as an 
	EC2 with preconfigured proxy servers (Nginx or Apache), a load balancer, an auto-scaling group, and so on. 
	Elastic Beanstalk environments have limited resources; for example, Elastic Beanstalk does not create a VPC for you.




 
Auto Scaling group need new AMI instance:
	 Create a new Launch Configuration with the new instance type and update the Auto Scaling Group.
	 You can't modify a launch configuration after you've created it.
	 
	 
	 
	 
	 
EBS provides three volume types to best meet the needs of your workloads: 
	General Purpose (SSD)   for cost-effective storage option for a wide variety of workloads.  gp2
	Provisioned IOPS (SSD)  for very intensive I/O workloads that require very high throughput. io1 
	Magnetic                for Low-cost HDD volume designed for throughput-intensive/infrequently accessed data workloads. st1/sc1




	 
Increase read-throughput on the MySQL database:
	Enable Amazon RDS Read Replicas
	 
Read replicas are available in Amazon RDS for MySQL, MariaDB, Oracle, and PostgreSQL as well as Amazon Aurora.	 
	 
	 




VM workloads to the AWS cloud, “lift-and-shift” strategy: 
		Install the AWS Replication Agent on each of the on-premises VMs to continuously replicate the servers to AWS. 
		Use AWS Migration Service (AWS MGN) to launch test instances and perform cutover once testing is completed.
		
AWS Application Migration Service (AWS MGN) is the primary migration service recommended for lift-and-shift migrations to AWS.	 
AWS MGN enables organizations to move applications to AWS without having to make any changes to the applications, 
their architecture, or the migrated servers.

AWS MGN automatically converting your source servers from physical, virtual machines, and cloud infrastructure to run natively on AWS.
Implementation begins by installing the AWS Replication Agent on your source servers.
	 
	 
AWS Application Discovery Service is primarily used to track the migration status not capable of doing the actual migration.


	 
	 
	 

Requirement if I/O throughput is the highest priority:
		Use Storage optimized instances with Instance Store Volume.
	 
EC2 Instance types can be broadly classified into five:
	General Purpose         =  Provide a balance of compute, memory and networking resources.
	Compute-Optimized       =  These types of instances have a higher CPU to memory ratio.
	Memory-Optimized        =  Optimized to execute memory-intensive operations like in-memory databases or processing real-time data.
	Storage-Optimized       =  Storage optimized EC2 instances are used to support high I/O workloads such as parallel processing.
	Accelerated Computing   =  It provides compute capacity for very high performant machine learning and scientific workloads( With GPU).




UDP is not supported in Application Load Balancer. UDP is a Layer 4 traffic, use a Network Load Balancer.
	
	
	
	
AWS resources in Amazon VPC don’t go beyond their respective service limits,rovides real-time guidance:
	AWS Trusted Advisor.
	
Trusted Advisor is online tool that provides you with real-time guidance to help you provision your resources following best practices. 
It inspects your AWS environment and makes recommendations for saving money, improving system performance and reliability,security gaps.

	

	 
	 
Development of its GraphQL APIs, custom domain feature and https:
	Develop the application using the AWS AppSync service and use its built-in custom domain feature. 
	Associate an SSL certificate to the AWS AppSync API using the ACM service to enable HTTPS communication.

With AppSync, you can use custom domain names to configure a single, memorable domain that works for both your GraphQL and real-time APIs.
	
	
	
	
	 
	 
Multiple AWS Site-to-Site VPN,slow connectivity issues:
	Associate the VPCs to an Equal Cost Multipath Routing (ECMR)-enabled Transit Gateway and attach additional VPN tunnels.
	 
AWS Transit Gateway also enables you to scale the IPsec VPN throughput with equal-cost multi-path (ECMP) routing support over 
multiple VPN tunnels. 
A single VPN tunnel still has a maximum throughput of 1.25 Gbps. 
If you establish multiple VPN tunnels to an ECMP-enabled Transit Gateway, it can scale beyond the default limit of 1.25 Gbps.

	 
	 
	 
	 
For provides higher bandwidth, higher packet per second (PPS) performance, and consistently lower inter-instance latencies: 
	Enable Enhanced Networking with Elastic Network Adapter (ENA) on the Windows EC2 Instances. 
	 
With RDS Enhanced Monitoring, you can monitor the operating system of your DB instance in real time.
With EC2 enable Detailed Monitoring, EC2 console displays monitoring graphs with a 1-minute period for the instance.

	 
	 
	 
	 
In SQS the number of messages is constantly growing:	 
		Create an AMI of the backend application's EC2 instance. Use the image to set up an Auto Scaling group and configure a 
		target tracking scaling policy based on the ApproximateAgeOfOldestMessage metric.
		
The ApproximateAgeOfOldestMessage metric is useful when applications have time-sensitive messages and you need to ensure that 
messages are processed within a specific time period.






On Receives a burst of traffic then instance takes 1 minute to boot up before it can respond to user requests:
		Create a step scaling policy and configure an instance warm-up time condition.
	 
	 
	 
	 

Telecommunication carriers' 5G networks:	 
		Launch the application to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. Create node groups in 
		Wavelength Zones for the Amazon EKS cluster via the AWS Wavelength service. 
		Apply the AWS authenticator configuration map (aws-auth ConfigMap) to your cluster.
		
AWS Wavelength combines the high bandwidth and ultralow latency of 5G networks with AWS compute and storage services so that 
developers can innovate and build a new class of applications.
	
	



The Volume Gateway is a cloud-based iSCSI block storage volume for your on-premises applications.

There are two options for Volume Gateway:
	Cached Volumes - you store volume data in AWS, with a small portion of recently accessed data in the cache on-premises.
	Stored Volumes - you store the entire set of volume data on-premises and store periodic point-in-time backups (snapshots) in AWS.

			
			
	 
	 
	 
Both the HTTP (80) and HTTPS (443) check offered Application Load Balancer. 
A TCP health check is only offered in Network Load Balancers and Classic Load Balancers.


	 



Security groups stateful
Network Firewall is a stateful, supports both stateless and stateful rules. 
Network ACLs are stateless.
 
 
 


IAM roles are global services that are available to all regions hence, 
all you have to do is assign the existing IAM role to the instance in the new region.





Multi-Region VPC transfer data between the instances without traversing the public internet:
	Set up a VPC peering connection between the VPCs.
	Re-configure the route table’s target and destination of the instances’ subnet.

VPC endpoints are region-specific only and do not support inter-region communication.
VPC endpoint enables users to privately connect their VPC to supported AWS services. 




Generated log files should be encrypted to avoid any security issues:
	Use CloudTrail with its default settings.
	
By default, CloudTrail event log files are encrypted using Amazon S3 server-side encryption (SSE). 
You can also choose to encrypt your log files with an AWS Key Management Service (AWS KMS) key. 





In EBS encryption, what service does AWS use to secure the volume's data at rest? 
	By using your own keys       	in AWS Key Management Service (KMS).
	By using Amazon-managed keys 	in AWS Key Management Service (KMS).






Enable the security team to inspect traffic entering and exiting their VPC:
	Create a firewall using the AWS Network Firewall service at the VPC level then add custom rule groups for inspecting ingress 
	and egress traffic. Update the necessary VPC route tables.

Traffic Mirroring is simply an Amazon VPC feature that you can use to copy network traffic from an elastic network interface. 
Traffic mirror filters can't inspect the actual packet of the incoming and outgoing traffic.






Processing should not be delayed or interrupted:
	Use On-Demand Capacity Reservations, which provide compute capacity that is always available on the specified recurring schedule.

On-Demand Capacity Reservations enable you to reserve compute capacity for your EC2 instances in a specific Availability Zone 
for any duration






Performance Issue of the Kinesis Data Streams:
	Increase the number of shards of the Kinesis stream by using the UpdateShardCount command.	




Highly scalable, yet still cost-effective:
	Launch an Auto-Scaling group of EC2 instances to host your application services and an SQS queue. 
	Include an Auto Scaling trigger to watch the SQS queue size which will either scale in or scale out the number of 
	EC2 instances based on the queue.
	
	
	
	
Extracting and visualizing sentiments from the transcribed files:
	Create an Amazon Comprehend analysis job. Index the sentiment along with the transcript to an Amazon OpenSearch cluster. 
	Visualize the results using the OpenSearch Dashboard.
	
	


Lambda execution The default timeout is 3 seconds, and minumum 1 second up to a maximum value of 15 minutes.




Set up the multi-account AWS environment for your company:
	Use AWS Organizations and Service Control Policies to control services on each account.

AWS Organizations offers policy-based management for multiple AWS accounts. 
With Organizations, you can create groups of accounts, automate account creation, apply and manage policies for those groups.

Organizations enable you to centrally manage policies across multiple accounts without requiring custom scripts and manual processes. 
It allows you to create Service Control Policies (SCPs) that centrally control AWS service use across multiple AWS accounts.








@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

10 applications with an on-premises 70TB data for each application, two weeks to migration:
	Order 10 Snowball Edge Storage Optimized devices to complete the one-time data transfer.
	Setup Site-to-Site VPN to establish on-going connectivity between the on-premises data center and AWS Cloud.

Snowball Edge:
	It provides up to 80 TB of usable HDD storage, 40 vCPUs, 1 TB of SATA SSD storage, and up to 40 Gb network connectivity.
 
Site-to-Site VPN:
	VPN Connections can be configured in minutes and are a good solution if you have an immediate need, have low to modest 
	bandwidth requirements with internat base connectivity.

Snowmobile capacity of up to 100 petabytes. 
To migrate large datasets of 10PB or more in a single location, you should use Snowmobile.
For datasets less than 10PB or distributed in multiple locations, you should use Snowball. 




When you apply a retention period to an object version explicitly, you specify a Retain Until Date for the object version.
S3 stores the Retain Until Date setting in the object version's metadata and protects the object version until the 
retention period expires.

In Default setting you specify a duration, in either days or years, for every object version placed in the bucket.





Intermediary query results are kept only for 24 hours:
	Store the intermediary query results in S3 Standard storage class

S3 Glacier Instant Retrieval:
	S3 Glacier Instant Retrieval delivers the fastest access to archive storage, with the same throughput and milliseconds access as 
	the S3 Standard and S3 Standard-IA storage classes.




Native Windows workloads should continue to AWS:
	Use FSx File Gateway to provide low-latency, on-premises access to fully managed file shares in  FSx for Windows File Server.
	The applications deployed on AWS can access this data directly from Amazon FSx in AWS.
	SMB clients with native Windows SMB environment)

Amazon Storage Gateway’s File Gateway: 
	When you need to access S3 using a file system protocol, you should use File Gateway with SMB. 
	File Gateway does not support file shares for native Windows workloads, for that use Amazon FSx File Gateway.




Wants to integrate data files from application with AWS Cloud via an NFS interface:
	AWS Storage Gateway - File Gateway.
	
AWS Storage Gateway's file interface, or file gateway, offers you a seamless way to connect to the cloud in order to 
store application data files and backup images as durable objects on Amazon S3 cloud storage. 

File gateway offers SMB or NFS-based access to data in Amazon S3 with local caching. 
As the company wants to integrate data files from its analytical instruments into AWS via an NFS interface, 
therefore AWS Storage Gateway - File Gateway is the correct answer.

Volume Gateway to present iSCSI block storage volumes, Volume Gateway does not support NFS interface.
Tape Gateway does not support NFS interface.
You cannot use AWS Site-to-Site VPN to integrate data files via the NFS interface.




1 EC2 instance, 1 AMI and 1 snapshot exist in region B:
	When the new AMI is copied from region A into region B, it automatically creates a snapshot in region B because 
	AMIs are based on the underlying snapshots.
	


GuardDuty service. All the existing findings have to be deleted:
	Disable the service in the general settings - Disabling the service will delete all remaining data, including your 
	findings and configurations before relinquishing the service permissions and resetting the service.

Suspend the service in the general settings:
	This will immediately stop the service from analyzing data, but does not delete your existing findings or configurations.
	
No De-register option,  only Disable and Suspend.


	


ALB Routing:
	Host-based Routing:
	You can route a client request based on the Host field of the HTTP header allowing you to route to multiple 
	domains from the same load balancer.

	Path-based Routing:
	You can route a client request based on the URL path of the HTTP header.

	HTTP header-based routing:
	You can route a client request based on the value of any standard or custom HTTP header.

	HTTP method-based routing:
	You can route a client request based on any standard or custom HTTP method.

	Query string parameter-based routing:
	You can route a client request based on the query string or query parameters.

	Source IP address CIDR-based routing:
	You can route a client request based on source IP address CIDR from where the request originates.

The path pattern is applied only to the path of the URL, not to its query parameters.




Requires exactly 10 instances to be available during the peak hour:
	Configure your Auto Scaling group by creating a scheduled action that kicks-off at the designated hour on the last day of the month. 
	Set the desired capacity of instances to 10. This causes the scale-out to happen before peak traffic kicks in at the designated hour.

A scheduled action sets the minimum, maximum, and desired sizes to what is specified by the scheduled action at the time 
specified by the scheduled action. For the given use case, the correct solution is to set the desired capacity to 10. 
When we want to specify a range of instances, then we must use min and max values.

Target tracking policy or simple tracking policy cannot be used to effect a scaling action at a certain designated hour.




AWS services would you recommend as a caching layer:
	DynamoDB Accelerator (DAX) - Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache for DynamoDB.
	ElastiCache - Amazon ElastiCache for Memcached is an ideal front-end for data stores like Amazon RDS or Amazon DynamoDB.





INVALID lifecycle transitions:
	S3 Intelligent-Tiering => S3 Standard
	S3 One Zone-IA => S3 Standard-IA

Any storage class to the S3 Standard storage class. 
Any storage class to the Reduced Redundancy storage class. 
S3 Intelligent-Tiering storage class to the S3 Standard-IA storage class.
S3 One Zone-IA storage class to the S3 Standard-IA or S3 Intelligent-Tiering.
 
 

VALID lifecycle transitions:
	S3 Standard => S3 Intelligent-Tiering
	S3 Standard-IA => S3 Intelligent-Tiering
	S3 Standard-IA => S3 One Zone-IA


S3 Standard storage class to any other storage class. 
Any storage class to the S3 Glacier or S3 Glacier Deep Archive.
S3 Standard-IA storage class to the S3 Intelligent-Tiering or S3 One Zone-IA storage classes.
S3 Intelligent-Tiering storage class to the S3 One Zone-IA storage class.
S3 Glacier storage class to the S3 Glacier Deep Archive storage class.


WaterFall: S3 Standard
			 S3 Standard-IA
			   S3 Intelligent-Tiering
				 S3 One Zone-IA
				   S3 Glacier
				     S3 Glacier Deep Archive
					 

 
Use Instance Store based EC2 instances for high random I/O performance at low cost,and the resilient architecture 
	can adjust for the loss of any instance.

Use EBS based EC2 instances - EBS based volumes would need to use Provisioned IOPS (io1) as the storage type and that would 
incur additional costs. As we are looking for the most cost-optimal solution, this option is ruled out.

Use EC2 instances with EFS mount points - Using EFS implies that extra resources would have to be provisioned. 
As we are looking for the most resource-efficient solution, this option is also ruled out.





Configure AWS WAF on the Application Load Balancer in a VPC:
	WAF with ALB to allow or block requests based on the rules in a web access control list (web ACL). 
	Geographic (Geo) Match Conditions in AWS WAF allows you to use AWS WAF to restrict application access based on the 
	geographic location of your viewers. 
With geo match conditions you can choose the countries from which AWS WAF should allow access.
	
Use Geo Restriction feature of Amazon CloudFront in a VPC :
	CloudFront helps in restricting traffic based on the user's geographic location. 
	But, CloudFront works from edge locations and doesn't belong to a VPC, this is Incorrect.





Ingest the data in Kinesis Data Firehose and use an intermediary Lambda function to filter and transform the incoming stream 
before the output is dumped on S3.

	Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. 
	It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, 
	and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you’re already using today.

	Kinesis Data Analytics cannot directly ingest data from the source, it ingests data either from 
	Kinesis Data Streams or Kinesis Data Firehose, so this option is ruled out.

	Kinesis Data Streams cannot directly write the output to S3. Unlike Firehose, KDS does not offer a ready-made integration via an 
	intermediary Lambda function to reliably dump data into S3. 

	EMR uses Hadoop, an open-source framework, to distribute your data and processing across a resizable cluster of Amazon EC2 instances. 
	Using an EMR cluster would imply managing the underlying infrastructure so it’s ruled out because the correct solution 
	for the given use-case should require the least amount of infrastructure maintenance.

	 
	 
 

Make More resilient to spikes in request rates:
	You can use Aurora replicas and CloudFront distribution to make the application more resilient to spikes in request rates.

Aurora Replicas have two main purposes. You can issue queries to them to scale the read operations for your application.
Aurora Replicas also help to increase availability. If the writer instance in a cluster becomes unavailable, 
Aurora automatically promotes one of the reader instances to take its place as the new writer.

Use AWS Global Accelerator - AWS Global Accelerator is a service that improves the availability and performance of your 
applications with local or global users. It provides static IP addresses that act as a fixed entry point to your application 
endpoints in a single or multiple AWS Regions.
Since CloudFront is better for improving application resiliency to handle spikes in traffic, so this option is ruled out.




Since the data is accessed only twice in a financial year but needs rapid access when required, the most cost-effective 
storage class for this use-case is S3 Standard-IA. 

Standard-IA has the same availability as that of S3 Intelligent-Tiering. So, it's cost-efficient to use 
S3 Standard-IA instead of S3 Intelligent-Tiering.





Maintenance patching, the instance, MOST time/resource efficient steps:
	Put the instance into the Standby state and then update the instance by applying the maintenance patch. 
	Once the instance is ready, you can exit the Standby state and then return the instance to service
You can put an instance that is in the InService state into the Standby state, update some software or troubleshoot the instance.	
Instances that are on standby are still part of the Auto Scaling group, but they do not actively handle application traffic.	

Suspend the ReplaceUnhealthy process type for the Auto Scaling group and apply the maintenance patch to the instance. 
Once the instance is ready, you can manually set the instance's health status back to healthy and activate the 
ReplaceUnhealthy process type again.

Taking the snapshot of the existing instance to create a new AMI and then creating a new instance not time/resource optimal.





Peak rate of about 1000 messages per second to be processed via SQS:
	Use Amazon SQS FIFO queue in batch mode of 4 messages per operation to process the messages at the peak rate.
	
Maximum batch 10 messages per operation , FIFO queues can support up to 3,000 messages per second. 
Maximum batch size for a standard Amazon SQS queue is 10,000 records. 	



24*7 in the production environment and 8 hour for dev:
	Use reserved EC2 instances for the production application and on-demand instances for the dev application.

Spot blocks can only be used for a span of up to 6 hours, so this option does not meet the requirements,
also note that AWS has stopped offering Spot blocks to new customers.




There are no S3 data transfer charges when data is transferred in from the internet. 
Also with S3TA, you pay only for transfers that are accelerated.
Does not need to pay any transfer charges for the upload because S3TA did not result in an accelerated transfer.





Default ASG Scaling- in: Select the AZ with most instance and then:
	First priority is given to any allocation strategy for On-Demand vs Spot instances. 
	The next priority is to consider any instance with the oldest launch template unless there is an instance 
	that uses a launch configuration. So this rules out Instance A. 
	Next, you need to consider any instance which has the oldest launch configuration. 
	This implies Instance B will be selected for termination and Instance C will also be ruled out as it has the 
	newest launch configuration. 
	Instance D, which is closest to the next billing hour, is not selected as this criterion is last in the order of priority.
	
	


Wants to manage the workload using a mix of on-demand and spot instances across multiple instance types:
	You can only use a launch template to provision capacity across multiple instance types using both 
	On-Demand Instances and Spot Instances to achieve the desired scale, performance, and cost.
	
You cannot use a launch configuration to provision capacity across multiple instance types using both 
On-Demand Instances and Spot Instances.




(ASG) is not terminating an unhealthy Amazon EC2 instance:
	The health check grace period for the instance has not expired.(with until the health check grace period expires, def 5m, with CLI 0)
	The instance maybe in Impaired status.(waits a few minutes for the instance to recover.)
	The instance has failed the ELB health check status. (By default, ASG doesn't use the results of ELB health 
	
	checks to determine an instance's health status when the group's health check configuration is set to EC2. As a result, 
	Amazon EC2 Auto Scaling doesn't terminate instances that fail ELB health checks)
	
ASG terminates Spot instances when capacity is no longer available or the Spot price exceeds your maximum price.
ASG needs more number of instances, ASG will launch new, healthy instances and does not keep unhealthy ones alive.
ASG terminates the unhealthy instance also if A custom health check might have failed.




Kinesis Agent cannot write to a Kinesis Firehose for which the delivery stream source is already set as Kinesis Data Streams.

Kinesis Agent is a stand-alone Java software application that offers an easy way to collect and send data to 
Kinesis Data Streams or Kinesis Firehose.





AWS Organizations and you would like to ensure all EC2 instances in all these accounts can communicate privately:
	Create a VPC in an account and share one or more of its subnets with the other accounts using Resource Access Manager(RAM).
	
AWS Resource Access Manager (RAM) is a service that enables you to easily and securely share AWS resources with any 
AWS account or within your AWS Organization. You can share Transit Gateways, Subnets,Reoute53, DNS Resolver etc.
	
AWS RAM is a Regional service. When you share a resource with principals in other AWS accounts, 
they must access each resource from the same AWS Region that it was created in.





Run their applications on single-tenant hardware and MOST cost-effective way of isolating EC2 instances to a single tenant:
	Dedicated Instances. (IF NO NEED BYOL)

A Dedicated Host is also a physical server that's dedicated for your use. (WITH BYOL)
With a Dedicated Host, you have visibility and control over how instances are placed on the server.
This option is costlier than the Dedicated Instance and hence is not the right choice for the current requirement.





Setup a lifecycle policy to transition the raw zone data into Glacier Deep Archive after 1 day of object creation.
Use Glue ETL job to write the transformed data in the refined zone using a compressed file format.

It is cost-optimal to write the data in the refined zone using a compressed format instead of CSV format.



By default, an S3 object is owned by the AWS account that uploaded it. 
So the S3 bucket owner will not implicitly have access to the objects written by Redshift cluster.





AWS Global Accelerator, you can shift traffic gradually or all at once between the blue and the green environment and 
vice-versa without being subject to DNS caching on client devices and internet resolvers(mobile phones which are to DNS caching).

Route 53 weighted routing to spread traffic across different deployments not working because
DNS caching is a negative behavior for this use case and hence Route 53 is not a good option.

ALB with weighted target groups feature for blue/green deployments now working because ALB not Global servies it Regional.

	
	


All the log files (consisting of system logs, application logs, database logs, etc) that can be processed in a serverless fashion:
	Kinesis Data Firehose.
	
 
 
 

"Effect": "Allow",
  "Resource": "*",
  "Condition": {
	"StringEquals": {
	  "aws:RequestedRegion": "eu-west-1"
	}

It allows running EC2 instances only in the eu-west-1 region, and the API call can be made from anywhere in the world.

aws:RequestedRegion represents the target of the API call. 
So in this example, we can only launch EC2 instances in eu-west-1, and we can do this API call from anywhere.



Prevent team of developers in your company, make self admin:
	For each developer, define an IAM permission boundary that will restrict the managed policies they can attach to themselves.
AWS supports permissions boundaries for IAM entities (users or roles).

SCP not work here because, SCPs working with your Organization accounts.





Notifies the security team 30 days before the certificate expiration:
	Leverage AWS Config managed rule to check if any third-party SSL/TLS certificates imported into ACM are marked for expiration 
	within 30 days. 
	Configure the rule to trigger an SNS notification to the security team if any certificate expires within 30 days.

You can leverage an AWS Config managed rule to check if any ACM certificates in your account are marked for 
expiration within the specified number of days what is imported. Certificates provided by ACM are automatically renewed. 

ACM does not automatically renew the certificates that you import. 

Certificate Manager (ACM) does not attempt to renew third-party certificates that are imported.

Any SSL/TLS certificates created via ACM do not need any monitoring/intervention for expiration. 
ACM automatically renews such certificates. 

It is certainly possible to use the days to expiry CloudWatch metric to build a CloudWatch alarm to monitor the imported ACM certificates. 
But this option needs more configuration effort than directly using the AWS Config managed rule.





Notified via an email whenever the CPU utilization high:
	SNS and Amazon CloudWatch.
You can use CloudWatch Alarms to send an email via You can use CloudWatch Alarms to send an email via SNS whenever 
any of the EC2 instances breaches a certain threshold. whenever any of the EC2 instances breaches a certain threshold.
	
	
	

decouple the user authentication process for the application:
	Use Cognito Authentication via Cognito User Pools for your Application Load Balancer
Application Load Balancer can be used to securely authenticate users for accessing your applications.

You cannot directly integrate Cognito User Pools with CloudFront distribution as you need to create a separate Lambda@Edge 
This involves additional development effort.




Replicate the newly created on-premises video files to the EFS file system:
	Configure an AWS DataSync agent on the on-premises server that has access to the NFS file system. 
	Transfer data over the Direct Connect connection to an AWS PrivateLink interface VPC endpoint for Amazon EFS by using a private VIF. 
	Set up a DataSync scheduled task to send the video files to the EFS file system every 24 hours.
	



PostgreSQL port = 5432 HTTP port = 80 HTTPS port = 443
	The security group of RDS should have an inbound rule from the security group of the EC2 instances in the ASG on port 5432
	The security group of the EC2 instances should have an inbound rule from the security group of the ALB on port 80
	The security group of the ALB should have an inbound rule from anywhere on port 443




DNS queries for any resources in the on-premises network from the AWS VPC and visvisa:
	Create an inbound endpoint on Route 53 Resolver and then DNS resolvers on the on-premises network can forward DNS queries 
	to Route 53 Resolver via this endpoint.

	Create an outbound endpoint on Route 53 Resolver and then Route 53 Resolver can conditionally forward queries to resolvers 
	on the on-premises network via this endpoint.




Company wants to run directory-aware workloads on AWS :
	AWS Managed Microsoft AD
	
	
AD Connector - Use AD Connector if you only need to allow your on-premises users to log in to AWS applications and services 
with their Active Directory credentials. 
You cannot use it to run directory-aware workloads on AWS, hence this option is not correct.

Simple AD is a standalone managed directory that is powered by a Samba 4 Active Directory Compatible Server. 
Simple AD does not support features such as trust relationships with other domains and many more.

Amazon Cloud Directory - Amazon Cloud Directory is a cloud-native directory that can store hundreds of millions of 
application-specific objects with multiple relationships and schemas. 
Use Amazon Cloud Directory if you need a highly scalable directory store for your application’s hierarchical data. 
You cannot use it to establish trust relationships with other domains on the on-premises infrastructure. 

AWS Managed Microsoft AD is your best choice if you have more than 5,000 users and need a trust relationship set up between an 
AWS hosted directory and your on-premises directories. 

Simple AD is the least expensive option and your best choice 
if you have 5,000 or fewer users and don’t need the more advanced Microsoft Active Directory features such as trust 
relationships with other domains.



Spot instances:	
	If a spot request is persistent, then it is opened again after your Spot Instance is interrupted
	Spot blocks are designed not to be interrupted
	When you cancel an active spot request, it does not terminate the associated instance




Service control policies (SCPs):
If a user or role has an IAM permission policy that grants access to an action that is either not allowed or 
explicitly denied by the applicable SCPs, the user or role can't perform that action

SCPs affect all users and roles in attached accounts, including the root user

SCPs do not affect service-linked role
	A service-linked role is a unique type of IAM role that is linked directly to an AWS service. 
	Service-linked roles are predefined by the service and include all the permissions that the service requires to call 
	other AWS services on your behalf.





live sports results via UDP:
	Use Global Accelerator to provide a low latency way to distribute live sports results.
Global Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP. 


CloudFront supports HTTP/RTMP protocol based requests, therefore this option is incorrect.
ALB or ASG cannot help with decreasing latency of incoming traffic from the source.




Each EC2 instance that you launch into a VPC has a tenancy attribute(default, dedicated, host):
	You can only change the tenancy of an instance from dedicated to host and host to dedicated after you've launched it.



If either Launch Configuration Tenancy or VPC Tenancy is set to dedicated, then the instance tenancy is also dedicated.
	When you create a launch configuration, the default value for the instance placement tenancy is null and the 
	instance tenancy is controlled by the tenancy attribute of the VPC. 

	If you set the Launch Configuration Tenancy to default and the VPC Tenancy is set to dedicated, 
	then the instances have dedicated tenancy. 
	If you set the Launch Configuration Tenancy to dedicated and the VPC Tenancy is set to default, 
	then again the instances have dedicated tenancy.




Multiple AWS Site-to-Site VPN:
	If you have multiple AWS Site-to-Site VPN connections, you can using the AWS VPN CloudHub. 

The corporate headquarters has an AWS Direct Connect connection to the VPC and the branch offices have 
Site-to-Site VPN connections to the VPC.
Therefore using the AWS VPN CloudHub, branch offices can send and receive data with each other as well as with their 
corporate headquarters.

VPC Endpoint - A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services 
powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection.

VPC peering facilitates a connection between two VPCs within the same AWS network, therefore this option cannot be used to 
send and receive data between the remote branch offices of the company.

Software VPN just handles connectivity between the remote network and Amazon VPC, therefore it cannot be used to send and 
receive data between the remote branch offices of the company.




ECS container instances running behind an ALB website slows down when the traffic spikes:
	Configure AWS Auto Scaling to scale out the ECS cluster when the ECS service's CPU utilization rises above a threshold.
	


Address Translation for the EC2 instance:
	Internet Gateway, Address Translation is done by Internet Gateway.
Additionally, an Internet Gateway supports IPv4 and IPv6 traffic.

To enable access to or from the internet for instances in a subnet in a VPC, you must do the following:
	Attach an Internet gateway to your VPC.
	Ensure that instances in your subnet have a globally unique IP address (public IPv4 address, Elastic IP address, or IPv6 address).
	Ensure that your network access control lists and security group rules allow the relevant traffic to flow to and from your instance.
	
	
	
Impaired automatic recovery process by CloudWatch alarm:
	A recovered instance is identical to the original instance, including the instance ID, private IP addresses, Elastic IP addresses, 
	and all instance metadata.
	If your instance has a public IPv4 address, it retains the public IPv4 address after recovery
	If the impaired instance is in a placement group, the recovered instance runs in the placement group. 




Pre-defined configurations for all deployment, such as using a specific type EC2, specific IAM roles:
	Use AWS CloudFormation StackSets to deploy the same template across AWS accounts and regions.
A StackSets lets you create stacks for different AWS accounts across regions by using a single AWS CloudFormation template.
Using an administrator account of an "AWS Organization".

CloudFormation templates cannot be used to deploy the same template across AWS accounts and regions.	
	





Purchased the domain covid19survey.com using Route 53:
	Create an alias record for covid19survey.com that routes traffic to www.covid19survey.com

You cannot create a CNAME record for the top node of the DNS namespace, so this option is incorrect.

Additionally, an alias record can only redirect queries to selected AWS resources such as S3 buckets, CloudFront distributions, 
and another record in the same Route 53 hosted zone; however a CNAME record can redirect DNS queries to any DNS record. 
So, you can create a CNAME record that redirects queries from app.covid19survey.com to app.covid19survey.net.




Your application is hosted by a provider on yourapp.provider.com. 
You would like to have your users access your application using www.your-domain.com ?
	Create a CNAME record
A CNAME record maps DNS queries for the name of the current record, such as acme.example.com, to another domain 
(example.com or example.net) or subdomain (acme.example.com or zenith.example.org).
		
CNAME records can be used to map one domain name to another. 
Although you should keep in mind that the DNS protocol does not allow you to create a CNAME record for the top node of a DNS namespace, 
also known as the zone apex. For example, if you register the DNS name example.com, the zone apex is example.com. 
You cannot create a CNAME record for example.com, but you can create CNAME records for www.example.com, newproduct.example.com, and so on.




What does this CloudFormation snippet do? (Select three)

SecurityGroupIngress:
     - IpProtocol: tcp
       FromPort: 80
       ToPort: 80
       CidrIp: 0.0.0.0/0
     - IpProtocol: tcp
       FromPort: 22
       ToPort: 22
       CidrIp: 192.168.1.1/32
	   
It allows any IP to pass through on the HTTP port.
It configures a security group's inbound rules.
It lets traffic flow from one IP on port 22.

	   


Authenticate to your DB instance:
	Use IAM authentication from Lambda to RDS PostgreSQL
	Attach an AWS Identity and Access Management (IAM) role to AWS Lambda

Authenticate to your DB instance using AWS Identity and Access Management (IAM) database authentication. 
IAM database authentication works with MySQL and PostgreSQL. 
With this authentication method, you don't need to use a password when you connect to a DB instance. 
Instead, you use an authentication token.		   




Route 53 simple record to point "myapp.mydomain.com" from the old Load Balancer to the new one:
	The TTL is still in effect - TTL (time to live), is the amount of time, in seconds, 
	that you want DNS recursive resolvers to cache information about a record.
	

	


DB failover facilitate with a short Recovery Time Objective (RTO):
	Provision Amazon Aurora Global Database.
Aurora Global Database is good for applications that need to support cross-Region reads with low latency updates and the ability to 
quickly failover between regions. 

DynamoDB global tables provide cross-region active-active capabilities with high performance, but you lose some of the data access 
flexibility that comes with SQL-based databases. 
Due to the active-active configuration of DynamoDB global tables, there is no concept of failover because the 
application writes to the table in its region, and then the data is replicated to keep the other regions' table in sync. 
DynamoDB global tables is a much costlier solution than Aurora Global Database for the given requirement.



Concerned about the VPC-bound components accessing SQS over the public internet:
	Use VPC endpoint to access Amazon SQS
	
AWS customers can access SQS from their Amazon VPC using VPC endpoints, 
without using public IPs, and without needing to traverse the public internet.	




Set up a VPC gateway endpoint for Amazon S3. Attach an endpoint policy to the endpoint. 
Update the route table to direct the S3-bound traffic to the VPC endpoint.


VPC in four different ways with the wizard:
	VPC with a public subnet  only
	VPC with a private subnet only and AWS Site-to-Site VPN access

	VPC with public and private subnets (NAT)
	VPC with public and private subnets and AWS Site-to-Site VPN access



Fully managed NoSQL persistent data store with in-memory caching:
	DynamoDB
 It's a fully managed, multi-region, multi-master, durable database with built-in security, 
 backup and restore, and in-memory caching for internet-scale applications with DAX.	

ElastiCache high throughput and low latency in-memory data stores such as Redis and Memcached. 
ElastiCache is used as a caching layer. It's not a fully managed NoSQL database.



	
 
 
{
 "Sid": "IPAllow",
 "Effect": "Allow",
 "Principal": "*",
 "Action": "s3:*",
 "Resource": "arn:aws:s3:::examplebucket/*",
 "Condition": {
	"IpAddress": {"aws:SourceIp": "54.240.143.0/24"},
	"NotIpAddress": {"aws:SourceIp": "54.240.143.188/32"}
 }
}
It authorizes an entire CIDR except one IP address to access the S3 bucket .
	
	
	


S3 data cannot be deleted until the regulatory time period has expired:
	Use S3 Object Lock
S3 Object Lock is an Amazon S3 feature that allows you to store objects using a write once, read many (WORM) model.	
	
Use S3 Glacier Vault Lock:
	A vault is a container for storing archives on Glacier. 
	Since Vault Lock is only for Glacier and not for S3, so it cannot be used for the given use-case.



	
	
Batch job via a shell script:	
	Amazon EC2 is the right choice as it can accommodate batch processing and run customized scripts.
Amazon Kinesis Data Streams/Lambda/Glue those cannot run custom shell scripts.
	
	
	
	
Stream the existing data files as well as any ongoing file updates from S3 to Kinesis Data Streams:
		Leverage AWS Database Migration Service (AWS DMS) as a bridge between Amazon S3 and Amazon Kinesis Data Streams.
	
Using Lambda functions would require significant custom development to write the data into Kinesis Data Streams,
so this option is not the right fit.

S3 cannot directly write data into SNS, although it can certainly use S3 event notifications to send an event to SNS. 
Also, SNS cannot directly send messages to Kinesis Data Streams.


	
	

Data loss of a few minutes without jeopardizing the forecasting models:
		Pilot Light - The term pilot light is often used to describe a DR scenario in which a minimal 
		version of an environment is always running in the cloud.
		
Backup and Restore method is cheaper, it has an RPO in hours, so this option is not the right fit.	
	
Warm Standby -  a fully functional environment is always running in the cloud.	
Multi-Site - A multi-site solution runs on AWS as well as on your existing on-site infrastructure in an active-active configuration. 
Those 2 are option is more costly compared to Pilot Light.	
	
	
	
	
Need to scale and be highly available:	
	Set ASG minimum capacity to 2
	Use Reserved Instances for the minimum capacity
	
When we specify 2 as the minimum capacity, the ASG would create these 2 instances in separate AZs.	
Reserved Instances provide you with significant savings on your Amazon EC2 costs compared to On-Demand Instance pricing. 	
	
	
	
	
Incurring costs that seem too high for their business requirements:	
		Use AWS Cost Explorer Resource Optimization to get a report of EC2 instances that are either 
		idle or have low utilization and use AWS Compute Optimizer to look at instance type recommendations.

AWS Cost Explorer helps you identify under-utilized EC2 instances.		
Compute Optimizer helps you choose the optimal Amazon EC2 instance types, including those that are part of an Amazon 
EC2 Auto Scaling group, based on your utilization data. It does not recommend instance purchase options.



	

Asynchronously decouple the event-driven architecture:	
	Use Amazon EventBridge to decouple the system architecture - Both Amazon EventBridge and Amazon SNS can be used to develop 
	event-driven applications, but for this use case, EventBridge is the right fit.
	
EventBridge is recommended when you want to build an application that reacts to events from SaaS applications and/or AWS services. 
Amazon EventBridge is the only event-based service that integrates directly with third-party SaaS partners. 

SNS can be used for event-based services. But, our use case needs integration with third-party SaaS services, 
hence EventBridge is the right choice, as SNS does not support third-party services integration.

	
SQS is a message queuing service from amazon and works well for decoupling applications. 
It does not directly integrate with third-party SaaS services.




Which is the only resource-based policy that the IAM service supports?
	Trust policy - Trust policies define which principal entities (accounts, users, roles, and federated users) can assume the role.
	
The IAM service supports only one type of resource-based policy called a role trust policy, which is attached to an IAM role.
 
(ACLs) are service policies that allow you to control which principals in another account can access a resource. 
ACLs cannot be used to control access for a principal within the same account.

	



Traffic will often be unpredictable:
	Set up a DynamoDB table in the on-demand capacity mode.

Amazon DynamoDB has two read/write capacity modes for processing reads and writes on your tables:

On-demand
Provisioned (default, free-tier eligible)

On-demand mode:
	You create new tables with unknown workloads.
	You have unpredictable application traffic.
	You prefer the ease of paying for only what you use.
	
Provisioned mode::
	You have predictable application traffic.
	You run applications whose traffic is consistent or ramps gradually.
	You can forecast capacity requirements to control costs.






Copy objects across S3 buckets in different Regions:
	Copy data from the source bucket to the destination bucket using the aws S3 sync command.
	Set up S3 batch replication to copy objects across S3 buckets in different Regions using S3 console.
	
The aws S3 sync command uses the CopyObject APIs to copy objects between S3 buckets.

S3 Batch Replication provides you a way to replicate objects that existed before a replication configuration was in place, 
objects that have previously been replicated, and objects that have failed replication. 

S3 Transfer Acceleration is a bucket-level feature that enables fast, easy, and secure transfers of files over 
long distances between your client and an S3 bucket. 
You cannot use Transfer Acceleration to copy objects across S3 buckets in different Regions using S3 console.
 
 

Create a Lifecycle Policy to transition objects to S3 Standard IA using a prefix after 45 days.




Serverless with Lambad:
	Since Lambda functions can scale extremely quickly, its a good idea to deploy a CloudWatch Alarm that notifies your team 
	when function metrics such as ConcurrentExecutions or Invocations exceeds the expected threshold.

By default, Lambda functions always operate from an AWS-owned VPC and hence have access to any public internet address or public AWS APIs. 
Once a Lambda function is VPC-enabled, it will need a route through a NAT gateway in a public subnet to access public resources.

If you intend to reuse code in more than one Lambda function, you should consider creating a Lambda Layer for the reusable code:
Layers let you keep your deployment package small, which makes development easier. A function can use up to 5 layers at a time.
You can now package and deploy Lambda functions as container images.




Rest api Aurora database have been very high:
	Enable API Gateway Caching
	
You can enable API caching in Amazon API Gateway to cache your endpoint's responses. 
With caching, you can reduce the number of calls made to your endpoint and also improve the latency of requests to your API. 
When you enable caching for a stage, 
API Gateway caches responses from your endpoint for a specified time-to-live (TTL) period, in seconds.

The default TTL value for API caching is 300 seconds. The maximum TTL value is 3600 seconds. TTL=0 means caching is disabled.
 
Adding Aurora Read Replicas would greatly increase the cost, therefore this option is ruled out.
 

	


ALB removes an instance from its pool of healthy instances whenever it is detected as unhealthy but 
the Auto Scaling group fails to kick-in and provision the replacement instance:
	The Auto Scaling group is using EC2 based health check and the Application Load Balancer is using ALB based health check.
	
	
	
 
Migration of hundreds of terabytes of files from their on-premises data center to Amazon S3:
	Use AWS DataSync to migrate existing data to Amazon S3 and then use File Gateway to retain access to the migrated data 
	for ongoing updates from the on-premises applications
	
File Gateway can be used to move on-premises data to AWS Cloud, but it not an optimal solution for high volumes. 
Migration services such as DataSync are best suited for this purpose. 
S3 Transfer Acceleration cannot facilitate ongoing updates to the migrated files from the on-premises applications.



 
Remove sensitive details from the transactions before storing the cleansed transactions in a document database for low-latency retrieval:
	Feed the streaming transactions into Amazon Kinesis Data Streams. 
	Leverage Lambda integration to remove sensitive data from every transaction and then store the cleansed transactions in DynamoDB. 
    The internal applications can consume the raw transactions off the Kinesis Data Stream.
	
The use case requires a near-real-time solution for cleansing, processing and storing the transactions, 
so using a batch process would be incorrect.

You cannot set up multiple consumers for Kinesis Data Firehose delivery streams as it can dump data in a single data repository at a time,
so this option is incorrect.



Spread placement group:
	A spread placement group can span multiple Availability Zones in the same Region. 
	You can have a maximum of seven running instances per Availability Zone per group. 
	Therefore, to deploy 15 EC2 instances in a single Spread placement group, the company needs to use 3 AZs.


	
Use Amazon Transcribe to convert audio files to text and Amazon Athena to understand the underlying customer sentiments.

	
	
	
Performance lag for the data delivery speed between producers and consumers of the data streams:
	Use Enhanced Fanout feature of Kinesis Data Streams.
You should use enhanced fan-out if you have multiple consumers retrieving data from a stream in parallel. 

Kinesis Data Firehose can only write to S3, Redshift, Elasticsearch or Splunk. 
You can't have applications consuming data streams from Kinesis Data Firehose, that's the job of Kinesis Data Streams.

As multiple applications are consuming the same stream concurrently, both SQS Standard and SQS FIFO are not the right fit for the given use-case.
 
 
 
 
 
ProvisionedThroughputExceededException exception:
	Use batch messages
To reduce overhead and increase throughput, the application must batch records and implement parallel HTTP requests. 
This will increase the efficiency overall and ensure you are optimally using the shards.
	
Increasing shards could be a short term fix but will substantially increase the cost, so this option is ruled out.

	


RDS instance resilient from a disaster recovery perspective.
	Use cross-Region Read Replicas
	Enable the automated backup feature of Amazon RDS in a multi-AZ deployment that creates backups across multiple Regions.
	
Amazon RDS supports Cross-Region Automated Backups. Manual snapshots and Read Replicas are also supported across multiple Regions.

	
	
	
DNS alias record to point to the secondary ALB in another Region in case of failure of the primary ALB:	
	Enable an Amazon Route 53 health check 



Created a static website and then deployed it on Amazon S3 url:
	http://bucket-name.s3-website.Region.amazonaws.com
	http://bucket-name.s3-website-Region.amazonaws.com



Huge traffic spike during the upcoming Thanksgiving sale:
	Auto Scaling group scheduled action.
	
	
	

SQS queue got event whenever a new object is uploaded on S3:
	Only Standard SQS queue is allowed as an Amazon S3 event notification destination, whereas FIFO SQS queue is not allowed.
	
	
	
	
Save development time and deployment costs high-throughput request-response message pattern:
	SQS temporary queues
Amazon SQS temporary queues - Temporary queues help you save development time and deployment costs when using 
common message patterns such as request-response. You can use the Temporary Queue Client to create high-throughput, 
cost-effective, application-managed temporary queues.



	
Only the permitted EC2 instances can read from the EFS file system:
	Use VPC security groups to control the network traffic to and from your file system
	Use an IAM policy to control access for clients who can mount your file system with the required permissions

You control which EC2 instances can access your EFS file system by using VPC security group rules and AWS Identity and Access 
Management (IAM) policies. Use VPC security groups to control the network traffic to and from your file system. 
Attach an IAM policy to your file system to control which clients can mount your file system and with what permissions, 
and you may use EFS Access Points to manage application access. 
Control access to files and directories with POSIX-compliant user and group-level permissions.

GuardDuty is a threat detection service that continuously monitors for malicious activity and unauthorized behavior to 
protect your AWS accounts, workloads, and data stored in Amazon S3. 
It cannot be used for access control to the EFS file system.





Instance Store volumes:
	You can't detach an instance store volume from one instance and attach it to a different instance .
	If you create an AMI from an instance, the data on its instance store volumes isn't preserved.
	
If an instance reboots (intentionally or unintentionally), data in the instance store persists.	
	
When you stop, hibernate, or terminate an instance, every block of storage in the instance store is reset. 




Runing with 'DeleteOnTermination' attribute set to True for its root EBS volume:
	Set the DeleteOnTermination attribute to False using the command line - If the instance is already running, 
	you can set DeleteOnTermination to False using the command line.
	
It is not possible to update this attribute of a running instance from the AWS console.





Which of the following AWS resources can the AWS Firewall Manager configure rules on:	
	AWS WAF
	AWS Shield Advanced
	VPC Security Groups	
Firewall Manager makes it easy to bring new applications and resources into compliance by enforcing a common set of security rules.
		
Using AWS Firewall Manager, you can centrally configure AWS WAF rules, AWS Shield Advanced protection, 
Amazon Virtual Private Cloud (VPC) security groups, AWS Network Firewalls, and Amazon Route 53 Resolver 
DNS Firewall rules across accounts and resources in your organization. It does not support Network ACLs as of today.


These three options are not in the list of AWS resources supported by AWS Firewall Manage:
	Amazon Inspector
	Amazon GuardDuty 
	Network Access Control Lists (NACLs)



Automatically recover from the failure of an AZ:
	Create an auto-scaling group that spans across 2 AZ, which min=1, max=1, desired=1.
	So we have an ASG with desired=1, across two AZ, so that if an instance goes down, it is automatically recreated in another AZ.
	
	Create an Elastic IP and use the EC2 user-data script to attach it
	With an Elastic IP address, you can mask the failure of an instance or software by rapidly remapping the address to another instance 
	in your account.
	Instead ALB, to minimize costs, we must use an Elastic IP.
	
	Assign an EC2 Instance Role to perform the necessary API calls.
	
	
	
	

Unauthorized behavior in the future:
	Amazon GuardDuty - Amazon GuardDuty continuously monitors for malicious or unauthorized behavior to help protect your AWS resources, 
	including your AWS accounts and access keys. 
	GuardDuty identifies any unusual or unauthorized activity, like cryptocurrency mining or infrastructure 
	deployments in a region that has never been used. 
	
	
	
AWS Direct Connect connections with speeds greater than 1 Gbps:
	Opt for two separate Direct Connect connections terminating on separate devices in more than one Direct Connect location.
	
It is important to understand that AWS Managed VPN supports up to 1.25 Gbps throughput per VPN tunnel and does not support 
Equal Cost Multi-Path (ECMP) for egress data path in the case of multiple AWS Managed VPN tunnels terminating on the same VGW. 
Thus, AWS does not recommend customers use AWS Managed VPN as a backup for Direct Connect connections with speeds greater than 1 Gbps.

 
 
 
S3 storage classes supports encryption by default for both data at rest as well as in-transit?
	Amazon S3 Glacier
S3 Glacier automatically encrypts data at rest using Advanced Encryption Standard (AES) 256-bit symmetric keys and supports 
secure transfer of your data over Secure Sockets Layer (SSL).

 

	

Necessary to read the first 250 bytes of each object in S3:
	Create an application that will traverse the S3 bucket, issue a Byte Range Fetch for the first 250 bytes, 
	and store that information in RDS.
A byte-range request is a perfect way to get the beginning of a file and ensuring we remain efficient during our scan of our S3 bucket. 

	
	

RDS needs to use a caching service that supports multi-threading:	
	Amazon ElastiCache for Memcached 

Choose Memcached if the following apply to you:
	You need the simplest model possible.
	You need to run large nodes with multiple cores or threads (support for multi-threading).
	You need the ability to scale out and in, adding and removing nodes as demand on your system increases and decreases.
	You need to cache objects.

Redis does not support multi-threading.	
DAX does not support relational databases.

Amazon ElastiCache for Redis - Redis, which stands for Remote Dictionary Server, is a fast, open-source, 
in-memory key-value data store for use as a database, cache, message broker, and queue.

Amazon ElastiCache for Memcached is an open-source, distributed, 
in-memory key-value store that can retrieve data in milliseconds.





The big data analysis job needs to read the data from Amazon S3 and output it back to S3:
	Amazon EMR 
	AWS Glue 





EBS volumes. The database is heavily I/O bound:
		Use RAID 0 when I/O performance is more important than fault tolerance.
		
RAID 1 when fault tolerance is more important than I/O performance.		
		
		
		
		
		
Near-real-time data querying that is scalable with minimal data loss:		
	Capture data in Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.
						
Kinesis Data Firehose is the easiest way to capture, transform, and load streaming data into Redshift for near real-time analytics. 
It is also an auto-scaling solution as there is no need to provision any shards like Kinesis Data Streams.

			
		
		
		
RSS multi-AZ during the maintenance window:		
	Any database engine level upgrade for an RDS DB instance with Multi-AZ deployment triggers both the primary and 
	standby DB instances to be upgraded at the same time. This causes downtime until the upgrade is complete.
Upgrades to the database engine level require downtime.
	
		

AWS Managed Microsoft AD is your best choice if you need actual Active Directory features to support AWS applications or Windows workloads.
AD Connector is your best choice when you want to use your existing on-premises directory with compatible AWS services.		

Simple AD provides a subset of the features offered by AWS Managed Microsoft AD.
Simple AD does not support features: MFA, trust relationships with other domains, 
Active Directory Administrative Center, PowerShell support, Active Directory recycle bin, group managed service accounts, 
and schema extensions for POSIX and Microsoft applications.




 
Custom scripts only once during the launch of the Amazon EC2:		
		Run the custom scripts as user data scripts on the Amazon EC2 instances
		
You can update your configuration to ensure that your user data scripts and cloud-init directives run every time you 
restart your instance. By default, the scripts are run, only once during the boot process while first launching the instance.


		
		
		
As the Availability Zones got unbalanced, Amazon EC2 Auto Scaling will compensate by rebalancing the Availability Zones. 
When rebalancing, Amazon EC2 Auto Scaling launches new instances before terminating the old ones, 
so that rebalancing does not compromise the performance or availability of your application.

Amazon EC2 Auto Scaling creates a new scaling activity for terminating the unhealthy instance and then terminates it. 
Later, another scaling activity launches a new instance to replace the terminated instance.




Cost-optimal Advanced Encryption Standard (AES-256) and the company does not want to manage the encryption keys:
	SSE-S3
There are no additional fees for using server-side encryption with Amazon S3-managed keys (SSE-S3).

SSE-KMS
SSE-KMS provides an option where AWS manages the encryption key on your behalf, however, this entails a usage fee for the KMS key.



Client-Side Encryption - You can encrypt data client-side and upload the encrypted data to Amazon S3. 
In this case, you manage the encryption process, the encryption keys, and related tools.

SSE-C - You manage the encryption keys and Amazon S3 manages the encryption as it writes to 
disks and decryption when you access your objects.



Wants to use the private hosted zones feature of Route 53:
	enableDnsHostnames
	enableDnsSupport

For each VPC that you want to associate with the Route 53 hosted zone, change the following VPC settings to true:
	enableDnsHostnames
	enableDnsSupport





Users from other countries denied access to these live-streamed:

Route 53 based geolocation routing policy:
		Geolocation routing lets you choose the resources that serve your traffic based on the geographic location of your users, 
		meaning the location that DNS queries originate from.
		
CloudFront web distribution:		
		You can use georestriction, also known as geo-blocking, to prevent users in specific geographic locations from accessing 
		content that you're distributing through a CloudFront web distribution.(whitelist /blacklist)
		
		


UDP protocol and needs to support fast regional failover:
	Global Accelerator is a good fit for non-HTTP use cases, such as gaming (UDP), IoT (MQTT), or Voice over IP, as well as for 
	HTTP use cases that specifically require static IP addresses or deterministic, fast regional failover.

Route 53 is ruled out as the company wants to continue using its own custom DNS service.


ELB Regional, if user Global then AWS Global Accelerator, if user in same region use ALB or NLB.


		
		
		
It needs the games table to be accessible globally but needs the users and games_played tables to be regional only:		
	For the given use-case, need to have two Aurora clusters, one for the global table (games table) 
	and the other one for the local tables (users and games_played tables).



		
		
		
Need to process hot data and clod data:		
	FSx for Lustre provides the ability to both process the 'hot data' in a parallel and distributed fashion as well as easily 
	store the 'cold data' on Amazon S3.



NFS interface=AWS Storage Gateway - File Gateway
Lambda integrates natively with Kinesis Data Streams.

		

AWS KMS enforces a waiting period for delete kms key:
	You can set the waiting period from a minimum of 7 days up to a maximum of 30 days. The default waiting period is 30 days. 






ECS with EC2 launch type is charged based on EC2 instances and EBS volumes used. 
ECS with Fargate launch type is charged based on vCPU and memory resources that the containerized application requests.





dynamic website is hosted using on-premises servers, and its slow:
	Use Amazon CloudFront with a custom origin pointing to the on-premises servers.
You can use different origins for different types of content on a single site – e.g. 
Amazon S3 for static objects, Amazon EC2 for dynamic content, and custom origins for third-party content.




GuardDuty analyzes tens of billions of events across multiple AWS data sources, such as 
	AWS CloudTrail events, Amazon VPC Flow Logs, and DNS logs.




NLB is unable to detect HTTP errors for the application:
	Replace the Network Load Balancer (NLB) with an Application Load Balancer (ALB) and configure HTTP health checks on the 
	ALB by pointing to the URL of the application. Leverage the Auto Scaling group to replace unhealthy instances.

Network Load Balancers use active and passive health checks to determine whether a target is available to handle requests. 
With active health checks, the load balancer periodically sends a request to each registered target to check its status.

By default, each load balancer node routes requests only to the healthy targets in its Availability Zone.






S3 Standard-IA ideal for long-term storage, backups, and as a data store for disaster recovery files. 
But, it costs more than S3 One Zone-IA because of the redundant storage across availability zones. 
As the data is re-creatable, so you don't need to incur this additional cost.





Cost of test file storage on S3 Standard < Cost of test file storage on EFS < Cost of test file storage on EBS.




AWS Shield Advanced across multiple AWS accounts too much bill:
	Consolidated billing has not been enabled. All the AWS accounts should fall under a single consolidated billing for 
	the monthly fee to be charged only once.





S3 Versioning:
Once you version-enable a bucket, it can never return to an unversioned state. 
Versioning can only be suspended once it has been enabled.



hybrid cloud environment and run data-intensive analytics workloads that support DFS:
	Amazon FSx for Windows File Server:
	Amazon FSx supports the use of Microsoft’s Distributed File System (DFS) to organize shares into a single folder 
	structure up to hundreds of PB in size. 
 
FSx for Lustre does not support Microsoft’s Distributed File System (DFS).
AWS Managed Microsoft AD does not support Microsoft’s Distributed File System (DFS).
 
 



ElastiCache - Amazon ElastiCache for Memcached is an ideal front-end for data stores like Amazon RDS or Amazon DynamoDB, 
providing a high-performance middle tier for applications with extremely high request rates and/or low latency requirements.





Wants to delegate access to a set of users from another AWS account:
	Create a new IAM role with the required permissions to access the resources in the production environment. 
	The users can then assume this IAM role while accessing the resources from the production environment.
	



Can be used as a boot volume:
	General Purpose SSD (gp2)
	Provisioned IOPS SSD (io1)
	Instance Store
	
	
	
	

Permissions to list an S3 bucket and delete objects from that bucket:
{
    "Action": [
        "s3:DeleteObject"
    ],
    "Resource": [
        "arn:aws:s3:::example-bucket/*"
    ],
    "Effect": "Allow"
}






does not want to provide its own encryption keys but still wants to maintain an audit trail and key use by whom:
	Use SSE-KMS to encrypt the user data on S3.
	



API Gateway creates RESTful APIs that enable stateless client-server communication and API Gateway also creates WebSocket APIs 
that adhere to the WebSocket protocol, which enables stateful, full-duplex communication between client and server.




Resilient architecture can adjust for the loss of any instance, therefore you should use Instance Store based EC2



block access from two countries and allow access only from the home country:
	Configure AWS WAF on the Application Load Balancer in a VPC.
	
 
 
RDS:
	Multi-AZ follows synchronous replication and spans at least two Availability Zones within a single region. 
	Read replicas follow asynchronous replication and can be within an Availability Zone, Cross-AZ, or Cross-Region.
	
	
	



Amazon API Gateway, Amazon SQS and Amazon Kinesis:
	API Gateway sets a limit on a steady-state rate and a burst of request.
	Amazon SQS offers buffer capabilities to smooth out temporary volume spikes without losing messages or increasing latency.
	Amazon Kinesis is a fully managed, scalable service that can ingest, buffer, and process streaming data in real-time.
	
	
	
	


Spreadsheet is saved on an EFS file system created in us-east-1 region:
	The spreadsheet on the EFS file system can be accessed in other AWS regions by using an inter-region VPC peering connection.
 
You can connect to Amazon EFS file systems from EC2 instances in other AWS regions using an inter-region VPC peering connection, 
and from on-premises servers using an AWS VPN connection. 








Regular request 100 spike touches about 5000 requests per second:
	Amazon SNS message deliveries to AWS Lambda have crossed the account concurrency quota for Lambda, so the team needs to contact 
	AWS support to raise the account limit.
	
AWS Lambda currently supports 1000 concurrent executions per AWS account per region.
For more You need to contact AWS support to raise the account limit.


	
	

In Order 1000 messages per second to be processed via SQS:
	Use Amazon SQS FIFO queue in batch mode of 4 messages per operation to process the messages at the peak rate.
	
By default, FIFO queues support up to 300 messages per second (300 send, receive, or delete operations per second).
4 messages per operation so that the FIFO queue can support up to 1200, max 10 for FIFO.


	
		
Enable storage auto-scaling for RDS MySQL
	If your workload is unpredictable, you can enable storage autoscaling for an Amazon RDS DB instance.




Lambda function in AWS account A that accesses an Amazon S3 bucket in AWS account B:
	Create an IAM role for the Lambda function that grants access to the S3 bucket. 
	Set the IAM role as the Lambda function's execution role. 
	Make sure that the bucket policy also grants access to the Lambda function's execution role.
	
bucket are in different accounts, then you need to grant Amazon S3 permissions on both the IAM role and the bucket policy.



	
	

replacement for the DFSR:
	FSx for Windows
	
	



"Statement":[
	{
		"Effect":"Deny",
		"Action":"ec2:*",
		"Resource":"*",
		"Condition":{
			"StringNotEquals":{
				"ec2:Region":"us-west-1"
			}
		}
	},
	{
		"Effect":"Allow",
		"Action":"ec2:TerminateInstances",
		"Resource":"*",
		"Condition":{
			"IpAddress":{
				"aws:SourceIp":"10.200.200.0/24"
			}
		}
	}
]
Users belonging to the IAM group can terminate an EC2 instance in the us-west-1 region when the user's source IP is 10.200.200.200






Encryption key usage must be logged for auditing purposes
Encryption Keys must be rotated every year
The data must be encrypted at rest:
	Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with automatic key rotation.
	
	



EC2 instances need to access  S3 and DynamoDB:
	Attach the appropriate IAM role to the EC2 instance profile so that the instance can access S3 and DynamoDB
	
	
	

Static website  scalable serverless solution:
	Build the website as a static website hosted on Amazon S3. Create a CloudFront distribution with Amazon S3 as the origin. 
	Use Amazon Route 53 to create an alias record that points to your CloudFront distribution.
	
You can't host a website on Lambda. Also, you can't have CloudFront in front of Lambda. 	
	
	 
	





failover environment on AWS in case the on-premises data center fails:
	Set up a Route 53 failover record. 
	Run application servers on EC2 instances behind an Application Load Balancer in an Auto Scaling group. 
	Set up AWS Storage Gateway with stored volumes to back up data to S3.
	
	
Storage Gateway also integrates natively with Amazon S3 cloud storage which makes your data available for in-cloud processing.




	
	
Leverage Amazon Aurora MySQL with Multi-AZ Aurora Replicas and create the dev database by restoring from the 
automated backups of Amazon Aurora.
No performance impact or interruption of database service occurs as backup data is being written.





improve the performance of its big data processing workflows running on Amazon EFS:
	Max I/O
Max I/O performance mode is used to scale to higher levels of aggregate throughput and operations per second. 
Highly parallelized applications and workloads, big data analysis, media processing, and genomic analysis
 
 
Provisioned Throughput
Bursting Throughput
This two throughput mode of EFS and not the performance mode.





Multiple AWS accounts VPCs have been provisioned across these AWS accounts(hub-and-spoke styl):
	Build a shared services VPC
	
Sharing resources from a central location instead of building them in each VPC may reduce administrative overhead and cost.	
	
	


Hadoop cluster deployed in the on-premises data center highly available with about 50 EC2 instances per Availability Zone:
	Partition placement group
This strategy is typically used by large distributed and replicated workloads, such as Hadoop, Cassandra, and Kafka. 

Cluster placement group
low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of HPC applications. 
This is not suited for distributed and replicated workloads such as Hadoop.

Spread placement group
Spread – strictly places a small group of instances across distinct underlying hardware to reduce correlated failures. 
This is not suited for distributed and replicated workloads such as Hadoop.





User loging see different file on there upload file:
Write a one time job to copy the videos from all EBS volumes to S3 and then modify the application to use Amazon S3 standard for storing the videos
Mount EFS on all EC2 instances. Write a one time job to copy the videos from all EBS volumes to EFS. Modify the application to use EFS for storing the videos





it needs 80 instances 80% of the time and spike need 300 ec2:
Purchase 80 reserved instances. Provision additional on-demand and spot instances per the workload demand (Use Auto Scaling Group with launch template to provision the mix of on-demand and spot instances)



user level as well as account-level access permissions for the data stored in S3 buckets:
	Use Amazon S3 Bucket Policies
	
Bucket policies in Amazon S3 can be used to add or deny permissions across some or all of the objects within a single bucket. 
Policies can be attached to users, groups, or Amazon S3 buckets, enabling centralized management of permissions. 
With bucket policies, you can grant users within your AWS Account or other AWS Accounts access to your Amazon S3 resources.


	
	
minimize the application boostrap time whenever the system needs to be stopped and then started:
	Use EC2 Instance Hibernate
	
Creating an AMI may help with all the system dependencies, but it won't help us with speeding up the application start time.




Prevent granting themselves the AdministratorAccess:	
	For each developer, define an IAM permission boundary that will restrict the managed policies they can attach to themselves.
If you consider this option, since AWS Organizations is not mentioned in this question, so we can't apply an SCP.




	
	
S3 Data encrypted and decrypted using the same key in both AWS regions:
	Create a new S3 bucket in the us-east-1 region with replication enabled from this new bucket into another bucket in us-west-1 region. 
	Enable SSE-KMS encryption on the new bucket in us-east-1 region by using an AWS KMS multi-region key. 
	Copy the existing data from the current S3 bucket in us-east-1 region into this new S3 bucket in us-east-1 region.
	
	
	
	

You can use CloudWatch Alarms to send an email via SNS whenever any of the EC2 instances breaches a certain threshold.




RDS read replicas data transfer charge:
	There are no data transfer charges for replicating data within the same Availability Zone
	There are no data transfer charges for replicating data within the same AWS Region
	There are a data transfer charges for replicating data across AWS Regions






less frequently accessed files on AWS that can be concurrently accessed by hundreds of EC2 instances:
	Amazon Elastic File System (EFS) Standard–IA storage class 
The EFS Standard storage class is used for frequently accessed files.
	
	
	
	

decouple the user authentication process for the application:
	Use Cognito Authentication via Cognito User Pools for your Application Load Balancer.
Amazon Cognito identity pools provide temporary AWS credentials for users who are guests (unauthenticated) and for users 
who have been authenticated and received a token.
	
You cannot directly integrate Cognito User Pools with CloudFront distribution as you have to create a separate Lambda@Edge 
function to accomplish the authentication via Cognito User Pools. This involves additional development effort, 
so this option is not the best fit for the given use-case.






2 Hour The solution for the workload should be able to withstand server failures:
	Run the workload on a Spot Fleet
	
Only spot fleets can maintain target capacity by launching replacement instances after Spot Instances in the fleet are terminated, 
so spot instances, by themselves, are not the right fit for this use-case.



	
	
App slow down for loading on another region(eu-west-1):
	Setup another fleet of EC2 instances for the web tier in the eu-west-1 region. Enable latency routing policy in Route 53. 
	Create Amazon Aurora read replicas in the eu-west-1 region 
	
	



The auditor has its own AWS account and needs its own copy of the RDS:
	Create an encrypted snapshot of the database, share the snapshot, and allow access to the AWS Key Management Service (AWS KMS) encryption key
	
You can share AWS KMS CMKs with another AWS account by adding the other account to the AWS KMS key policy.



Configure an AWS DataSync agent on the on-premises server that has access to the NFS file system. Transfer data over the Direct Connect connection to an AWS PrivateLink interface VPC endpoint for Amazon EFS by using a private VIF. Set up a DataSync scheduled task to send the video files to the EFS file system every 24 hours







DNS queries for the private hosted zone remain unresolved:
	Enable DNS hostnames and DNS resolution for private hosted zones.
	
DNS hostnames: For non-default virtual private clouds that aren't created using the Amazon VPC wizard, this option is disabled by default. 	
DNS resolution: Private hosted zones accept DNS queries only from a VPC DNS server.	







Linux iles will be stored and accessed frequently at first, and then infrequently:
	EFS IA
EFS IA for the file that not accessed every day, with storage prices up to 92% lower compared to Amazon EFS Standard.






Aurora multi-master DB cluster:
	For applications where you can't afford even brief downtime for database write operations, a multi-master cluster can help to 
	avoid an outage when a writer instance becomes unavailable.

	
	
	


EBS change this default behavior to ensure that the volume persists even after the instance terminates:
Set the DeleteOnTermination attribute to false







Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) - 
	When you use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3), each object is encrypted with a unique key. 
	As an additional safeguard, it encrypts the key itself with a master key that it regularly rotates.

	
Server-Side Encryption with Customer-Provided Keys (SSE-C)-	
	For the given use-case, the company wants to manage the encryption keys via its custom application and let S3 manage the encryption, 
	therefore you must use Server-Side Encryption with Customer-Provided Keys (SSE-C)

Server-Side Encryption with Customer Master Keys (CMKs) Stored in AWS Key Management Service (SSE-KMS) -
	Server-Side Encryption with Customer Master Keys (CMKs) stored in AWS Key Management Service (SSE-KMS) is similar to SSE-S3. 
	SSE-KMS provides you with an audit trail that shows when your CMK was used and by whom. 
	Additionally, you can create and manage customer-managed CMKs or use AWS managed CMKs that are unique to you, your service, 
	and your Region.


Client-Side Encryption with data encryption is done on the client-side before sending it to Amazon S3 - 
	You can encrypt the data client-side and upload the encrypted data to Amazon S3. In this case, you manage the encryption process, 
	the encryption keys, and related tools.



 

CORRECT for AMIs:
	You can copy an AMI across AWS Regions.
	You can share an AMI with another AWS account.
	Copying an AMI backed by an encrypted snapshot cannot result in an unencrypted target snapshot.(encrypted-to-unencrypted = NO)




For AWS Managed IPSec VPN Connection between:
	Create a Virtual Private Gateway on the AWS side of the VPN and a Customer Gateway on the on-premises side of the VPN.
	
	
	
AWS DataSync fully automates and accelerates moving large active datasets to AWS, up to 10 times faster than command-line tools. 
It is natively integrated with Amazon S3, Amazon EFS, Amazon FSx for Windows File Server, Amazon CloudWatch, and AWS CloudTrail.
	
The AWS Transfer Family provides fully managed support for file transfers directly into and out of Amazon S3 and Amazon EFS. 
Therefore, it cannot support migration into the other AWS storage services mentioned in the given use-case 
(Amazon FSx for Windows File Server).



RDS  read replicas should lag no more than 1 second behind the primary instance to provide the best possible user experience:
	Set up database migration from RDS MySQL to Aurora MySQL. Swap out the MySQL read replicas with Aurora Replicas. 
	Configure Aurora Auto Scaling.

Auror The replica lag times are in the 10s of milliseconds.





For multiple High Performance Computing (HPC) workflows:
	Elastic Fabric Adapter (EFA)
An Elastic Fabric Adapter (EFA) is a network device that you can attach to your Amazon EC2 instance to accelerate 
High Performance Computing (HPC) and machine learning applications.

Elastic Network Interface - An Elastic Network Interface (ENI) is a logical networking component in a 
VPC that represents a virtual network card,insufficient for HPC workflows.

Elastic Network Adapter - Elastic Network Adapter (ENA) devices support enhanced networking via single root I/O virtualization 
(SR-IOV) to provide high-performance networking capabilities.
Still EFA is a better fit for the given use-case because the EFA device provides all the functionality of an ENA device, plus OS bypass.

Enable enhanced networking with the Elastic Network Adapter (ENA) on Windows.







Network Load Balancer (NLB) to handle millions of requests per second, instances in a public subnet and IDs as the targets for the NLB:
	Traffic is routed to instances using the primary private IP address specified in the primary network interface for the instance.
So elastic IP address or public IP address cannot be used to route the traffic to the instance.






VPC peering facilitates a connection between two VPCs within the AWS network, therefore this option cannot be used to 
send and receive data between the remote branch offices of the company.
Use VPN CloudHub for connect multiple remote office branch.






Three AZ with public and provate subnet:
	Set up three NAT gateways, one in each public subnet in each AZ. Create a custom route table for each AZ that 
	forwards non-local traffic to the NAT gateway in its AZ.
	
	


Real-time processing with manage service:
Use Amazon Kinesis Data Streams to ingest the data, process it using AWS Lambda or run analytics using Kinesis Data Analytics.





ElastiCache:
	Use ElastiCache to improve latency and throughput for read-heavy application workloads.
	Use ElastiCache to improve the performance of compute-intensive workloads.

Amazon ElastiCache can be used to significantly improve latency and throughput for many read-heavy application workloads 
(such as social networking, gaming, media sharing, leaderboard, and Q&A portals) or 
compute-intensive workloads (such as a recommendation engine) by allowing you to store the objects that are often read in the cache.





The database rollover will archive:
	Schedule a weekly EventBridge event cron expression to invoke a Lambda function that runs the database rollover job.
	
	
	


NAT instance supports port forwarding.
NAT instance can be used as a bastion server.
Security Groups can be associated with a NAT instance.




SQS FIFO queue:
	Delete the existing standard queue and recreate it as a FIFO queue
	Make sure that the name of the FIFO queue ends with the .fifo suffix
	Make sure that the throughput for the target FIFO queue does not exceed 3,000 messages per second




DynamoDB table. As soon as the issue is detected, the team needs to remove the corrupted:
	Use DynamoDB point in time recovery to restore the table to the state just before corrupted data was written.
	
	
	


complex with too many ALBs in multiple AWS Regions firewall need to reduce IP:
	Launch AWS Global Accelerator and create endpoints for all the Regions. 
	Register the ALBs of each Region to the corresponding endpoints.
	
	
	
	
EBS:
	Provisioned IOPS SSD (io1)
	50 IOPS/GB to a maximum of 64,000 IOPS and provide up to 1,000 MB/s of throughput per volume.

	General Purpose SSD (gp2) -
	 It supports max IOPS/Volume of 16,000.

	Cold HDD (sc1) IOPS/Volume of 250.

	Throughput Optimized HDD (st1) It supports max IOPS/Volume of 500.




Therefore, you cannot use an Internet Gateway ID as the custom source for the inbound rule.






Amazon FSx for Windows File Server - Amazon FSx for Windows File Server is a fully managed, highly reliable file storage 
that is accessible over the industry-standard Server Message Block (SMB) protocol.

File Gateway Configuration of AWS Storage Gateway - Depending on the use case, Storage Gateway provides 3 types of storage 
interfaces for on-premises applications: File, Volume, and Tape. 
The File Gateway enables you to store and retrieve objects in Amazon S3 using file protocols such as Network 
File System (NFS) and Server Message Block (SMB).




wants a solution that can handle complex database configurations such as secondary indexes, foreign keys, and stored procedures:
	AWS Schema Conversion Tool
	AWS Database Migration Service





Use Amazon GuardDuty to monitor any malicious activity on data stored in S3. 
Use Amazon Macie to identify any sensitive data stored on S3.







Use AZ ID to uniquely identify the Availability Zones across the two AWS Accounts:
if you share a subnet in the Availability Zone with the AZ ID usw2-az2 with another account, this subnet is available to 
that account in the Availability Zone whose AZ ID is also usw2-az2.




application will be accessed by users from different geographic regions of the world,  latency for a great user experience:
Use Amazon S3 for hosting the web application and use S3 Transfer Acceleration to reduce the latency that geographically 
dispersed users might face.








Single AWS Acc multiple VPC need to connect:
	VPc Peering.
You can create a VPC peering connection between your own VPCs, or with a VPC in another AWS account. 
The VPCs can be in different regions (also known as an inter-region VPC peering connection). VPC Peering helps connect two VPC.






Kinesis will be great for event streaming from the IoT devices, for sending notifications SNS.




CloudFront:
	CloudFront can route to multiple origins based on the content type
	Use an origin group with primary and secondary origins to configure CloudFront for high availability and failover.
	Use field level encryption in CloudFront to protect sensitive data for specific content.
	
	
	
	
	
	
	
You can host multiple TLS secured applications, each with its own TLS certificate, behind a single load balancer. 
Use SSL certificates with SNI	
	
	
	

maximum possible availability for the database layer while minimizing operational and management overhead:	
Migrate the data to Amazon RDS for SQL Server database in a Multi-AZ deployment
Amazon RDS supports Multi-AZ deployments for Microsoft SQL Server by using either SQL Server Database Mirroring (DBM) or Always On Availability Groups (AGs). 
	
	
	
	
	
	
For dister recovery currently takes over 45 minutes to install on a Linux system:
		Create an AMI after installing the software and copy the AMI across all Regions. 
		Use this Region-specific AMI to run the recovery process in the respective Regions.
		
		
AWS does not copy launch permissions, user-defined tags, or Amazon S3 bucket permissions from the source AMI to the new AMI. 
After the copy operation is complete, you can apply launch permissions, user-defined tags, and Amazon S3 bucket
 permissions to the new AMI.




Check S3 buckets settings being changed regularly:
	Use CloudTrail to analyze API calls
	
	
	
	
Improve the VPN throughpu:
	Create a transit gateway with equal cost multipath routing and add additional VPN tunnels.
 
 
 
		
RDS specific best practices are incorporated into a reusable infrastructure template to be used by all your AWS users:
	Use CloudFormation to manage RDS databases.
	
 AWS CloudFormation allows you to use programming languages or a simple text file to model and provision, 
 in an automated and secure manner, all the resources needed for your applications across all regions and accounts. 



 
	
highly available cost-effect:
	Set the minimum capacity to 2
	Use Reserved Instances for the minimum capacity
	
	
	
	
Leverage Amazon Kinesis Data Streams to capture the data from the website and feed it into Amazon Kinesis Data Analytics which can query the data in real time. Lastly, the analyzed feed is output into Kinesis Data Firehose to persist the data on Amazon S3




EC2 instance and the EBS volume are under-utilized:	
		Convert the Amazon EC2 instance EBS volume to gp2 .

Therefore, gp2 is the right choice as it is more cost-effective than io1, and it also allows a burst in performance when needed.




Amazon EventBridge is recommended when you want to build an application that reacts to events from SaaS applications and/or AWS services. 
Amazon EventBridge is the only event-based service that integrates directly with third-party SaaS partners.
SNS also even driven but does not support third-party (SaaS) services integration.



	
The IAM service supports only one type of resource-based policy called a role Trust policy, which is attached to an IAM role.





dynamically alter the size of a geographic area from which traffic is routed to a specific server resource:	
	Geoproximity routing - Geoproximity routing lets Amazon Route 53 route traffic to your resources based on the geographic location of your users and your resources. You can also optionally choose to route more traffic or less to a given resource by specifying a value, known as a bias.
	
	
	
	
	
	
EC2 take huse time to run, make it lessthen 2 miute:
		Create a Golden AMI with the static installation components already setup
	    Use EC2 user data to customize the dynamic installation parts at boot time
	
	
	
	
Opt for Multi-AZ configuration with automatic failover functionality to help mitigate failure - Multi-AZ is the best option when data retention, minimal downtime, and application performance are a priority.

Data-loss potential - Low. Multi-AZ provides fault tolerance for every scenario, including hardware-related issues.




VPCs and on-premises networks through a central hub:	
	Use AWS Transit Gateway to connect the Amazon VPCs to the on-premises networks .
	
	
	

(ELB) in a Region malfunctioned:
	Set up AWS Global Accelerator and add endpoints to cater to users in different geographic locations.
	
	
	

HIPAA compliant in-memory database that supports SQL query:
	ElastiCache for Redis/Memcached
Both ElastiCache for Redis and ElastiCache for Memcached are HIPAA Eligible.	
	
	
	
	
No IAM user with AdministratorAccess:
	Some of the AWS tasks that only a root account user can do are as follows: change account name or 
	root password or root email address, change AWS support plan, close AWS account, enable MFA on S3 bucket delete, 
	create Cloudfront key pair, register for GovCloud. 


	
RDS primary instance of the Multi-AZ configuration goes down:	
		When failing over, Amazon RDS simply flips the canonical name record (CNAME) for your DB instance to point at the standby, 
		which is in turn promoted to become the new primary. 
	
Amazon RDS uses several different technologies to provide failover support. 
Multi-AZ deployments for MariaDB, MySQL, Oracle, and PostgreSQL DB instances use Amazon's failover technology. 
SQL Server DB instances use SQL Server Database Mirroring (DBM) or Always On Availability Groups (AGs).


	
	
Then, the instance has to be manually restarted, for auto:
		Setup a CloudWatch alarm to monitor the health status of the instance. In case of an Instance Health Check failure, 
		an EC2 Reboot CloudWatch Alarm Action can be used to reboot the instance.
		
Using Amazon CloudWatch alarm actions, you can create alarms that automatically stop, terminate, reboot, or recover your EC2 instances. 		
		
		
		
historical data (any data older than a year) into S3, as the daily analytical reports:	
		Use Redshift Spectrum to create Redshift cluster tables pointing to the underlying historical data in S3. 
		The analytics team can then query this historical data to cross-reference with the daily reports from Redshift.
		
		
		
Ultiple test databases that must be re-created from production Aurora data.		
		Use database cloning to create multiple clones of the production DB and use each clone as a test DB.
		
		
		
high IOPS. The team wants to install the database on an EC2 instance with the optimal storage type:		
Amazon EC2 with EBS volume of Provisioned IOPS SSD (io1) type



S3 low transfrer speed offices in remote location:
			Use Amazon CloudFront distribution with origin as the S3 bucket. 
			This would speed up uploads as well as downloads for the video files.
			Enable Amazon S3 Transfer Acceleration for the S3 bucket. This would speed up uploads as well as downloads for the video files.
			
			
A process replaces an existing object and immediately tries to read it. Amazon S3 always returns the latest version of the object.


directed to a static error page, configured as a backup, in case of unavailability of the primary website:
Set up a Route 53 active-passive type of failover routing policy. If Route 53 health check determines the ALB endpoint as unhealthy, the traffic will be diverted to a static error page, hosted on Amazon S3 bucket

Metadata, which can be included with the object, is not encrypted while being stored on Amazon S3. Therefore, AWS recommends that customers not place sensitive information in Amazon S3 metadata.



wants to continue using their existing encryption key generation mechanism:
	SSE-C - With Server-Side Encryption with Customer-Provided Keys (SSE-C), you manage the encryption keys and Amazon 
	S3 manages the encryption.
	
Only Standard SQS queue is allowed as an Amazon S3 event notification destination, whereas FIFO SQS queue is not allowed.	
	
	


implement a distributed in-memory cache-based session management solution:
	Amazon ElastiCache can be used as a distributed in-memory cache for session management. 
	
	
	
high-performance IOPS when doing file processing in a temporary storag:
	Use EC2 instances with Instance Store as the storage type
	
	
	
best practices on cost optimization, performance, and security for their system:	
	AWS Trusted Advisor
	
	
VPCs in a hub and spoke model:	
		Use a transit gateway to interconnect the VPCs.
		
		
DynamoDB encryption details are nowhere in CloudTrails:
	By default, all DynamoDB tables are encrypted under an AWS owned customer master key (CMK), 
	which do not write to CloudTrail logs.All DynamoDB tables are encrypted. There is no option to enable or disable encryption for new or existing tables.
	
	
	
flexible nightly process which runs for 1 hour using Python:
	Run on a Spot Instance with Spot Block

Spot Instances with a defined duration (also known as Spot blocks) are designed not to be interrupted and will run continuously 
for the duration you select. This makes them ideal for jobs that take a finite time to complete, 
such as batch processing, encoding and rendering, modeling and analysis, and continuous integration.



ELB cannot distribute incoming traffic for targets deployed in different regions. 


 
Create an S3 Event Notification that sends a message to an SQS queue. Make the EC2 instances read from the SQS queue.

 
		
EFs access control such that only the permitted EC2:	
	Use VPC security groups to control the network traffic to and from your file system
	Use an IAM policy to control access for clients who can mount your file system with the required permissions
You control which EC2 instances can access your EFS file system by using VPC security group rules and AWS Identity and 
Access Management (IAM) policies. Use VPC security groups to control the network traffic to and from your file system. 



Set up an on-premises file gateway. Configure data sources to write the .json files to the file gateway. 
Point the legacy analytics application to the file gateway. The file gateway should replicate the .json files to Amazon S3.

When you stop, hibernate, or terminate an instance, every block of storage in the instance store is reset.



automatically recover from the failure of an AZ:
	Create an auto-scaling group that spans across 2 AZ, which min=1, max=1, desired=1
	Assign an EC2 Instance Role to perform the necessary API calls
	Create an Elastic IP and use the EC2 user-data script to attach it	
	
So we have an ASG with desired=1, across two AZ, so that if an instance goes down, it is automatically recreated in another AZ.



Dynamic port mapping with an Application Load Balancer makes it easier to run multiple tasks on the same 
Amazon ECS service on an Amazon ECS cluster.


encrypted using the company's proprietary algorithm:
	Client Side Encryption



Provisioned IOPS SSD EBS volumes - Amazon EBS Multi-Attach enables you to attach a single Provisioned IOPS SSD (io1 or io2) 
volume to multiple instances that are in the same Availability Zone. 

General-purpose SSD-based EBS volumes not supported for Multi-Attach functionality.




ElastiCache for Redis supports replication and archival snapshots right out of the box. 
ElastiCache for Memcached does not support replication and archival snapshots, so this option is ruled out.	
	
	
	
Not able to modify AWS CloudTrail configuration:	
		Set up a service control policy (SCP) that prohibits changes to CloudTrail, and attach it to the developer accounts.
		
		
IOPS on the EBS volume is maxing out. The disk size of the database must not change because of a licensing issue:		
		Convert the gp2 volume to an io1
The only solution is to convert the volume into an io1 volume. 
This will allow us to keep the same disk size while independently increasing the IOPS for that volume.
		
		
		
	
	
Using SQS as a middleware will help us sustain the write throughput scale infinitely.	
Kinesis Data Streams cannot scale infinitely and we may have the same throughput issues. 	
	
	
	
	
S3 bucket through CloudFront and not directly:	
	Create an origin access identity (OAI) and update the S3 Bucket Policy
	
	
High levels of inter-node communications and HPC:
	Deploy EC2 instances with Elastic Fabric Adapter
	Deploy EC2 instances in a cluster placement group
	
	
When you modify the database engine for your DB instance in a Multi-AZ deployment, then Amazon RDS upgrades both the primary and secondary DB instances at the same time. In this case, the database engine for the entire Multi-AZ deployment is shut down during the upgrade.


Create a separate gateway endpoint for S3 and DynamoDB each. Add two new target entries for these two gateway endpoints in the route table of the custom VPC



Create two SQS standard queues: one for pro and one for lite. 
Set up EC2 instances to prioritize polling for the pro queue over the lite queue.



Aurora Serverless is the perfect way to create a database that can scale down to 0 servers, 
and scale up to many servers, as an OLTP database.





	
archive the on-premises data into a POSIX and accessed for just about a week in a year.:
	EFS Infrequent Access
S3 not POSIX compliant file storage solution. 	
	


required application response times while accounting for any traffic spikes:
	Leverage horizontal scaling for the web and application tiers by using Auto Scaling groups and Application Load Balancer.
	
	
	

EC2 instance needs to access a DynamoDB table in the same AWS account:
	Set up an IAM service role with the appropriate permissions to allow access to the DynamoDB table. Configure an instance profile to assign this IAM role to the EC2 instance
	
	
	
high-frequency reading and writing:
	Use Amazon EFS with Provisioned Throughput mode
	
	
	

A Big Data company wants to optimize its daily Extract-Transform-Load (ETL) process serverless:
	AWS Glue - AWS Glue provides a managed ETL service that runs on a serverless Apache Spark environment.
	
	
	
	

























=================================================
#Code | Helping Heand | Example
=================================================


#Node Lambda API
-------------------------------------------------
exports.handler =  async function(event, context) {
    return {
        statusCode: 200,
        body: JSON.stringify("Simple NodeJs API Response !"),
      };
}


#PythonLabda
-------------------------------------------------
import json

def lambda_handler(event, context):
    body = "Hello from Lambda!"
    statusCode = 200
    return {
        "statusCode": statusCode,
        "body": json.dumps(body),
        "headers": {
            "Content-Type": "application/json"
        }
    }
	
	

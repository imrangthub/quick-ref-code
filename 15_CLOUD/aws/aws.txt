#################################################
#                 AWS                          #
#################################################
https://twitter.com/i/status/1576389331484545024
=>sudo chmod 777 -R destinationFolder/*
Allow ec2 file permission

=>/mnt/efs/fs1
MetadataURL is http://169.254.169.254/latest/meta-data
  
	  
#!/bin/bash
yum update -y
yum install -y httpd
systemctl start httpd
systemctl enable httpd
echo "<h1>Hello World from $(hostname -f)</h1>" > /var/www/html/index.html


=================================================
#General | Basic | Info      
================================================= 


ConfusingTakeaLook
------------------


HandOnRemain
----------------------------
Amazon CloudFront Hands On
CloudFormation

Video Checkout:
2)Giving permissions to federated/outside users & groups.
You can't assign role to user.

AWS Best Practices for DDoS Resiliency Application Layer Defense

Ephemeral Ports

Before->Amazon GuardDuty

S3 Bucket Policies
S3 CORS
S3 Select

DynamoDB provisoning model

Amazon Aurora Serverless




Amongst the new topics you'll learn about in this update:
================================================
-RDS Custom for Oracle and Microsoft SQL Server, RDS & Aurora Backup and Monitoring, RDS Proxy
-S3 Object Lambda, S3 Batch Operations
-Amazon EKS, AWS App Runner, DocumentDB, Neptune, Keyspaces (for Apache Cassandra), QLDB, Timestream, 
 QuickSight, Glue, Lake Formation, MSK - Managed Streaming for Apache Kafka...
-CloudWatch Metric Streams, CloudWatch Insights
-Many AWS Machine Learning services



SSM
================================================
=>aws ssm get-parameters-by-path --path /myapp/prod/ --recursive
=>aws ssm get-parameters-by-path --path /myapp/prod/ 
=>aws ssm get-parameters --name /myapp/prod/db-url /myapp/prod/db-pass
=>aws ssm get-parameters --name /myapp/prod/db-url /myapp/prod/db-pass --with-decryption


=================================================
#AWS Top View | Flow | Overview
=================================================


#AWS Global Infrastructure
-------------------------------------------------
AWS: 
  -Region
  	-AvailableZone
		-VPC 
			-Router 
			-RouteTables
			-Gateway
			-InternetGateway
			-VPCEndpoint(InterfaceEndpoints and GatewayEndpoints)
			-VPG(VPN Gateway VirtualPrivateGateway)+Site-to-Site VPN+VPNCloudHub(set it up, connect multiple VPN connections on the same VGW)
			-DCG(DirectConnectGateway for DX)
				-Subnet
					-NACL
					-NATInstance
					-NATGateway
					-EC2
						-SecurityGroup
					
				
#Security
-------------------------------------------------
SCP->ResourceBase->IdentityBase->IAMPermissionBoundry->SessionPolicy->Go!

Root User:
		-IAM User      +Permission Policy
		-User Group    +Permission Policy
		-IAM Role      +Permission Policy ->For EC2 to doing somthing
		
SCP:
	-OU			   +Permission Policy
		-User
		-Role
	  
	
	
Policy:		=>Predefined+Custome+(Optional)Condition
IAMRole:	=>Predefined+Custome

Principals: Root Users, IAM Users and Instance Principals.
PrincipleEntities: Users, Groups, Roles and Policies.



#Interfaces | EndPoints
-------------------------------------------------
AWS: 
  -Region
  	-AvailableZone
		-VPC +IGW+GWLB
			-Subnet +GWLBEndPoint
				-EC2++SecurityGroups
					++ENI++SecurityGroups
				
				

=================================================
#AWS Services Scope | Area
================================================= 
IAM
	Users, Groups, Roles, Accounts – Global
		Same AWS accounts, users, groups and roles can be used in all regions
	Key Pairs – Global and Regional
		Amazon EC2 created key pairs are specific to the region
		RSA key pair can be created and uploaded that can be used in all regions
Virtual Private Cloud
	VPC – Regional
		VPC are created within a region
	Subnet – Availability Zone
		Subnet can span only a single Availability Zone
	Security groups – Regional
		A security group is tied to a region and can be assigned only to instances in the same region.
	VPC Endpoints – Regional
		You cannot create an endpoint between a VPC and an AWS service in a different region.
	VPC Peering – Regional
		Create a VPC peering connection between your own VPCs, with a VPC in another AWS account, or with a VPC in a different Region.
		VPC Peering can now span multi-region
	Elastic IP Address – Regional
		Elastic IP address created within the region can be assigned to instances within the region only
EC2
	Resource Identifiers – Regional
		Each resource identifier, such as an AMI ID, instance ID, EBS volume ID, or EBS snapshot ID, is tied to its region and 
		can be used only in the region where you created the resource.
	Instances – Availability Zone
		An instance is tied to the Availability Zones in which you launched it. However, note that its instance ID is tied to the region.
	EBS Volumes – Availability Zone
		Amazon EBS volume is tied to its Availability Zone and can be attached only to instances in the same Availability Zone.
	EBS Snapshot – Regional
		An EBS snapshot is tied to its region and can only be used to create volumes in the same region and has to be copied from 
		One region to other if needed.
AMIs – Regional
	AMI provides templates to launch EC2 instances
	AMI is tied to the Region where its files are located with Amazon S3. For using AMI in different regions, the AMI can be copied 
	to other regions.
Auto Scaling – Regional
	Auto Scaling spans across multiple Availability Zones within the same region but cannot span across regions
Elastic Load Balancer – Regional
	Elastic Load Balancer distributes traffic across instances in multiple Availability Zones in the same region
Cluster Placement Groups – Availability Zone
	Cluster Placement groups can be span across Instances within the same Availability Zones
S3 – Global but Data is Regional
	S3 buckets are created within the selected region
	Objects stored are replicated across Availability Zones to provide high durability but are not cross region replicated unless 
	done explicitly.
Route53 – Global
	Route53 services are offered at AWS edge locations and are global
DynamoDB – Regional
	All data objects are stored within the same region and replicated across multiple Availability Zones in the same region
	Data objects can be explicitly replicated across regions using cross-region replication
WAF – Global
	Web Application Firewall (WAF) services protects web applications from common web exploits are offered at AWS edge locations 
	and are global
CloudFront – Global
	CloudFront is the global content delivery network (CDN) services are offered at AWS edge locations
Storage Gateway – Regional
	AWS Storage Gateway stores volume, snapshot, and tape data in the AWS region in which the gateway is activated
AWS Config – Regional
AWS GuardDuty – Regional





=================================================
#AWS Security, Identity, & Compliance services
================================================= 
Category:UseCases:AWSService

Identity & access management:
	Securely manage access to services and resources
	AWS Identity & Access Management (IAM)
	
	Cloud single-sign-on (SSO) service
	AWS IAM Identity Center (successor to AWS SSO)
	
	Identity management for your apps
	Amazon Cognito
	
	Managed Microsoft Active Directory
	AWS Directory Service
	
	Simple, secure service to share AWS resources
	AWS Resource Access Manager
	
	Central governance and management across AWS accounts
	AWS Organizations
	
Detection:
	Automate AWS security checks and centralize security alerts
	AWS Security Hub
	
	Protect AWS accounts with intelligent threat detection
	Amazon GuardDuty
	
	Automate vulnerability management
	Amazon Inspector
	
	Record and evaluate configurations of your AWS resources
	AWS Config
	
	Track user activity and API usage
	AWS CloudTrail
	
	Security management for IoT devices
	AWS IoT Device Defender
	
Network and application protection:
	Network security
	AWS Network Firewall
	
	DDoS protection
	AWS Shield
	
	Filter and control outbound DNS traffic for your VPCs
	Amazon Route53 Resolver DNS Firewall
	
	Filter malicious web traffic
	AWS Web Application Firewall (WAF)
	
	Central management of firewall rules
	AWS Firewall Manager
	
Data protection:
	Discover and protect your sensitive data at scale
	Amazon Macie
	
	Key storage and management
	AWS Key Management Service (KMS)
	
	Hardware based key storage for regulatory compliance
	AWS CloudHSM
	
	Provision, manage, and deploy public and private SSL/TLS certificates
	AWS Certificate Manager
	
	Rotate, manage, and retrieve secrets
	AWS Secrets Manager
	
Incident response:
	Investigate potential security issues
	Amazon Detective
	Scalable, cost-effective application recovery to AWS
	AWS Elastic Disaster Recovery
Compliance:
	No cost, self-service portal for on-demand access to AWS’ compliance reports
	AWS Artifact
	
	Continuously audit your AWS usage to simplify how you assess risk and compliance
	AWS Audit Manager


=================================================
#AWS Service List
=================================================
Compute Services
	Amazon EC2 - Secure, resizable Compute Instances (400+)
	EC2 Autoscaling - Automated compute capacity scaling
	Amazon LightSail - Easy virtual private server instances
	ElasticBeanstalk - Deploy & scale web apps (Java/Ruby/etc)
	Lambda - Serverless Compute Functions
Container Services
	ECR - Elastic Container Registry
	ECS - Elastic Container Service to deploy/manage clusters & tasks
	EKS - Elastic Kubernetes Service
	AWS Copilot - CLI to launch and manage containers
	AWS Fargate - Serverless Compute Engine for ECS/EKS Containers
Database Services
	Aurora - MySQL and PostgreSQL compatible database service
	DynamoDB - KeyValue / Document Database
	ElastiCache - Scalable in-memory database
	Neptune - Graph database for highly connected data sets
	Amazon RDS - Relational Database (MySQL/Postgres/Maria etc)
	Timestream - Serverless time series db for IoT
Network and Content Delivery
	AWS VPC - Logically isolated virtual private clouds
	API Gateway - Create and manage APIs
	CloudFront - Fast content delivery network CDN service
	Route53 - Fast DNS service
	AWS PrivateLink - Connect your on-prem network to AWS
	AWS AppMesh - Monitor, control, and debug the communications between services.
	AWS CloudMap - Resource discovery (can define custom names for your application resources,) 
	               Implementing lightweight on-premises API connectivity using inverting traffic proxy.
	AWS Direct Connect - Links your network directly to AWS to deliver consistent, low-latency performance.
	Global Accellerator - App traffic routing over the AWS network
	AWS TransitGateway - Centralised VPC and on prem connectivity
	Elastic Load Balancing - Service to evenly distribute network traffic
AWS Storage
	S3 - Object storage service
	EBS - Elastic Block Store, Persistent block
	EFS - Serverless Elastic File System(Only for Linux)
	FSx for Lustre - High performance file storage using Lustre
	FSx for Windows File System - AWS Windows file system
	S3 Glacier - Durable low cost archival storage
	AWS Backup - Policy driven data protection
	AWS Snow - Edge infrastructure for storage and compute
	AWS Storage Gateway - Hybrid on prem AWS storage 
	CloudEndure - Disaster recovery service 
Analytics Service
	Athena - Serverless SQL Query in S3.
	CloudSearch - Search Solution for Websites and Apps
	ElasticSearch - Deploy and run ElasticSearch, commonly used for log analytics.
	EMR(Elastic MapReduce, ) - Big Data Platform and Analysis, big data frameworks for complex and unstructured data.
	Kenesis - Real-time streaming data capture and analysis
	Redshift - Data Warehouse Service (gigabytes to a petabyte)uses SQL to analyze structured and semi-structured.
	QuickSight - Serverless ML BI Dashboards
	Data Exchange - Subscribe to 3rd Party Data Sets
	Data Pipeline - Transfer and process data
	Glue - Data discovery, enrichment and transfer
	AWS Lake Formation - Set up Data Lakes quickly
Application Integration Services
	Step Functions - Serverless Function Orchestration
	AppFlow - Integrate 3rd party app data,  securely transfer data between SaaS applications like 
	          Salesforce, SAP, Zendesk, Slack, and ServiceNow, and AWS services like Amazon S3 and  Redshift.
	EventBridge - Serverless Event Bus
	MQ - Message Broker Service for Apache/Rabbit MQ
	SNS - Simple Notification Messaging System
	SQS - Simple Queue Service Inter Component Messaging
	AppSync - GraphQL API Service
Cost Management Services
	AWS Cost Explorer - Visualize and manage AWS costs
	AWS Budgets - Service to set and monitor usage budgets
	AWS Cost and Usage Report - reporting to analyse AWS usage
BlockChain
	Amazon Managed Blockchain - Hyperledger & Ethereum Service
	Quantum Ledger DB (QLDB) - Fully managed financial ledger db

	
	


=================================================
#DataTransfer
================================================= 
One AWS account(or use) that want to communicate the resources in another account which can be achieved by:
	Cross-Account AssumeRole
	VPC Peering
	Resource Access Manager
	VPC endpoint service
	Transit Gateway
	
AWS DataSync:Copy Data correctly(Move data at onech).
	AWS DataSync is a secure, online service that automates and accelerates moving data between 
	on premises and AWS Storage services. 

DataSync can copy data between NFS shares,SMB shares, Hadoop Distributed File Systems (HDFS), 
self-managed object storage, 
Snowcone, S3 buckets,EFS file systems, FSx for Windows,FSx for Lustre, FSz for OpenZFS, 
and FSx for NetApp ONTAP file systems.


AWS Data Migration Service:
	AWS Data Migration Service copies data between databases, also send data to Amazon S3, 
	Amazon Kinesis and Apache Kafka.

AWS Database Migration Service (AWS DMS) is a cloud service that makes it easy to migrate 
relational databases, data warehouses, NoSQL databases, and other types of data stores. 
You can use AWS DMS to migrate your data into the AWS Cloud or between combinations of 
cloud and on-premises setups.


AWS Storage Gateway:
	AWS Storage Gateway provides a virtual storage device that stores data in the cloud 
	(on S3, Glacier, FSx, etc). Think of it as a cloud-backed H: drive with unlimited storage.


AWS Direct Connec:
	AWS Direct Connect links your office or data center to AWS via fiber. It's for high-speed, 
	permanent connectivity to the Cloud.

One end of the cable is connected to your router, the other to an AWS Direct Connect router. 
With this connection, you can create virtual interfaces directly to 
public AWS services S3 or to Amazon VPC, bypassing internet service providers in your network path.


AWS Site-to-Site VPN:
	AWS Site-to-Site VPN creates a VPN connection between your office or data center and 
	AWS via existing data connections. For example, it can create a VPN connection across your existing 
	Internet fiber connection.

A Site-to-Site VPN connection offers two VPN tunnels between a virtual private gateway or a 
transit gateway on the AWS side, 
and a customer gateway (which represents a VPN device) on the remote (on-premises) side.	

IPSec communications to create encrypted VPN tunnels between two locations. 
You cannot use AWS Site-to-Site VPN to integrate data files via the NFS interface.
	


=================================================
#Storage pricing | cost 
=================================================

	
EFS:
-------------------------------------------------
Serverless Elastic File System. for Linux Only.
Amazon EFS, you pay only for the resources that you use. 
The EFS Standard Storage pricing is $0.30 per GB per month. 



EBS:
-------------------------------------------------
EBS General Purpose SSD (gp2) volumes, the charges are $0.10 per GB-month of provisioned storage. 
Provisioned storage of 100GB for this use-case, the monthly cost on EBS is $0.10*100 = $10. 



S3:
-------------------------------------------------
A serverless, S3 Standard storage, the pricing is $0.023 per GB per month.





=================================================
#Noteable | Example | Topis | Tips | VIP
=================================================


#Resilient:স্থিতিস্থাপক
-------------------------------------------------
You can use Aurora replicas and CloudFront distribution to make the application more resilient to 
spikes in request rates.




#Availability:প্রাপ্যতা, লভ্যতা
-------------------------------------------------
If you have workloads that global client base, AWS recommends that you use Global Accelerator. 

If you have workloads hosted in a single AWS Region and used by clients in 
and around the same Region, you can use an 
Application Load Balancer or Network Load Balancer to manage your resources.



You can't enable termination protection for Spot Instances.


Network Firewall cannot directly integrate with the Application Load Balancer.
AWS WAF straightforward way of integrating with an ALB but not Network Firewall with an ALB.




AWS CodeDeploy:
	AWS CodeDeploy fully automates your software deployments, allowing you to deploy reliably and rapidly.

	AWS CodeDeploy is a fully managed developer tool that is used for deploying code from a code repository such as 
	GitHub or AWS CodeCommit. 
	You can deploy to many services including AWS services such as AWS Elastic Beanstalk, AWS Lambda, and AWS Fargate. 
	AWS CodeDeploy can be used independently or in a pipeline with AWS CodePipeline.

CodeDeploy is not meant to distribute traffic across instances.
CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, 
on-premises instances, serverless Lambda functions, or Amazon ECS services.





VPC Egress-Only  for IPv6:
	Launch the EC2 instance to a private subnet and attach an Egress-Only 
	Internet Gateway to the VPC to allow outbound IPv6 communication to the internet. 
	Use AWS Network Firewall to set up the required rules for traffic inspection and traffic filtering.
	
	
	
Internet Gateway does not limit or control any outgoing IPv6 connection.
NAT Gateway is only applicable for IPv4, not IPv6. 




AWS Proton:
	AWS Proton allows you to deploy any serverless or container-based application with increased efficiency, consistency, and control. 
	You can define infrastructure standards and effective continuous delivery pipelines for your organization. 
	Proton breaks down the infrastructure into environment and service (“infrastructure as code” templates).

AWS Proton allows customers to define application components as a stack, which creates everything needed to provision, 
deploy, and monitor an application, including compute, networking, code pipeline, security, and monitoring. 

AWS Proton associated with:
	Platform Team
	Developers
	Environment Templates
	Service Templates






Amazon Managed Service for Prometheus (AMP):
	 The Amazon Managed Service for Prometheus is only a Prometheus-compatible monitoring and alerting service that makes it easy 
	 to monitor containerized applications and infrastructure at scale.



Amazon Managed Service for Grafana (AMG):
	Amazon Managed Service for Grafana is a fully managed service with rich, interactive data visualizations to help 
	customers analyze, monitor, and alarm on metrics, logs, and traces across multiple data sources.
	
	
	

Amazon WorkDocs is more often used to easily create, edit, and share documents for collaboration and 
not for serving object data like Amazon S3.
	
 



Ensure that the database is eventually consistent and highly available:
	Configure the Auto Scaling group to spread the Amazon EC2 instances across three Availability Zones. 
	Use the AWS Database Migration Service (DMS) with a replication server and an ongoing replication 
	task to migrate the embedded NoSQL database to Amazon DynamoDB.




How ALB prevent SQL injection attacks:
	Use WAF and set up a managed rule to block request patterns associated with the exploitation 
	of SQL databases, like SQL injection attacks. Associate it with the Application Load Balancer. 
	Integrate AWS WAF with AWS Firewall Manager to reuse the rules across all the AWS accounts.




AWS Network Firewall is a managed service that makes it easy to deploy essential 
	network protections for all of your VPCs.




Route 53 Resolver DNS Firewall can only filter and regulate outbound DNS traffic from your VPC.
	It can neither do active traffic flow inspection nor block any vulnerability exploits.



Redshift(SQL Big data analyse) cluster as their data warehouse region outage or down:
	Enable Cross-Region Snapshots Copy in your Amazon Redshift Cluster.



Convert audio recordings into text using Amazon Transcribe. 
	Set up Amazon Translate to translate Hindi texts into English and use Amazon Comprehend for sentiment analysis.


Process both mission-critical data and non-essential batch jobs:
	Use ECS as the container management service then set up a combination of Reserved and 
	Spot EC2 Instances for processing mission-critical and non-essential batch jobs respectively.
    Scheduled Reserved Instances (Scheduled Instances).




S3 retrieve the required data in under 15 minutes under all circumstances 150 MB/s of retrieval throughput:
	Use Expedited Retrieval to access the financial data.
	Purchase provisioned retrieval capacity.

Expedited retrievals allow you to quickly access your data when occasional urgent requests 
for a subset of archives are required. For all but the largest archives (250 MB+), data accessed 
using Expedited retrievals are typically made available within 1–5 minutes. 

Provisioned capacity ensures that your retrieval capacity for expedited retrievals is available when you need it.




Collect and process the application log files:
Amazon S3 for storing the application log files and Elastic MapReduce(EMR) for processing the log files.




Fastest storage option with high I/O Performance for the temporary files:
	Configure RAID 0 in multiple instance store volumes.

RAID (Redundant Array of Independent Disks) is just a data storage virtualization technology 
that combines multiple storage devices to achieve higher performance or data durability.

RAID 0 configuration enables you to improve your storage volumes’ performance 
by distributing the I/O across the volumes in a stripe. 
	
This configuration can be implemented on both EBS or InstanceStore volumes. 

RAID 1 configuration is used for data mirroring. 
You need to configure RAID 0 to improve the performance of your storage volumes.




Following resources can be attach to your Transit Gateway:
	– One or more VPCs.
	– One or more VPN connections
	– One or more AWS Direct Connect gateways
	– One or more Transit Gateway Connect attachments
	– One or more Transit gateway peering connections
	


 
RDS if the primary database instance fails:
	The canonical name record (CNAME) is switched from the primary to standby instance.




For Single RDS security use SecurityGroup not Network ACL.
	Network ACL covers the entire subnet which means that other applications that use the same 
	subnet will also be affected.



A Kinesis data stream stores records from 24 hours by default to a maximum of 8760 hours (365 days).



ASG:
	With Step scaling, you choose scaling metrics and threshold values for the CloudWatch alarms that 
	trigger the scaling process as well as define how your scalable target should be scaled when a 
	threshold is in breach for a specified number of evaluation periods. Step scaling policies 
	increase or decrease the current capacity of a scalable target based on a set of scaling adjustments, 
	known as step adjustments. 



CloudWatch:
	By default, CloudWatch doesn’t monitor memory usage but only the -
	CPU utilization, Network utilization, Disk performance, and Disk Reads/Writes.

EC2 Detailed Monitoring does not provide metrics for memory usage,
just provides a higher frequency of metrics (1-minute frequency). 




AWS Transfer:
	Create an Amazon S3 bucket with encryption enabled. 
	Launch an AWS Transfer for SFTP endpoint to securely upload files to the S3 bucket. 
	Configure an S3 lifecycle rule to delete files after a month.




Storage optimized instances:
	Storage optimized instances are designed for workloads that require high, 
	sequential read and write access to very large data sets on local storage.

Memory Optimized Instances:
	Memory Optimized Instances are designed to deliver fast performance for workloads that process 
	large data sets in memory, which is quite different from handling 
	high read and write capacity on local storage.




EMR(Big Data Frameworks) previously called Amazon Elastic MapReduce:
	Amazon EMR is a managed cluster platform that simplifies running big data frameworks, such as 
	Apache Hadoop and Apache Spark, on AWS to process and analyze vast amounts of data.
	
By using these frameworks and related open-source projects, such as Apache Hive and Apache Pig, 
you can process data for analytics purposes and business intelligence workloads. 
Additionally, you can use Amazon EMR to transform and move large amounts of data into and out 
of other AWS data stores and databases.




Amazon Redshift is the most widely used cloud data warehouse:
	analyze all your data using standard SQL and your existing Business Intelligence (BI) tools. 
	It allows you to run complex analytic queries against terabytes to petabytes of 
	structured and semi-structured data, using sophisticated query optimization, columnar storage 
	on high-performance storage, and massively parallel query execution.



DynamoDB:
	DynamoDB doesn’t fully support the use of standard SQL and Business Intelligence (BI) tools, 
	unlike Amazon Redshift. It also doesn’t allow you to run complex analytic queries against 
	terabytes to petabytes of structured and semi-structured data.




Virtual Desktops:
	First, you need a VPN connection to connect the VPC and your on-premises network. 
	Second, you need AWS Directory Services to integrate with your on-premises Active Directory 
	and lastly, you need to use Amazon WorkSpace to create the needed Virtual Desktops in your VPC.




SAML 2.0:
	Before you can use SAML 2.0-based federation you must configure your organization’s IdP 
	and your AWS account to trust each other. 
	Inside your organization, you must have an IdP that supports SAML 2.0, 
	like Microsoft Active Directory Federation Service (AD FS, part of Windows Server), Shibboleth, 
	or another SAML 2.0 compatible provider.



DataSync:
	AWS DataSync is primarily used to migrate existing data to Amazon S3. 
	AWS Storage Gateway is more suitable if you still want to retain access to the migrated data 
	and for ongoing updates from your on-premises file-based applications.



Amazon EFS only supports file locking, Object lock is a feature of Amazon S3.



RDS Notification:
	Create a native function or a stored procedure that invokes a Lambda function. 
	Configure the Lambda function to send event notifications to an Amazon SQS queue for the 
	processing system to consume.





AWS Artifact:
	Use AWS Artifact to view the security reports as well as other AWS compliance-related information.
	AWS Artifact is your go-to, central resource for compliance-related information that matters to you. 
	It provides on-demand access to AWS’ security and compliance reports and select online agreements. 
	
Reports available in AWS Artifact include our Service Organization Control (SOC) reports, 
Payment Card Industry (PCI) reports, and certifications from accreditation bodies across 
geographies and compliance verticals that validate the implementation and operating effectiveness of 
AWS security controls. 
Agreements available in AWS Artifact include the Business Associate Addendum (BAA) and the 
Nondisclosure Agreement (NDA).




Create an Amazon S3 bucket with encryption enabled:
	Launch an AWS Transfer for SFTP endpoint to securely upload files to the S3 bucket. 
	Configure an S3 lifecycle rule to delete files after a month.
	There is no retention policy option on AWS Transfer for SFTP.



You can use EventBridge to run ECS tasks when certain AWS events occur.



AWS Control Tower (Multiple AWS accounts):
	AWS Control Tower service is primarily used to manage and govern multiple AWS accounts and not just S3.



ParallelCluster @(open-source cluster management tool):
	AWS ParallelCluster is simply an AWS-supported open-source cluster management tool that makes it easy 
	for you to deploy and manage High-Performance Computing (HPC) clusters on AWS.



AWS Proton @(“infrastructure as code” templates):
	AWS Proton allows you to deploy any serverless or container-based application with 
	increased efficiency, consistency, and control. 
	You can define infrastructure standards and effective continuous delivery pipelines for your organization. 
	Proton breaks down the infrastructure into environment and service.



Filter policies in SNS @(SNS Queue Filter):
	Create one Amazon SNS topic and configure the Amazon SQS queues to subscribe to the SNS topic. 
	Set the filter policies in the SNS subscriptions to publish the message to the 
	designated SQS queue based on its quote request type.





AWS Organizations and AD @(IAMIdentityCenter):
	On the master account, use AWS Organizations to create a new organization with all features turned on. 
	Invite the child accounts to this new organization.
	Configure AWS IAM Identity Center (AWS Single Sign-On) for the organization 
	and integrate it with the company’s directory service using the Active Directory Connector
	 
	Amazon Cognito is used for single sign-on in mobile and web applications. 
	You don’t have to use it if you already have an existing Directory Service to be used for authentication.
	 
User->OnPermDirectoryService(MS AD)->ActiveDirectoryConnector(ADTrust)->AWS IAMIdentityCenter(SSO)->access
	->AWSConsole
	->BusinessCloueApp
	->SAMLApplication





DynamoDB and AWS Backup: @(backups to another AWS account for disaster recovery):
	Create a DynamoDB gateway endpoint. Associate the endpoint to the appropriate route table. 
	Use AWS Backup to automatically copy the on-demand DynamoDB backups to another AWS account for disaster recovery.

	Point-in-Time Recovery (PITR) feature is not capable of restoring a DynamoDB table to a 
	particular point in time in a different AWS account.

DynamoDB on-demand backups cannot be copied to a different account or Region. 

To create backup copies across AWS accounts and Regions and for other advanced features, use AWS Backup.

Auto Scaling is not enabled in a DynamoDB table which is created using the AWS CLI.




Storage Gateway:
	Amazon Storage Gateway is used only for creating a backup of data from your on-premises server 
	and not from the Amazon services.

	Use AWS Storage Gateway to backup the data directly to Amazon S3 Glacier Deep Archive.
	Snowball Edge can’t directly integrate backups to S3 Glacier.




Roure53 pre-requirment when routing traffic:
	A registered domain name.
	The S3 bucket name must be the same as the domain name.
	No need The S3 bucket must be in the same region as the hosted zone.




Minimize the impact of DDoS attacks:
	Configure Amazon CloudFront distribution and set Application Load Balancer as the origin. 
	Create a rate-based web ACL rule using AWS WAF and associate it with Amazon CloudFront.

By using AWS WAF, you can configure web access control lists (Web ACLs) for your CloudFront distributions 
or Application Load Balancers to filter and block requests based on request signatures. 





Department base bill:
	Tag resources with the department name and enable cost allocation tags.




MySQL database needs to replicated in  S3 as CSV files:
	Create a full load and change data capture (CDC) replication task using AWS Database Migration Service (AWS DMS). 
	Add a new Certificate Authority (CA) certificate and create an AWS DMS endpoint with SSL.

When using Amazon S3 as a target in an AWS DMS task, both full load and change data capture (CDC) 
data is written to comma-separated value (.csv) format by default.




Snowball:
	AWS Snowball devices can upload the files to  S3. the primary goal is one-time migration of data to AWS 
	which can be accomplished by using AWS Snowball devices.



WorkDocs simply enables you to share content, provide rich feedback, and collaboratively edit documents.



ENI:
	If the instance fails, you (or more likely, the code running on your behalf) can attach 
	the network interface to a hot standby instance.
 
 
 
 
Detected Unauthorized person using Cameras, security team alerted via SMS:
	Use Amazon Kinesis Video to stream live feeds from the cameras. 
	Use Amazon Rekognition to detect unauthorized personnel. 
	Set the phone numbers of the security as subscribers to an SNS topic.

 
 
 
 
Amazon Fraud Detector:
	Amazon Fraud Detector is a fully managed service that identifies potentially fraudulent online activities 
	such as online payment fraud and fake account creation.

AWS Trusted Advisor only provides best practice recommendations. It cannot define rules for your AWS resources.





EBS volumes live configuration Change:
	EBS volumes support live configuration changes while in production, which means that you can modify 
	the volume type, volume size, and IOPS capacity without service interruptions.
	An EBS volume is off-instance storage that can persist independently from the life of an instance.



 
SQS and Amazon Simple Workflow Service (SWF) services for decoupled architecture in AWS. 
You can’t create a VPC peering for your on-premises network and AWS VPC.





AWS Control Tower:
	AWS Control Tower provides a single location to easily set up your new well-architected multi-account 
	environment and govern your AWS workloads with rules for security, operations, and internal compliance.
	
AWS Control Tower provides three methods for creating member accounts:
	– Through the Account Factory console that is part of AWS Service Catalog.
	– Through the Enroll account feature within AWS Control Tower.
	– From your AWS Control Tower landing zone’s management account, using Lambda code 
	  and appropriate IAM roles.

AWS Control Tower automatically implements guardrails using multiple building blocks such as 
AWS CloudFormation to establish a baseline, AWS Organizations service control policies (SCPs) 
to prevent configuration changes, and AWS Config rules to continuously detect non-conformance.





Systems Manager Parameter:
	Systems Manager Parameter Store doesn’t rotate its parameters by default.
	Use AWS Secrets Manager to store and encrypt the database credentials, API keys, and other secrets. 
	Enable automatic rotation for all of the credentials.

KMS is primarily used for encryption and not for hosting your credentials.





SQS @(retention period ):
	In Amazon SQS, you can configure the message retention period to a value from 1 minute to 14 days. 
	Default is 4 days. Once the message retention limit is reached, messages are automatically deleted.





Amazon Kinesis Data Firehose is a fully managed service for delivering real-time streaming data. 
Although it can stream data to an S3 bucket, it is not suitable to be used as a queue for a batch application.

Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. 
It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, 
and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you are already using today.





Amazon Redshift(data warehouse):
	Amazon Redshift is a fast( near real-time), scalable data warehouse that makes it simple and cost-effective 
	to analyze all your data across your data warehouse and data lake. 
	Redshift delivers ten times faster performance than other data warehouses by using machine learning, 
	massively parallel query execution, and columnar storage on a high-performance disk.



RealTime EC2 Log Processing:
	Create a Kinesis Data Stream and use AWS Lambda to read records from the data stream real-time.
	
Kinesis Data Firehose  near RealTime.
	Amazon Athena and Amazon Redshift(Analytics / BI / Data Warehouse) not RealTime processing.
Redshift is a relational database and best suited for tabular data; Athena is better for semi-structured and unstructured data.	
	




RDS Mysql: increase the disk space without impacting:
	Modify the DB instance settings and enable storage autoscaling.
	RDS Storage Auto Scaling automatically scales storage capacity in response to growing database workloads, with zero downtime.




ELB LogProcessing with EMR:
	Amazon S3 for storing ELB log files and Amazon EMR for analyzing the log files.
	You can also run other popular distributed frameworks such as Apache Spark, HBase, Presto, and Flink in Amazon EMR, 
	and interact with data in other AWS data stores such as Amazon S3 and Amazon DynamoDB.



The “Trust Relationship” policy simply defines which Principals can Assume the IAM Role and under which conditions.





Error:EC2ThrottledException:
	Your Lambda function automatically scales based on the number of events it processes. 
	If your Lambda function accesses a VPC, you must make sure that your VPC has sufficient ENI capacity 
	to support the scale requirements of your Lambda function. 





Route53:
	You can use Route 53 health checking to configure active-active and active-passive failover configurations. 

Active-Active Failover:
	In active-active failover, all the records that have the same name, the same type (such as A or AAAA), and the same routing policy 
	(such as weighted or latency) are active unless Route 53 considers them unhealthy. 
	Route 53 can respond to a DNS query using any healthy record.
	Active-Active Failover no parimary or secondary resource.

Active-Passive Failover:
	Use an active-passive failover configuration when you want a primary resource or group of resources to be available 
	the majority of the time and you want a secondary resource or group of resources to be on standby in case all the 
	primary resources become unavailable.






Aurora  Backup:
	Create an AWS Backup plan to take daily  Aurora snapshots with a retention period of 90 days.
	Maximum backup retention period for Aurora automated backup is only 35 days.



Aurora Instance class to Aurora Serverless:
	Use AWS Database Migration Service (AWS DMS) to migrate a new Aurora Serverless database.
	You can set up a DMS task for either one-time migration or ongoing replication.




AWS and On-Permiss Dedicated connection (With multi AWS acc):
	Create a new Direct Connect gateway and integrate it with the existing Direct Connect connection. 
	Set up a Transit Gateway between AWS accounts and associate it with the Direct Connect gateway.

VPC peering is not supported in a Direct Connect connection. VPC peering does not support transitive peering relationships.
 
VPN connection traverses the public Internet and doesn’t use a dedicated connection.




CloudFront Origin Access Identity (OAI) a feature ensures that  CloudFront can serve S3 content.
 
 
 

By default Network ACLs allow all inbound and outbound traffic.
By default Security group includes an outbound rule that allows all outbound traffic, no inbound rules. 




Kinesis Data Streams:
	Collect and process large streams of data records in real-time.
	The producers continually push data to Kinesis Data Streams, and the consumers process the data in real-time. 
	Consumers (such as a custom application running on Amazon EC2 or an Amazon Kinesis Data Firehose delivery stream) 
	can store their results using an AWS service such as  DynamoDB,  Redshift,  S3.


 
AWS Data Exchange is a data marketplace service. 
AWS Data Exchange is on a mission to increase speed to value for third-party data sets in the cloud.
 
 
 
Need to use a service that can store and retrieve objects through 
standard file storage protocols for quick recovery:
	  Use the AWS Storage Gateway file gateway to store all the backup data in Amazon S3.
	  You cannot directly access the volume gateway using Amazon S3 APIs.
	 
	 
	 
S3:
	Can access S3 buckets file using an S3 URL or through their CloudFront distribution:
	A better solution is to set up an origin access identity (OAI) then use Signed URL or Signed Cookies 
	in your CloudFront web distribution for Restrict access file.

S3 does not public event messages to Amazon MQ. You should use an Amazon SQS instead.

S3 supports 3 destinations where it can publish events:
	1. SNS topic
	2. SQS queue
	3. AWS Lambda






Retrieve a subset of data from a large CSV file stored in an S3: 
	Perform an S3 Select operation based on the bucket's name and object's key.
	
Metadata is not needed when querying subsets of data in an object using S3 Select. 
Tags just provide additional information to your object, not needed when querying with S3 Select although this can be useful 
for S3 Batch Operations. 
 
 
 
 
 
S3 Cross-account Permissions to copy objects from a source bucket in Account A to a destination bucket in Account B:
	– Attach a bucket policy to the source bucket in Account A.
	– Attach an AWS Identity and Access Management (IAM) policy to a user or role in Account B.
	– Use the IAM user or role in Account B to perform the cross-account copy.
	 
	 
 
Aurora DB cluster:
	A reader endpoint for an Aurora DB cluster provides load-balancing support for read-only connections to the DB cluster.
	Cluster endpoint (also known as a writer endpoint) simply connects to the current primary DB instance for that DB cluster.



Kinesis stream Retation periond(1 to 365):
	A Kinesis data stream stores records from 24 hours (1 day ) by default to a maximum of 8760 hours (365 days).
 
 
 
By default, Fargate tasks are given a minimum of 20 GiB of free ephemeral storage, 
	which meets the storage requirement in the scenario.



Interface endpoint vs Transit Gatewa:
	You pay an hourly rate for every provisioned Interface endpoint.
	AWS Transit Gatewa: VPCs and on-premises networks through a central hub.




RDS read-replica:
	RDS Replicas asynchronous replication and create read replicas within a Region or between Regions.




Tags:
	All AWS resources be tagged with a standard naming convention:
	Use an AWS Config rule to detect non-compliant tags.
	 



S3 Retrival within 15 minutes under all circumstances:
	If you require access to Expedited retrievals under all circumstances, you must purchase provisioned retrieval capacity.




ALB SSL MultipleCertificate:
	Upload all SSL certificates of the domains in the ALB using the console and bind multiple certificates to the 
	same secure listener on your load balancer. 
	ALB will automatically choose the optimal TLS certificate for each client using Server Name Indication (SNI).

Wildcard certificate can only handle multiple sub-domains but not different domains.
 



S3 decrypted by the Lambda function call:
	Attach the kms:decrypt permission to the Lambda function’s execution role. 
	Add a statement to the AWS KMS key’s policy that grants the function’s execution role the kms:decrypt permission.



The /32 denotes one IP address, and the /0 refers to the entire network.



AWS DataSync(moving data between on-premises and AWS storage services like S3,EFS):
	AWS DataSync does not work with Amazon EBS volumes.
	
	DataSync can copy data between Network File System (NFS) shares, Server Message Block (SMB) shares, self-managed object storage,
	AWS Snowcone, S3 buckets,Amazon EFS file systems, and Amazon FSx for Windows File Server file systems.

 


CloudFormation template:
	Needs to ensure that the required components are properly running before the stack creation proceeds:
	
	Configure a CreationPolicy attribute to the instance in the CloudFormation template. 
	Send a success signal after the applications are installed and configured using the cfn-signal helper script.

	UpdatePolicy attribute is primarily used for updating resources and for stack update rollback operations.
	
	UpdateReplacePolicy attribute is primarily used to retain or in some cases, back up the existing physical instance 
	of a resource when it is replaced during a stack update operation.



 

Avoid losing recently submitted requests:
	Use an Amazon SQS queue to decouple the application components and scale-out the EC2 instances based upon the 
	SqS ApproximateNumberOfMessages metric in Amazon CloudWatch.



Launch an  Group for each department. 
Create an IAM Policy that enforces MFA authentication with the least privilege permission. 
Attach the IAM Policy to each Group.




SCP:
	SCP can only be attached to the organization root, to an organizational unit (OU), or directly to an account, 
	but not directly in the IAM User. 

	IAM role Cannot directly associate with IAM user.
An IAM role is an IAM identity that you can create in your account that has specific permissions. An IAM role is similar to an IAM user.
	
Users and Groups use only Policies, You cannot attach Roles to it.

IAM User     = Single Account with credentials for login, e.g. JohnDoe
IAM Role     = Single Account without credentials, created for AWS Resources to "Assume".
IAM Group    = A collection of IAM Users.

IAM Policy   = Resource Access Rules.
Policies are added to Users, Roles, or Groups, to give them the permissions specified in the policy.




Secrets Manager Parameter vs Systems Manager Parameter:
	Secrets Manager there is a cost associated with using Store encrypted parameters with rotation. 
	If you are storing mostly application parameters, then the Systems Manager Parameter Store is a better fit
	with (AWS KMS) for the encryption.





You can’t have an Amazon S3 managed encryption key(SSE-S3) for client-side encryption.
– Set up Client-Side Encryption with a customer master key stored in AWS Key Management Service (AWS KMS).
– Set up Client-Side Encryption using a client-side master key.




Below are the valid EC2 lifecycle instance states:
	pending – The instance is preparing to enter the running state. 
		An instance enters the pending state when it launches for the first time, or when it is restarted after being in the stopped state.
	running – The instance is running and ready for use.
	stopping – The instance is preparing to be stopped. 
		Take note that you will not billed if it is preparing to stop however, you will still be billed if it is just preparing to hibernate.
	stopped – The instance is shut down and cannot be used. The instance can be restarted at any time.
	shutting-down – The instance is preparing to be terminated.
	terminated – The instance has been permanently deleted and cannot be restarted. 
		Take note that Reserved Instances that applied to terminated instances are still billed until the 
		end of their term according to their payment option.



VPC IP address allowed block(16-28) size in is between a /16 netmask (65,536 IP addresses) and /28 netmask (16 IP addresses)




EC2 Faster Boot:
	Migrate the application EC2 instance to an EC2 instance with hibernation enabled.
It is not possible to enable or disable hibernation for an instance after it has been launched.




50TB data transfer from on permiss:
	Request an Import Job to Amazon S3 using a Snowball device in the AWS Snowball Console.




GlobalRealTimeDataProcessing:
	Integrate CloudFront with Lambda@Edge in order to process the data in close geographical proximity to users 
	and respond to user requests at low latencies. 
	Process real-time streaming data using Kinesis and durably store the results to an Amazon S3 bucket.

CloudFront and Route 53 just do Geoproximity routing only not process date.
	By using Lambda@Edge and Kinesis together, you can process real-time streaming data so that you can track and analyze 
	globally-distributed user activity on your website and mobile applications, including clickstream analysis.





By using a Curl or Get Command to get the latest metadata information from http://169.254.169.254/latest/meta-data/
Like PrivatePublicIp





DynamoDB Streams:
	Enabling DynamoDB Streams to capture table activity and automatically trigger the Lambda function.

CloudWatch Alarms only monitor service metrics, not changes in DynamoDB table data.





Log file processing:
	S3 for storing the application log files and Amazon Elastic MapReduce(EMR | big data frameworks) for processing the log files.




SQS:
	Amazon (Default setting)SQS queue no order mentain of message as send or receive and 
	SQS does not guarantee that no duplicates will be sent.
	 
A Kinesis data stream is a set of shards that has a sequence of data records, and each data record has a sequence number 
and guarantee no duplicates.




AWS Data Pipeline:
	AWS Data Pipeline a cloud-based data workflow service that helps you process and move data between different 
	AWS services and on-premises data sources. 

It is not suitable for collecting data from distributed sources such as users, IoT devices, or clickstreams.




Hundred of EC2 instances Log Process:
	Install the Unified CloudWatch Logs agent in each instance which will automatically collect and push 
	data to CloudWatch Logs. Analyze the log data using CloudWatch Logs Insights.
	CloudWatch Logs Insights enables you to interactively search and analyze your log data in Amazon CloudWatch Logs. 




S3StaticResourcePublicAcc:
	Grant public read access to the object when uploading it using the S3 Console.
	Configure the S3 bucket policy to set all objects to public read.
	
An IAM Role, in itself, cannot directly make the S3 objects public or change the permissions of each individual object.





Differences between Fault Tolerance and High Availability is that:
	Fault tolarance refers to the minimum number of running instances is .like Need 4 and runing 4
	If Need 4 and runing 2 Its High available.





Dashboard for continuous detection of policy non-conformance and non-compliant 
resources across the enterprise and AWS multi-account strategy best practices ?

AWS Control Tower:
	Use AWS Control Tower to launch a landing zone to automatically provision and configure new accounts through an Account Factory. 
	Utilize the AWS Control Tower dashboard to monitor provisioned accounts across your enterprise. 
	Set up preventive and detective guardrails for policy enforcement.


AWS Control Tower offers a straightforward way to set up and govern an AWS multi-account environment, 
following prescriptive best practices. 

AWS Control Tower orchestrates the capabilities of several other AWS services, including AWS Organizations, AWS Service Catalog, 
and AWS Single Sign-On, to build a landing zone in less than an hour.
 
It offers a dashboard to see provisioned accounts across your enterprise, guardrails enabled for policy enforcement, 
guardrails enabled for continuous detection of policy non-conformance, and non-compliant resources organized by accounts and OUs.

When users perform work in any AWS account in your landing zone, they’re always subject to the guardrails 
that are governing their account’s OU.

The AWS Organizations service neither has the capability to build a landing zone nor a built-in dashboard ,
for continuous detection of policy non-conformance and non-compliant resources across the enterprise.






ElasticBeanstalk environments have limited resources; for example, ElasticBeanstalk does not create a VPC for you.
 
 
 
 
Increase acc time of Websit remove slow ness:
	– Use Amazon CloudFront with website as the custom origin.
	– Use Amazon ElastiCache for the website’s in-memory data store or cache.



Redshift is primarily used for OLAP (Online Analytical Processing).
Amazon RDS Read Replica of OLTP (Online Transactional Processing).



NAT gateway:
	You must specify an Elastic IP address to associate with the NAT gateway when you create it. 
	The Elastic IP address cannot be changed once you associate it with the NAT Gateway.



Regional Failover and High available:
	In a secondary region, create a global table of the DynamoDB table and replicate, auto-scaling group and application load balancer.
	Use Route 53 DNS failover to automatically route traffic to the resources in the secondary region. 
	Set up the AWS Well-Architected Tool to easily get recommendations for improving your workloads based on the AWS best practices.

A global secondary index can only be created in the region where its parent table resides.
 



 
When you create or update a distribution in CloudFront, you can add an origin access identity (OAI) and automatically update 
the bucket policy to give the origin access identity permission to access your bucket.

Alternatively, you can choose to manually change the bucket policy or change ACLs, which control permissions 
on individual objects in your bucket.
 
 
 



VPNs peering multiple regions:
	To interconnect all of the company’s on-premises networks, VPNs, and VPCs into a single gateway, 
	which includes support for inter-region peering across multiple AWS regions.

	Set up an AWS Transit Gateway in each region to interconnect all networks within it. 
	Then, route traffic between the Transit gateways through a peering connection.

If you attach a transit gateway peering connection, the transit gateway must be in a different Region.




Athena:
	Athena is an interactive query service that makes it easy to analyze data directly in S3 using standard SQL.
	Athena helps you analyze unstructured, semi-structured, and structured data stored in Amazon S3. 
	Examples include CSV, JSON, or columnar data formats such as Apache Parquet and Apache ORC. 
	You can use Athena to run ad-hoc queries using ANSI SQL without the need to aggregate or load the data into Athena.





RabbitMQ cluster:
	A cluster deployment is a logical grouping of three RabbitMQ broker nodes behind a Network Load Balancer, 
	each sharing users, queues, and a distributed state across multiple Availability Zones (AZ).



DataSync:
	AWS DataSync simplifies, automates, and accelerates copying large amounts of data to and from AWS storage services 
	over the internet or AWS Direct Connect. 
	
You deploy an DataSync agent to on-premises hypervisor or in Amazon EC2. To copy data to or from an on-premises file server.
To set up transfers between Snowcone device and AWS storage, use the DataSync agent AMI that comes pre-installed on your device.




To connect programmatically to an AWS service, you will need to use an AWS Direct Connect service endpoint.
No data transfer cost between S3 and EC2 in the same AWS Region.




LDAP to IAM:
	IAM policy is not enough to integrate your LDAP service to IAM. You need to use SAML, STS, or a custom identity broker.
	
	If your identity store is not compatible with SAML 2.0 then you can build a custom identity broker application 
	to perform a similar function.
	Develop an on-premises custom identity broker application and use STS to issue short-lived AWS credentials.
	


Elastic Fabric Adapter EFA not work for Windows:
	The OS-bypass capabilities of EFAs are not supported on Windows instances. 
	If you attach an EFA to a Windows instance, the instance functions as an Elastic Network Adapter without the added EFA capabilities.




Amazon S3 Anslysis tools:
	S3 Select
		Amazon S3 Select is designed to help analyze and process data within an object in Amazon S3 buckets, faster and cheaper.
	Amazon Athena
		Amazon Athena is an interactive query service that makes it easy to analyze data in Amazon S3 using standard SQL expressions.
		Simply point to your data in Amazon S3, define the schema, and start querying using standard SQL expressions. 
	Amazon Redshift Spectrum
		Redshift also includes Redshift Spectrum, allowing you to directly run SQL queries against exabytes of unstructured 
		data in Amazon S3. No loading or transformation is required, and you can use open data formats, 
		including Avro, CSV, Grok, ORC, Parquet, RCFile, RegexSerDe, SequenceFile, TextFile, and TSV.




Redshift disaster recovery:
	Enable Cross-Region Snapshots Copy in your Amazon Redshift Cluster.
	automated snapshots is not enough and will not be available in case the entire AWS region is down.
	You can configure Amazon Redshift to copy snapshots for a cluster to another region. 
	To configure cross-region snapshot copy, you need to enable this copy feature for each cluster and configure 
	where to copy snapshots and how long to keep copied automated snapshots in the destination region. 

When a cross-region copy is enabled for a cluster, all new manual and automatic snapshots are copied to the specified region.





High I/O performance for the EC2 temporary files:
	Configure RAID 0 in multiple instance store volumes. RAID 1 configuration is used for data mirroring. 




S3 upload encryption obj:
	Create an S3 bucket policy that denies permissions to upload an object unless the request includes 
	the s3:x-amz-server-side-encryption": "AES256" header. 
	
	Enable server-side encryption with Amazon S3-managed encryption keys (SSE-S3) and rely on the built-in key rotation feature 
	of the SSE-S3 encryption keys.





Deactivating and deleting any IAM user access key that is over 90 days old:
	Amazon EventBridge cannot directly check for IAM events that show the age of IAM access keys.
	
	Use the AWS Config managed rule to check if the IAM user access keys are not rotated within 90 days. 
	Create an Amazon EventBridge (Amazon CloudWatch Events) rule for the non-compliant keys, and define a target to invoke 
	a custom Lambda function to deactivate and delete the keys.





AWS Health:
	AWS Health provides ongoing visibility into your resource performance and the availability of your AWS services and accounts. 
	You can use AWS Health events to learn how service and resource changes might affect your applications running on AWS. 
	
	AWS Health provides relevant and timely information to help you manage events in progress. 
	AWS Health also helps you be aware of and to prepare for planned activities.
	
	Use EventBridge to detect and react to AWS Health events. Then, based on the rules that you create, 
	EventBridge invokes one or more target actions. 
	
	
Your account Healt/events page shows all events from the past 90 days.
AWS Service Health Dashboard shows public events that may affect several customers in particular regions. 
It doesn’t show events related to specific EC2 instances on individual AWS accounts.






Comprehend Medical and Textract:
	Use Amazon Textract to extract the text from the PDF reports. Integrate Comprehend Medical with the existing Lambda function 
	to identify the PHI from the extracted text.
	
	The PII (Personally Identifiable Information) redaction feature of the Amazon Textract Medical service is not enough to 
	identify all the Protected Health Information (PHI) in the PDF reports. Take note that PII is quite different from PHI.





Max IOPS for volume is 10 GiB (50:1):Set the IOPS to 500 then maintain a low queue length.

	An io1 volume can range in size from 4 GiB to 16 TiB. 
	You can provision from 100 IOPS up to 64,000 IOPS per volume on Nitro system instance families and up to 32,000 on 
	other instance families. The maximum ratio of provisioned IOPS to the requested volume size (in GiB) is 50:1.
	
	For example, a 100 GiB volume can be provisioned with up to 5,000 IOPS. 
	On a supported instance type, any volume 1,280 GiB in size or greater allows provisioning up to the 64,000 IOPS 
	maximum (50 × 1,280 GiB = 64,000).

The volume queue length is the number of pending I/O requests for a device.






EBS Multi-attach Not multi AZ:
	Multi-attach feature can only be enabled on EBS Provisioned IOPS io2 or io1 volumes. 
	In addition, multi-attach won’t offer multi-az resiliency because this feature only allows an EBS volume to be attached on 
	multiple instances within a availability zone (AZ).

EBS provides three volume types to best meet the needs of your workloads: 
	General Purpose (SSD), 
	Provisioned IOPS (SSD), 
	and Magnetic.





AWS Config:
	Configure AWS Config to trigger an evaluation that will check the compliance for a user’s password periodically.

AWS Control Tower is used to simplify the creation of new accounts with preconfigured constraints. 
It isn’t used to automate application deployments. Moreover, AWS Config is commonly used for 
monitoring the changes of AWS resources and not the custom resources for serverless or 
container-based applications in AWS.






Enable S3 server access logging:
	Server access logging provides detailed records for the requests that are made to a S3 bucket.
	
	Track and log every request access to their S3 buckets including the requester, bucket name, request time, request action, 
	referrer, turnaround time, and error code information, Enable server access logging for all required Amazon S3 buckets.

AWS CloudTrail logs provide a record of actions taken by a user, role, or an AWS service in Amazon S3, 
while S3 server access logs provide detailed records for the requests that are made to an S3 bucket.

AWS CloudTrail alone won’t give detailed logging information for object-level access.






Migrate all of its VM workloads to the AWS cloud:
	Install the AWS Replication Agent on each of the on-premises VMs to continuously replicate the servers to AWS. 
	Use AWS Migration Service (AWS MGN) to launch test instances and perform cutover once testing is completed.
	
AWS MGN(Application Migration Service)is the primary migration service recommended for lift-and-shift migrations to AWS.


The AWS Application Discovery Service is primarily used to track the migration status, 
This service is not capable of doing the actual migration.






Enhanced Monitoring:
	RDS Enhanced Monitoring metrics shown in the Process List:
	RDS Process,RDS child Process,OS Process.

Enhanced Monitoring metrics are useful when you want to see how different processes or threads on a DB instance use the CPU.

RDS provides metrics in real-time for the operating system (OS) that your DB instance runs on. 
You can view the metrics for your DB instance using the console or consume the Enhanced Monitoring JSON output






Where can you safely import the SSL/TLS certificate of your application?
	IAM Certificate store, 
	AWS Certificate Manager.
	
If you got your certificate from a third-party CA, import the certificate into ACM or upload it to the IAM Certificate store.

ACM lets you import third-party certificates from the ACM console, as well as programmatically. 
If ACM is not available in your region, use AWS CLI to upload your third-party certificate to the IAM Certificate store.


Audit Trail for SSE-KMS Key Uses:
	Envelope encryption, Encryption with AWS KMS-Managed Keys (SSE-KMS).

	Customer-Provided Keys (SSE-C),Amazon S3-Managed Keys (SSE-S3): these two do not provide you with an audit trail 
	that shows when your CMK was used and by whom, unlike Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS).






Two AWS services are issuing and deploying X.509 Certificates:
ACM Private CA—
	Certificates issued by a private CA are trusted only within your organization, not on the internet.
	With ACM Private CA, you can create your own CA hierarchy and issue certificates with it for authenticating internal users, 
	computers, applications, services, servers, and other devices and for signing computer code.

ACM Public CA—
	ACM public certificates for enterprise customers who need a publicly trusted secure web presence using TLS. 
	You can deploy ACM certificates into AWS Elastic Load Balancing, CloudFront, API Gateway, and other integrated services. 
	
	AWS Certificate Manager (ACM), you can import certificates that you obtained outside of AWS.
	Multiple certificates with the same domain name can be imported, but they must be imported one at a time.





Secure Connected RDS for MySQ:
	Use IAM DB Authentication and create database accounts using the AWS-provided AWSAuthenticationPlugin plugin in MySQL.

You can authenticate DB instance using IAM database authentication. IAM database authentication works with MySQL and PostgreSQL. 
AWS-provided plugin that works seamlessly with IAM to authenticate your IAM users. 





Allows or blocks web requests:
	A geo match condition lists countries that your requests originate from.

Using AWS WAF: 
	Create a web ACL with a rule that explicitly allows requests from approved IP addresses declared in an IP Set.
	Add another rule  geo match condition that blocks requests that originate from a specific country.
	
If you want to prioritize resources for users in a particular country, you could include a geo-match condition in 
	two different rate-based rules. 
Set a higher rate limit for users in the preferred country and set a lower rate limit for all other users.


If you are using the CloudFront geo restriction feature to block a country from accessing your content, 
any request from that country is blocked and is not forwarded to AWS WAF Classic. 

So if you want to allow or block requests based on geography plus other AWS WAF Classic conditions, 
you should not use the CloudFront geo restriction feature. Instead, you should use an AWS WAF Classic geo match condition.


ALB listener rule, It only determines how the load balancer routes the requests to its registered targets.
You can’t configure a geo match condition in an Application Load Balancer. 







AWS Trusted Advisor:
	AWS Trusted Advisor is an online tool that provides real-time guidance and resources best practices. 
	It inspects your AWS environment and makes recommendations for saving money, improving system performance and reliability, 
	or closing security gaps.

AWS Cost Explorer:
	AWS Cost Explorer a tool that enables you to view and analyze your costs and usage.
	It has an easy-to-use interface that lets you visualize, understand, and manage your AWS costs and usage over time.





SimpleDB vs DynamoDB:
	SimpleDB is a highly available and scalable NoSQL database, it has a limit on the request capacity or storage size 
	for a given table, unlike DynamoDB.

	DynamoDB is use this to have an ACID-compliant database, it is not capable of handling complex queries and highly 
	transactional (OLTP) workloads.





RDS vs Aurora:
	RDS not scalable to handle the growth of the database. 
	Aurora is the better choice as its underlying storage can grow automatically as needed.




Virtual Desktops:
	VPN connection to connect the VPC and your on-premises network. 
	Second, you need AWS Directory Services to integrate with your on-premises Active Directory and a
	Amazon Workspace to create the needed virtual desktops in your VPC.





Enhanced Networking vs ParallelCluster:
	Enable Enhanced Networking with Elastic Network Adapter (ENA) on the Windows EC2 Instances.
	Enhanced networking provides higher bandwidth, higher packet per second (PPS) performance, and consistently lower 
	inter-instance latencies. There is no additional charge for using enhanced networking.
	 
ParallelCluster:
	AWS ParallelCluster is just an AWS-supported open-source cluster management tool that makes it easy for you to deploy and manage 
	High-Performance Computing (HPC) clusters on AWS. 

It not provide higher bandwidth, higher packet per second (PPS) performance, and lower inter-instance latencies, unlike ENA or EFA.





ALB  health check with HTTP and HTTPS.
NLB and CLB health check with TCP is only.




IAM roles are global:
	Assign the existing IAM role to instances in the new region. IAM roles are global services that are available to all regions.





Block the IP addresses at subnet layer using Network Access Control List (ACLs):
	You can associate a network ACL with multiple subnets; however, a subnet can be associated with only one network ACL at a time. 
	When you associate a network ACL with a subnet, the previous association is removed.

Create a Web ACL rule in AWS WAF to block the specified country. Associate this rule to the Application Load Balancers. 






A static Anycast IP address is primarily used by AWS Global Accelerator to enable organizations to route traffic seamlessly 
to multiple regions and improve availability and performance for their end-users.






AppSync:
	AWS AppSync is a serverless GraphQL and Pub/Sub API service that simplifies building modern web and mobile applications. 
	It provides a robust, scalable GraphQL interface for application developers to combine data from multiple sources, 
	including Amazon DynamoDB, AWS Lambda, and HTTP APIs.
	
Develop the application using the AWS AppSync service and use its built-in custom domain feature. 
Associate an SSL certificate to the AWS AppSync API using the AWS Certificate Manager (ACM) service to enable HTTPS communication.

When you configure an AWS AppSync API, Its provisioned two endpoints:
	AWS AppSync GraphQL endpoint:
	AWS AppSync real-time endpoint:





SQS Short or Long polling:
	The ReceiveMessageWaitTimeSeconds is the queue attribute that determines whether you are using Short or Long polling. 
	By default, its value is zero which means it is using Short polling. 
	If it is set to a value greater than zero, then it is Long polling.
	
The default visibility timeout for a message is 30 seconds. The maximum is 12 hours in SQS.






Step scaling:
	With step scaling, you choose scaling metrics and threshold values for the CloudWatch alarms that trigger the scaling process 
	as well as define how scalable target should be scaled when a threshold is in breach for a specified number of evaluation periods. 

Step scaling policies increase or decrease the current capacity of a scalable target based on a set of scaling adjustments, 
known as step adjustments. 
 
Scaling up and down multiple times:
	Change the cooldown period of the Auto Scaling group and set the CloudWatch metric to a higher threshold.
 
 
 
 
 
Aurora failure on the primary database instance for failover:
	Aurora will attempt to create a new DB Instance in the same Availability Zone as the original instance 
	and is done on a best-effort basis.

If you have an Amazon Aurora Replica in the same or a different Availability Zone, when failing over, 
Amazon Aurora flips the canonical name record (CNAME) for your DB Instance to point at the healthy replica, 
which in turn is promoted to become the new primary. Start-to-finish failover typically completes within 30 seconds.

If you are running Aurora Serverless and the DB instance or AZ becomes unavailable, 
Aurora will automatically recreate the DB instance in a different AZ.

If you do not have an Amazon Aurora Replica (i.e., single instance) and are not running Aurora Serverless, 
Aurora will attempt to create a new DB Instance in the same Availability Zone as the original instance. 

For Single instance, no read repllica, Aurora will first attempt to create a new DB Instance in the same Availability Zone 
as the original instance. If unable to do so, Aurora will attempt to create a new DB Instance in a 
different Availability Zone and not the other way around.
 
 
 
 
 
 
Test new version of Application with  50/50 request:
	Use an Application Elastic Load balancer with Weighted Target Groups to divert and proportion the traffic between the 
	on-premises and AWS-hosted application.
	OR
	Use Route 53 with Weighted routing policy to divert the traffic between the on-premises and AWS-hosted application. 

Network Load balancer doesn’t have Weighted Target Groups.
 
 
 
 
IP addresses from one of the following CIDR blocks:
– 10.0.0.0/8 (RFC 1918)
– 100.64.0.0/10 (RFC 6598)
– 172.16.0.0/12 (RFC 1918)
– 192.168.0.0/16 (RFC 1918)


 
 
 
 
 
 
 
Heterogeneous migrations a two step process.:
	Heterogeneous database migration in which you need to transform your on-premises Oracle database to PostgreSQL in AWS:
	
	First, use the AWS Schema Conversion Tool to convert the source schema and application code to match that of the target database, 
	and then use the AWS Database Migration Service to migrate data from the source database to the target database.



 
Route53:
	If you have multiple web servers running on EC2 instances behind an Elastic Load Balancing load balancer, 

	Route 53 will route all traffic addressed to your website (e.g. www.tutorialsdojo.com) to the load balancer 
	DNS name (e.g. elbtutorialsdojo123.elb.amazonaws.com).

CNAME records cannot be created for your zone apex. 
You should create an alias record at the top node of a DNS namespace which is also known as the zone apex. 

For example, if you register the DNS name tutorialsdojo.com, the zone apex is tutorialsdojo.com. 
You can’t create a CNAME record directly for tutorialsdojo.com, but you can create an alias record for tutorialsdojo.com 
that routes traffic to www.tutorialsdojo.com.




Most AWS services use VPC Interface Endpoint, VPC Gateway Endpoint only for S3 and DynamoDB.
  
  
 
AWS Storage Gateway vs DataSync:
	Integrate or replicate the data->AWS Storage Gateway
	Migrate or move data->DataSync 

Set up AWS DataSync to move the existing health records from the on-premises network to the AWS Cloud. 
Launch a new Amazon S3 bucket to store existing and new records. 

Enable AWS CloudTrail with Data Events and Amazon S3 Object Lock in the bucket.

Amazon Storage Gateway:
	File Gateway (NFS)
	Volume Gateway (iSCSI)
	Tape Gateway (VTL)

A File Gateway is a type of Storage Gateway used to integrate your existing on-premise application with the Amazon S3. 
It provides NFS (Network File System) and SMB (Server Message Block) access to data in S3.


Archive on S3 and frequently accessed data locally on their on-premises server:
Use the Amazon Storage Gateway – Cached Volumes.

Volume Gateway stores and manages on-premises data in Amazon S3  either cache mode or stored mode.
Point-in-time backups of your volumes stored as EBS snapshots and come in two different operational modes: stored and cached.





SQS:
	SQS has automatically deleted the messages that have been in a queue for more than the maximum message retention period.
	The default message retention period is 4 days max 14 days.





S3 Time Constraint Transitioning:
	Set a lifecycle policy in the bucket to transition to S3 – Standard IA after 30 days
	Set a lifecycle policy in the bucket to transition the data from Standard storage class to Glacier after one week (7 days).

Only change the storage class of your objects 
	From S3 Standard storage class to STANDARD_IA or ONEZONE_IA storage after 30 days. 
	This limitation does not apply to INTELLIGENT_TIERING, GLACIER, and DEEP_ARCHIVE storage class.

The following constraints apply from Standard storage class to STANDARD_IA or ONEZONE_IA:
	1)not transition objects that are smaller than 128 KB to the STANDARD_IA or ONEZONE_IA.
	2)Objects must be stored for at least 30 days in the current storage class before you can transition them to STANDARD_IA or ONEZONE_IA.
	3)(in versioned buckets), you can transition only objects that are at least 30 days noncurrent to STANDARD_IA or ONEZONE_IA storage.





EBS Encryption at rest:
	using your own keys in AWS Key Management Service (KMS) and using Amazon-managed keys in AWS Key Management Service (KMS).




Step scaling:
	Step scaling applies “step adjustments” which means you can set multiple actions to vary the scaling 
	depending on the size of the alarm breach. 
	
When you create a step scaling policy, you can also specify the number of seconds that it takes for a newly launched instance to warm up.






AWS Systems Manager Run Command:
	AWS Systems Manager is a useful and powerful tool that allows organizations to operate complex infrastructure at scale, 
	both safely and securely.

	Systems Manager provides an operations console and APIs for centralized application and resource management in hybrid environments.

	AWS Systems Manager Run Command lets you remotely and securely manage the configuration of your managed instances. 
	A managed instance is any Amazon EC2 instance or on-premises machine in your hybrid environment that has been 
	configured for Systems Manager.

You can use Run Command from the AWS console, the AWS Command Line Interface, AWS Tools for Windows PowerShell, or the AWS SDKs. 
Run Command is offered at no additional cost.





 
AWS has an example of the implementation of Quota Monitor CloudFormation template that you can deploy on your AWS account. 
The template uses an AWS Lambda function that runs once every 24 hours.






Trusted Advisor:
	The AWS Trusted Advisor Service limit publishes- service limits metric to CloudWatch; 
	thus, you can configure an alarm and send a notification to Amazon SNS. 

	You can also create an AWS Lambda function to read data from specific Trusted Advisor checks. 
	A Lambda function invocation can be scheduled using AWS EventBridge (Amazon CloudWatch Events) to automated the process.




Use ECS as the container management service then set up a combination of Reserved and Spot EC2 Instances for processing 
mission-critical and non-essential batch jobs respectively.




During peak hours, many employees are experiencing slow connectivity issues:
	Associate the VPCs to an Equal Cost Multipath Routing (ECMR)-enabled Transit gateway and attach additional VPN tunnels.
	The maximum tunnel for a VPN connection is 2-two.
	 
	 
 
 



CloudTrail log processing:
	CloudTrail stores the log files to S3 and not in Glacier.
	By default, CloudTrail event log files are encrypted using Amazon S3 server-side encryption (SSE). 

You can also define Amazon S3 lifecycle rules to archive or delete log files automatically. 
If you want notifications about log file delivery and validation, you can set up Amazon SNS notifications.

Upload the data to S3 and set a lifecycle policy to transition data to Glacier after 0 days.
 
 
 
 
 
CloudHSM:
	Amazon strongly recommends that you use two or more HSMs, in separate Availability Zones, 
	in any production CloudHSM Cluster to avoid loss of cryptographic keys.





Access logs on the Application Load Balancer:
	Elastic Load Balancing provides access logs that capture detailed information about requests sent to your load balancer.
	Enable access logs on the Application Load Balancer. 

Integrate the ECS cluster with Amazon CloudWatch Application Insights to analyze traffic patterns and simplify troubleshooting.





Amazon FSx Windows File Server can scale out storage to hundreds of petabytes of data with tens of GB/s of throughput performance 
and millions of IOPS. 
Amazon EFS can only handle Linux workloads.





EKS cluster authentication:
	Kubernetes cluster and have role-based access control (RBAC) access to IAM users and roles for cluster authentication.
	single-digit millisecond latency:

Launch the application to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. 
Create node groups in Wavelength Zones for the Amazon EKS cluster via the AWS Wavelength service. 
Apply the AWS authenticator configuration map (aws-auth ConfigMap) to your cluster.

AWS Wavelength:
	AWS Wavelength combines the high bandwidth and ultralow latency of 5G networks with AWS compute and storage services 
	so that developers can innovate and build a new class of applications.

An Amazon EKS connector agent is only used to connect your externally hosted Kubernetes clusters and to allow them to be 
viewed in your AWS Management Console.
 
 
 
 
 
 
Network Firewall:
	Create a firewall using the AWS Network Firewall service at the VPC level then add custom rule groups for inspecting 
	ingress and egress traffic. Update the necessary VPC route tables.
	
Firewall must be created at the VPC level and not at the subnet level.
Network ACLs to control access to your subnets.
Security group for your EC2.	 
 
 
 
 
EC2 Terminating log save:
	Add a lifecycle hook to your Auto Scaling group to move instances in the Terminating state to the Terminating:Wait state 
	to delay the termination of unhealthy Amazon EC2 instances. 
	
Configure a CloudWatch Events rule for the EC2 Instance-terminate Lifecycle Action Auto Scaling Event with an associated Lambda. 
Trigger the CloudWatch agent to push the application logs and then resume the instance termination once all the logs are sent 
to CloudWatch Logs.





To collect logs from your Amazon EC2 instances and on-premises servers into CloudWatch Logs, AWS offers two options:
	Recommended – The unified CloudWatch agent.
	Supported, but deprecation – The older CloudWatch Logs agent(only Linux servers ).
	
Using  CloudWatch agent to collect metrics and logs from Amazon EC2 instances and on-premises servers.
Unified CloudWatch agent enables you to: 
	Collect internal system-level metrics from Amazon EC2 instances across operating systems also EC2 logs.
	
CloudWatch Agent enables you to collect and export host-level metrics and logs on instances running Linux or Windows server.





Dedicated physical server that doesn’t use virtualization,NFS protocol:
	Use an AWS Storage Gateway hardware appliance for your compute resources. 
	Configure File Gateway to store the application data and create an S3 bucket to store a backup of your data.

Among the AWS Storage Gateway storage solutions, only File Gateway can store and retrieve objects in S3 using the protocols NFS and SMB.

File Gateway is used to store and retrieve Amazon S3 objects through NFS and SMB protocols.

EFS for rapidly changing data and 1000 Linux servers.






There are two options for Volume Gateway iSCSI block :
	Cached Volumes – you store volume data in AWS, with a small portion of recently accessed data in the cache on-premises.
	Stored Volumes – you store the entire set of volume data on-premises and store periodic point-in-time backups (snapshots) in AWS.




By default, IAM users don’t have permission to create or modify Amazon EC2 resources or perform tasks using the EC2 API. 
(This means that they also can’t do so using the Amazon EC2 console or CLI.)
To allow IAM users to create or modify resources and perform tasks, you must create IAM policies that grant IAM users.






Messages are processed within a specific time period:
	Use a AMI to set up an Auto Scaling group and configure a target tracking scaling policy based on the
	SQS ApproximateAgeOfOldestMessage metric.

CPUUtilization metric is not meant for time-sensitive messages where you need to ensure that the messages are processed 
within a specific time period.

The ApproximateAgeOfOldestMessage metric is useful when applications have time-sensitive messages and you need to ensure 
that messages are processed within a specific time period. 





Due to S3 data volume, most queries take a long time to complete:
	Transform the JSON data into Apache Parque format. 
	Ensure that the user has an lakeformation:GetDataAccess IAM permission for underlying data access control.






ECS service’s memory and CPU utilization:
	Create an AWS Auto Scaling policy that scales out the ECS service when the service’s memory utilization is too high.
	Create an AWS Auto Scaling policy that scales out the ECS cluster when the cluster’s CPU utilization is too high.

ECS service and ECS container instance  metric are:

ECS Container Instances Metric:
	CPU Utilization
	Disk Reads
	Disk Read Operations
	Disk Writes
	Disk Write Operations
	Network In
	Network Out
	Status Check Failed (Any)
	Status Check Failed (Instance)
	Status Check Failed (System)
	
ECS Service Metric:
	ECSServiceAverageCPUUtilization—Average CPU utilization of the service.
	ECSServiceAverageMemoryUtilization—Average memory utilization of the service.
	
	
	
	
ALBRequestCountPerTarget—Number of requests completed per target in an Application Load Balancer target group.
By default, data records in Kinesis are only accessible for 24 hours from the time they are added to a stream.




ElasticBeanstalk, where does it store the application files and server log files?
	Application files are stored in S3. The server log files can also optionally be stored in S3 or in CloudWatch Logs.



CloudFront app Hig availability:The scenario uses an EC2 instance as an origin or CloudFront. 
	Provision two EC2 instances deployed in different Availability Zones and configure them to be part of an origin group.
	To achieve high availability in an EC2 instance, we need to deploy the instances in two or more Availability Zones. 
	You also need to configure the instances to be part of the origin group to ensure that the application is highly available.



S3 File Gateway presents  NFS and SMB protocols.
	Use an AWS Storage File gateway with enough storage to keep data from the last 48 hours. 
	Send the backups to an SMB share mounted as a local disk.

Owner full access to all uploaded objects in the S3 bucket by oterh user:
	Create a bucket policy that will require the users to set the object’s ACL to bucket-owner-full-control.





Amazon Pinpoint:
	Pinpoint is a flexible, scalable marketing communications service that connects you with customers over email, SMS, 
	push notifications, or voice.
	Amazon Pinpoint can send event data to Kinesis Data Firehose, which streams this data to AWS data stores such as 
	Amazon S3 or Amazon Redshift. 
	Amazon Pinpoint can also stream data to Kinesis Data Streams, which ingests and stores multiple data streams 
	for processing by analytics applications.

	The Amazon Pinpoint event stream includes information about user interactions with applications (apps) that you connect to 
	Amazon Pinpoint. 
	
It also includes information about all the messages that you send from campaigns, through any channel, and from journeys. 
This can also include any custom events that you’ve defined. 
Finally, it includes information about all the transactional email and SMS messages that you send.




With Application Load Balancers, cross-zone load balancing is always enabled.
With Network Load Balancers and Gateway Load Balancers, cross-zone load balancing is disabled by default. 

After you create the load balancer, you can enable or disable cross-zone load balancing at any time.

When you create a Classic Load Balancer, the default for cross-zone load balancing depends on how you create the load balancer. 
With the API or CLI, cross-zone load balancing is disabled by default. 
With the AWS Management Console, the option to enable cross-zone load balancing is selected by default.






On-Demand Capacity Reservations enable you to reserve compute capacity for EC2 instances in a specific Availability Zone for any duration. 
This gives you the ability to create and manage Capacity Reservations independently from the billing discounts offered 
by Savings Plans or Regional Reserved Instances.

When you create a Capacity Reservation, you specify:
	– The AvailabilityZone in which to reserve the capacity
	– The number of instances for which to reserve capacity
	– The instance attributes, including the instance type, tenancy, and platform/OS
 
On-Demand instances cannot reserve compute capacity at all.




Capacity error placement group :
	It is recommended that you launch the number of instances that you need in the placement group in a single launch request 
	and that you use the same instance type for all instances in the placement group.

	If you receive a capacity error when launching an instance in a placement group that already has running instances, 
	stop and start all of the instances in the placement group, and try the launch again. 

Restarting the instances may migrate them to hardware that has capacity for all the requested instances.





AWS Organization allows you to create SCPs that centrally control AWS service across multiple AWS accounts.





Reduce Cost:
	Deploy all the EC2 instances in the same Availability Zone. If you recall, data transferred between 
	EC2,  RDS,  Redshift,  ElastiCache instances, and Elastic Network Interfaces in the same Availability Zone is free. 

Instead of using the public network to transfer the data, you can use the private network to reduce the overall data transfer costs.

Could be charged with inter-Availability Zone data transfers if the instances are distributed across 
different availability zones.


You won’t be able to connect to your Amazon S3 bucket if you are using a private subnet unless you have a VPC Endpoint.
Private subnet connect S3 using vpc Endpoint.






Authenticate the users using Redis AUTH by creating a new Redis Cluster with both the 
	--transit-encryption-enabled and --auth-token parameters enabled.




In-flight data between your web servers and RDS should be secured:
	Force all connections to your DB instance to use SSL by setting the rds.force_ssl parameter to true. 
	Once done, reboot your DB instance.
	
	Download the Amazon RDS Root CA certificate. Import the certificate to your servers and configure your application to 
	use SSL to encrypt the connection to RDS.

There are 2 ways to use SSL to connect to your SQL Server DB instance:
	– Force SSL for all connections.
	– Encrypt specific connections.





RDS multiAZL:
– Increased database availability in the case of system upgrades like OS patching or DB Instance scaling.
– Provides enhanced database durability in the event of a DB instance component failure or an Availability Zone outage.

RDS synchronously replicates within same regin:
	RDS synchronously replicates the data to a standby instance in a different Availability Zone (AZ) that is in the same region.

By using cross-Region read replicas in Amazon RDS, you can create 
MariaDB, MySQL, Oracle, PostgreSQL, or SQL Server read replica in a different Region. (asynchronous replication)






Cross-account access to S3 objects:
	– IAM policies and resource-based bucket policies             for programmatic-only access to S3 bucket objects.
	– IAM policies and resource-based Access Control Lists (ACLs) for programmatic-only access to S3 bucket objects.
	– Cross-account IAM roles                                     for programmatic and console access to S3 bucket objects.

Not all AWS services support resource-based policies. 
Therefore, you can use cross-account IAM roles to centralize permission management when providing cross-account access 
to multiple services.





OpenSearch:
	Create an Amazon Comprehend analysis job. Index the sentiment along with the transcript to an Amazon OpenSearch cluster. 
	Visualize the results using the OpenSearch Dashboard.

The Amazon OpenSearch dashboard is a more suitable service to use than Grafana since the sentiment data is already processed 
by an Amazon OpenSearch cluster.





To enable the cross-region replication feature in S3, the following items should be met:
	The source and destination buckets must have versioning enabled and must be in different AWS Regions.
	Amazon S3 must have permission to replicate objects from that source bucket to the destination bucket on your behalf.





Deploy a conversational chatbot using Amazon Lex. 
Define conversation flow for specific user intentions. Integrate AWS Lambda functions as code hooks to perform actions 
based on user requests.

Comprehend is a natural language processing (NLP) service that uses machine learning to find insights and relationships in texts. 
It is not used to build chatbot applications.





Ingest/Consume the data using Amazon Kinesis Data Streams and create an AWS Lambda function to store the data in Amazon DynamoDB.

Amazon Redshift only  sub-second response times. 
Amazon DynamoDB Accelerator (DAX), microsecond response times.

Amazon Kinesis Data Firehose only supports  S3,  Redshift,  Elasticsearch, and an HTTP endpoint as the destination.






CloudFront Cache-Control:
	The Cache-Control and Expires headers control how long objects stay in the cache. 
	The Cache-Control max-age directive lets you specify how long (in seconds) you want an object to remain in the cache before 
	CloudFront gets the object again from the origin server. 

The minimum expiration time CloudFront supports is 0 seconds for web distributions and 3600 seconds (1Hr) for RTMP distributions.






Enable IAM cross-account access for all corporate IT administrators in each child account.
By setting up cross-account access in this way, you don’t need to create individual IAM users in each account. 

In addition, users don’t have to sign out of one account and sign into another in order to access resources that are 
in different AWS accounts.





AWS Consolidated Billing:
	Use AWS Consolidated Billing by creating AWS Organizations to link the divisions’ accounts to a parent corporate account.

You can use the consolidated billing feature in AWS Organizations to consolidate payment for multiple AWS accounts or
multiple AISPL accounts. 
With consolidated billing, you can see a combined view of AWS charges incurred by all of your accounts.


Tag Editor simply allows you to add, edit, and delete tags to multiple AWS resources at once for easier identification and monitoring.






Amazon Aurora replicas vs RDS replicas:
	The read replication latency of less than 1 second is only possible if you would use Amazon Aurora replicas.

Aurora replicas are independent endpoints in an Aurora DB cluster, best used for scaling read operations and increasing availability. 
You can create up to 15 replicas within an AWS Region.

RDS Read Replicas can only provide asynchronous replication in seconds and not in milliseconds.




High-frequency read and write operations handrad of ECS:
	ECS to access file system data across your fleet of Amazon ECS tasks.
	Amazon Elastic File System (Amazon EFS) provides simple, scalable file storage for use with your Amazon ECS tasks. 
	Launch an Amazon Elastic File System (Amazon EFS) with Provisioned Throughput mode and set the performance mode to Max I/O. 
	
	Configure the EFS file system as the container mount point in the ECS task definition of the Amazon ECS cluster.

EFS offers two performance modes:
	– General Purpose mode
	– Max I/O mode.
	
There are two throughput modes to choose from for your file system:
	– Bursting Throughput
	– Provisioned Throughput

Bursting Throughput mode won’t be able to sustain the constant demand of the global application. 
Need  Provisioned Throughput mode.


	
	
	
	
Cannot directly set a DynamoDB table as a container mount point:
	In the first place, DynamoDB is a database and not a file system which means that it can’t be “mounted” to a server.
 
 
 
 
 
Enable the EBS Encryption By Default feature for the AWS Region.
	Encryption By Default feature is a Region-specific setting and thus, you can’t enable it to selected EBS volumes only.

EBS encryption:
	– Encryption by default is a Region-specific setting. If you enable it for a Region, you cannot disable it for individual 
      volumes or snapshots in that Region.
	
	– When you enable encryption by default, you can launch an instance only if the instance type supports EBS encryption.
	– Amazon EBS does not support asymmetric CMKs.

Amazon EBS does not support asymmetric CMKs. To encrypt an EBS snapshot, you need to use symmetric CMK.

Amazon Elastic File System (EFS) doesn’t natively work with Amazon S3.
Amazon FSx for Lustre works natively with Amazon S3, a high-performance POSIX interface. 

 




Global Accelerator:
User->AWSEdgeNet->GlobalAcc->NLB/ALB/EC2

	Use AWS Global Accelerator create an endpoint with static IP for User and connect each AWS Region, then 
	Associate the Elastic Load Balancer from each region.
	
AWS Global Accelerator is a service that improves the availability and performance of your applications with local or global users. 
It provides static IP addresses that act as a fixed entry point to your application endpoints in a single or multiple AWS Regions, 
such as your Application Load Balancers, Network Load Balancers, or Amazon EC2 instances.

With AWS Global Accelerator, you can add or remove endpoints in the AWS Regions, run blue/green deployment, and A/B test 
without needing to update the IP addresses in your client applications. 

If you have multiple resources in multiple regions, you can use AWS Global Accelerator to reduce the number of IP addresses. 





Enhanced Networking:
	EC2 provides enhanced networking capabilities through the Elastic Network Adapter (ENA). 
	To use enhanced networking, you must install the required ENA module and enable ENA support.

	When you need a consistently lower inter-instance latencies.
	When you need a higher packet per second (PPS) performance and single root I/O virtualization (SR-IOV).





CloudFormation, a template:
In CloudFormation, a template is a JSON or a YAML-formatted text file that describes your AWS infrastructure:
	– Format Version
	– Description
	– Metadata
	– Parameters
	– Mappings
	– Conditions
	– Transform
	– Resources (required)
	– Outputs
	
	
	


EBS:
lessthen 1 minute.
What are types of EBS?
	General Purpose SSD.                =>Small to Medium db, boot volume, brodrang of work load.
	Provisioned IOPS SSD.               =>Consistent, low-letency performance and I/O Intensive app like Large Relationa or NoSQL DB.
	Magnetic:                           =>Data access infrequently, app where loest storage cont inportant.
	 ThroughputOptimized HDD/Cold HDD. (Latest low-cost Magnetic Storage)
     Previous generation Magnetic. (Old)


Amazon EBS Volume Types lists:
	General Purpose SSD: Maximum 10,000 IOPS/Volume
	Provisioned IOPS SSD: Maximum 20,000 IOPS/Volume
	Throughput Optimized HDD: Maximum throughput 500 MiB/s (Optimized for throughput rather than IOPS, good for large, contiguous reads)


Amazon EBS offers three types of Provisioned IOPS SSD volumes:
	Provisioned IOPS SSD (io2) volumes
	Provisioned IOPS SSD (io2) Block Express volumes
	Provisioned IOPS SSD (io1) volumes

IO2 volumes can deliver maximum of 500 IOPS per 1 GB where as IO1 volumes can deliver maximum of 50 IOPS per 1GB.
	io1 volume 1,280 GiB in size or greater (50 × 1,280 GiB = 64,000 IOPS)
	io2 volume 128 GiB in size or greater (500 × 128 GiB = 64,000 IOPS)
	
	50:1 for io1
	500:1 for io2
	
i2 instances=>deliver 350,000 random read IOPS and 320,000 random write IOPS.
i3 instances=>can deliver up to 3.3 million IOPS at a 4 KB block and up to 16 GB/second of sequential disk throughput.


	 
EBS Multi-attach only be enable on EBS Provisioned IOPS io1/io2 volumes not General purpose SSD.
EBS Multi-attach won’t offer Multi-AZ resiliency, this only allow EBS volume to be attached on Multiple intance within a single AZ.
 

AMI are categorized two type storage backed by(Store-Backed AMI):
	1) EBS.
	2) Instance Store.
	
AMI with EBS volume, created from an Amazon EBS Snapshot.
AMI is and Instance-Store volume, created from and template stored in Amazon S3.
	
Data of Instance store volumes persist only dureing the life of the instance.


EC2 instances support two types for block level storage: EC2 Instances can be launched using either EBS or 
Instance Store volume as root volumes and additional volumes.

EC2 instances can be launched by choosing between AMIs backed by EC2 instance store and AMIs backed by EBS.

Key points for Instance store backed Instance
	Boot time is slower then EBS backed volumes and usually less then 5 min.

EBS lessthen 1 minute.	
InstanceStore:
Lessthen 5 minute.
	There are three types of instance store volumes: ephemeral, non-volatile memory (NVMe) SSD, and TRIM

	



Network load balancer support Layer 4 traffic, and TCP,UDP,TLS protocol, ALB not support UDP.



Restart EC2 for error:
	 Look at CloudWatch logs for keywork or error, create a custom metric.
	 Then Create a CloudWatch alarm for that custom metric which invokes an action to restart the EC2.
You can create alarms that auto stop,terminate,reboot or recover EC2 instance using CloudWatch alarms action.

Flow logs are using VPC, not on specific EC2 instance.






AWS Server-Side Encryption:
	SSE-s3			=> Auto key rotates, No Audit trails show.
	SSE-KMS(CMKs)   => Auto key rotates, Protecton access, Audit trails show.
	SSE-C           => Auto key rotates, No Audit trails show.
	
	
	
	
Queue Message cant be duplicates tolerate:
	Use SQS FIFO or SWF (Simple Work Flow Services)
Altering Visibility timeout of SQS not guarantee message duplication.




Highly Scalable system with cost-effective:
	use AutoScaling SQS and EC2 for highly scalable distrubute system.
	
	
	
	
	
	
	
Get notify before 30 days of expration of SSL Certificates:
Two Way:
	First One: AWS ACM built-in certificate expiration event,which is raised throw Amazon EventBridge, to invoke a Lambda function.
	The funcation now can send notification using SQS or Security hub.
	
	Second one: Recent Lunch DaysToExpiry metric to schedule a batch search to expiring certificats and to log all finding.
	And Send Notification on SQS.
	
CloudWatch Event are truned into action using Amazon Eventbridge.
AWS health event are generated for ACM certificates that are eligibnle for renwwal.

EventProducer=>Event=>EventBridge=>rule=>ActionOnAWSServices(Lambda, Kisinsis, SQS)

AWS Ceritficate manager automatically generated AWS Health events. manually crateing a custom AWS Config rule to check
for SSL exprie is unnecessary. 
also AWS Config already provide a built-in acm-certiticate-expriration-check manage rule that can used, not need manually cration.






AutoScaling provides scaling plans for : EC2, SpotFleets,ECS Tasks (ECS Services or ECS Containers Instance), 
										 DynamoDB table and Index, Aurora Replics.
ECS Instance metrics:
	CPU Utilization
	DiskRead/Writes
	Network In/Out etc.
	
ECS Services metrics:
	ECSServiceAvaragesCPUUtilization
	ECSServicAvarageMemoryUtilization
	ALBRequestCoountPerTarget
	
AutoScaling not support any metrics from ALB.






RDS Mult-AZ deployment provide enhanced availability and durability for DB instance.
In case of Infrastructure failure or AZ fail:
	RDS perform an automatic failover to the standby Instance(Read Replica for Aurora. Endpoint remains same after failover.

RDS synchronously replicates the data to a standby instance in different AZ in same region not in a different region.





HPC, Natively workign with S3, POSIX interface=>FSx for Luster.
EFS, EBS, FSx for Windows: Not working with S3 easy way.

EFS=>NFS
FSx for Win=>SMB






AWS resource access share to different AWS account using cross-account acccess.
No need individual IAM user in each account.

AWS Organization Consolidate bill feature allow payment for multiple aws account or multiple AISPL acc.
Its for combined view of aws charge all account also get cost report for each member.

AWS Trusted advisor is an provides real-time guidance for best practices. Its not assist in maintaining goverence
over  AWS account.






Company Need to resuce IP address that need to regularly whitelist on corporate firewal:
	Use AWS Global Acclerator and Create and endpoint group for each AWS Region. Associate the ALB for each region to 
	the corresponding endpoin group.

Global Acclerator inporove application availabilithy and performance for local or global user.
It provide static IP that act as a fixed entry point to application endpoint in a single or multiple AWS Region
which application may backend by ALB,NLB or EC2.

For multiple resources in multiple region, use AWS Global Acclerator to reduce the number of IP address.
By Creating and endpoint group, you can add all of EC2 from a single region in that group.

No multiple endpoint for all the available AWS Region, better create one endpoint group for all region.

If multiple region rsourc then not use ALB for route traffic to multiple region Instead use AWS Global Acclearator.






Inspect Traffic In/Out of VPC: Use Network Firewall and add custom rule groups for inspecting traffic.

Only Traffic Mirroring filters can not inspect the actual packet within traffic, Its just copy network traffic
From and ENI.






Multiple Site-to-Site VPN connection slow for VPC and remote Network suring peak hours:
	Associate VPCs to and Equal Cost Multipath Routing ECMR-enable TransitGateway and attach additional VPN tunnels.
AWS transit Gateway enable you to scale the IPsec VPN throughput with equal-cost multi-pah ECMP routing support over 
multple VPN Tunnels.


At a time A VPC can only have have a single virtual private gateway attached to it, No multiple VPG not allow. 1 VPC = 1VPG
Maximum tunnel for a VPC connection is two by limit.




Amazon web services have mainly two dedicated managed services for workflow implementation.
	Simple Workflow Service (SWF)
	Step Functions


Simple Workflow Service (Amazon SWF) is a web service that makes it easy to coordinate work across distributed application components.
Amazon SWF, on the other hand, is a cloud-based service, allows common programming languages to be used, and lets developers 
control where tasks are processed.

A task is an invocation of a logical step in an Amazon SWF application. Amazon SWF interacts with workers which are programs 
that retrieve, process, and return tasks.


AWS Step Functions is a visual workflow service that helps developers use AWS services to build distributed applications, 
automate processes, orchestrate microservices, and create data and machine learning (ML) pipelines.
Your workflow can be visualized by state machines describing steps, their relationships, and their inputs and outputs.

Step Functions is a managed service, so users don't have to deploy or maintain any infrastructure for either the workflow management 
or the tasks themselves. 

SWF also manages workflow state in the cloud. However, unlike Step Functions, a user has to manage the infrastructure 
that runs the workflow logic and tasks.





VPC Inter-region private communication (VPC peering):
	Setup a VPC peering connection between VPCs.
	Re-config the route table targete and destination of the instance subnet.
	
VPC endpoint not needed becos VPCEndpoint are region specific only. Not support inter-region communicaton.

In VPC peering enables route traffic between them using private IPv4 or IPv6 like there in a single private network.
VPC peering cand own VPC, other account VPC, VPC can be different region.
Inter-region vpc peering encryps traffic, never travel public network.





Low inter-instance latencies with Windows server (SR-IOV):
	Enable Enhanced Netwoiking with ElasticNetwork Adapter (ENA) on the Windows EC2 instance.

Enhanced Netwoiking privides high bandwdith, higher packet per second (PPS) performance and consistently lower inter-instance latencies.
With No cost. using single root I/O vertulazation (SR-IOV), 100Gbps.

Elastic Fabric Adapter EFA  not support OS-bypass capabilitess for Windows Instance it will work as ENA.

AWS ParalledClusterr just a AWS-support open-source cluster management tools, Its for deploy manage HPC.
Its not provided high branwith,PPS and lower inter-instance latencies as ENA or EFA.




Config DNS zone apex record to point load balancer:
	Create and A record aliesed to the load balancer DNS name.

Use and Alias record pointing to the DNS name of Loadbalancer not IP, since the IP address of the Load balancer can change at any time.

CNAME record cannot be creaed for your zone apex, create alies record at the top node of DNS as zone apex.





Track AWS resources uses for quotas unexpectdly:
	Writge and Lambda function that refreshs tha AWS Trusted Advisor Service Limits checks and set it to run every 24 houts.
	Capture the events using Amazon EventBridge (CloudWatch Event) and use an SNS topic as the target for notifications.
	
	
AWS Trusted Advisor provide best practices from hundreds of thousands of AWS customer.
Trusted Advisor inspects your AWS environment make recommendatins for save money, inprove system availability, security Gap.

AWS has and example of the implemenation of Quota Monitoring CloudFormaton template that cand deploy on AWS account.
The Template uses a Lambda funcaton that runs onece every 24 hour and refresh Trusted advisor service Limits check quota throw API call.
CloudWatch event capture the status events from Trusted advisor, send status to targets SQS, SNS, lambda for Slack notification.
Trusted advisor services limit publish services limit metric to CloudWatch, config alarm and send notification to SNS or Lembda.

Trusted dAdvisor APIs are only available for Business, Enterprise On-Ramp or Support plans. (DescribeTrustedAdvisorChecks API)
Its Return all avalilable Trusted advisor check info, so its will be dificult to extract only "service limits" info from thsi api.






From S3 to Standard IA and OneZone IA need to stay data in current class more 30 days, not for Intelligence,Glacier or DepArch.
For surprice check for audit then need to with in 1 minute then use Glaicer. Ite  provide quick acc (1-5mm).
Deep Archive need several hours.

If you dont know the acccess time schedule or frequently change then use Intelligence class for save cost.

S3 proivides 3500(PUT) request per second to add data and 5500 read data (GET) default. Per prefix.
For parallel permormance to scale more request use prefix, S3 scale performance per prix.






Encrypted at rest, full control over the encryption key, immedit remove material from the AWS KMS, audit using CloudTrails:
	use Aws key Management Service to Create a CMK in a custom key store and store the non-extractable key material in CloudHSM.

A Custom key (KMS) store CloudHSM. For immeditely remove the key meterial from AWS KMS use a custom key Store.

Use Custom key Store (CloudHSM) for:
	Direct control.
	Immediatly remove key metatial from KMS and independently.
	Audit all use of keys independently from of KMS and CloudTrail.
	
AWS-owned CMK and AWS-manageed CMK are manage by AWS.





Many Employee need to granted to a S3 for there personal document:
	Config and IAM role and IAM Policy to access S3 Bucket.
	Setup a Federation proxy or and Identity provider and use AWS Security Token Service to generate Temp Token.
	
	
	


Prevent S3 photo link used by other company:
	Remove S3 public read access and use pre-signed URLs with expriy dates.
	




Prevent backend system from traffic spikes:
	Enable throttling limits and result caching in API Gateway.
API Gateway provide throttling (rate limit 1000 request per second), and caching to API call by TTL also invalid the cache.

	
	
	
	

A logging system for all change madb to AWS resource in all Region also provide and event history of api calls in MConsole and CLI:
	Setup CloudTrail trail in S3 using cli and pass --is-multi-region-trail and --include-global-service-event parameter.
	With KMS encryption MFA and bucket policy.
Not CloudWatch use CloudTrails.


CloudTrails record all activity of and account by MConsole, SDK,CLI and other AWS Services by user,role and services.
ClousTrails trails all region by default when create trail using MConsole, but in CLI need to pass parameter  --is-multi-region-trail.

By Default CloudTrails cover the activities of regional services(EC2,S3,RDS etc) not for global services.
For Global services (IAM CloudFront,WAF, Route53) in CLI mode add parameter --include-global-service-event parameter.







Aurora Custome endpoint:
	A Custome endpoint For different purpose (Read Only or read-write ) you can map each connect to a specific instance or a 
	Group of Instance.Base on usecase, of your requirment.

Aurora Cluster endpoint (also call writer endpoint) made from primary DB instance what is best for product traffic not for Repoting.
Use Custome endpoint for Repoting.

Create a custome endpoint in Aurora base on the specified criteria for product traffic and another custome end point for repoting.
Aurora involved a cluster of DB Instance not single instance. Each conn is handled by specific DB Instance.





Availabel in case of Oracle Database failure in future:
	Create Oracle database in RDS with Multi-AZ deployment.

Oracle RMAN and RAC are not supported in RDS.






Linux and Windows EC2 monitor for memory and disk Utilization metrics:
	Install CloudWatch agent to all EC2, View the custome metrics in CloudWatch console.
	
Enhanced Monitoring is a feature of RDS and By Default stored metrics for 30 days in CloudWatch logs.
And 
Detailed Monitoring for EC2. Detailed monitoring delivers metrics in 1-minute intervals, rather than 5-minute intervals.	






Handel Unpredictable transactional workload and autoscales capacity and peak load scales DB:
	Lunch and Autora Serverless DB cluster then set the minumum and maximum capacity for the cluster.
	
Aurora Serverless is and on-demand, auto-scaling configuration for Aurora.
Non-Serverless DB cluster of Autora called provisioned DB Cluster.

Both Provision DB and Serverless carry same of feature like: scale, permormance dustributed all two are same.

But Provisioning DB cluster for where you can predicatable workload and you cand adjust the capacity manually base on workload.
Where Serverless for un-predicatable workload.

	
	
	
	

Both historical record and frequently data are store on on-permises storage system what is going low capacity 
	Need to move Historical data:
	Use AWS DataSync to move historical data to AWS, choose S3Glacier Deep Archive to destination.

Storage Gateway mainly prividing low-latency access to data by caching frequently acc data on-premises and Archive data on Cloud Storage.
Storage Gateway optimizes data transfer to AWS by sending only change data and compressing data.








What needs outside of VPC for site-to-site VPN Conn:
	An Inter-routeable IP(Public IP/Static) of the customer gateway external interface for on-permises network.
	
Required For communication with own network using VPN:
	Attach a VPG virtual private gateway to VPC
	Create a custom route table
	Update SecurityGroup
	A public IP on-permises side
	A Customer Gateway on on-permise side(physical or software)

	
IPv6 not support by EC2 classic.

Fault tolerance for DirectConnectConnection to VPC:
	Establish a hardware VPN over Internet bwtween VPC and on-permises.
	Establish another DirectConnectConnection and Private Virtual Interface in same AWS region as VPC1.
	
CustomerNetwork=>DirectConnectConnection=>VIF=>DirectConnectGateway=>VGW=>VPC.

A virtual interface (VIF) is necessary to access AWS services, either public or private. 
	A public virtual interface enables access to public services, such as Amazon S3. 
	A private virtual interface enables access to your VPC.
	
	
	





A large portion of traffice from Philipnd and Indai will be route to resourde ap-northest-1 region:
	Use Reoute53 Geoproximity Routing.
	
Route53 Routing:
	Latency Routing:      Provide lowest latenct for resources, not guarantee user and resource will be same location.
	Geoproximity Routing: Route traffic using user and resource GeoLocation also with a Bias value for more/less traffic to a resource.
	Geolocation Routing:  GeoLocation of user base routing. Serve resource from the DNS queres origin from.
	Weighted Routing:     Multi resource associat with single domain name and set how much traffic to go each resource.
	
	
	
	

Publish events when an object is deleted or a versioned object is permanently deleted:
	Create a SNS topic and SQS. add and S3 Event notification confg on bucket to publish S3:ObjectCreated:* and 
	S3:ObjectRemoved:Delete event type to SQS and SNS.
	
s3:ObjectRemoved:Delete event for send nofification for version/non version permanently deleted.
ObjectRemoved:DeleteMarkerCreated: a new version created.

S3 can publish notifications for the following events:
	1. New object created events
	2. Object removal events
	3. Restore object events
	4. Reduced Redundancy Storage (RRS) object lost events
	5. Replication events

S3 supports the following destinations where it can publish events:
	1. SNS topic
	2. SQS queue
	3. Lambda
S3 does support Amazon MQ as a destination to publish events.

To avoid loging loop, use two buckets, or configure the trigger to only apply to a prefix used for incoming objects.




S3 protecting data at rest:
	Server-Side Encryption – You request Amazon S3 to encrypt your object before saving it on disks in its data centers and 
	decrypt it when you download the objects.
		Use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3)
		Use Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS)
		Use Server-Side Encryption with Customer-Provided Keys (SSE-C)
		
	Client-Side Encryption – You can encrypt data client-side and upload the encrypted data to Amazon S3. 
	In this case, you manage the encryption process, the encryption keys, and related tools.
		Use Client-Side Encryption with AWS KMS–Managed Customer Master Key (CMK)
		Use Client-Side Encryption Using a Client-Side Master Key

SSE-S3 is S3 managed key is fully managed by AWS and also rotates the key automatically and 
Customer master key (CMK) in AWS KMS that you can manage, rotate, and audit or alternatively, use a client-side master key 
that you manually maintain.








Concerned about the over-provisioning of the resources by ASG:
	Use target tracking scaling.
	
With a target tracking scaling policy, you can increase or decrease the current capacity of the group based on a 
target value for a specific metric. This policy will help resolve the over-provisioning of your resources.
	

Simple scaling: 
	Need to wait for the cooldown period to complete before initiating additional scaling activities. 
	
Target tracking or step scaling policies can trigger a scaling activity immediately without waiting for the 
cooldown period to expire.

Scheduled scalingis: 
	Mainly used for predictable traffic patterns. You need to use the target tracking scaling policy to optimize the 
	cost of your infrastructure without affecting the performance.






For Role-based access control. Currently, the roles are already assigned using groups in the corporate Active Directory:
	 AWS Directory Service AD Connector
	 IAM Roles

Take note that you can assign an IAM Role to the users or groups from your Active Directory once it is integrated with your 
VPC via the AWS Directory Service AD Connector.







AWS Fargate to run a batch job whenever an object is uploaded to S3:
	 Set up EventBridge rule to detect S3 object PUT operations and set the target to the ECS cluster to run a new ECS task.

EventBridge rule for detect all services level event.
It uses data from your own applications, integrated SaaS applications, and AWS services. 

EventBridge rule can runs an Amazon ECS task against a event, ECS tasks directly as targets for the CloudWatch Event rule.





 
Application is slow during the start of the day but then works normally after a couple of hours:
	Configure a Scheduled scaling policy for the Auto Scaling group to launch new instances before the start of the day.

The scheduled action tells Amazon EC2 Auto Scaling to perform a scaling action at specified times.
To create a scheduled scaling action, you specify the start time when the scaling action should take effect, and the new 
minimum, maximum, and desired sizes for the scaling action. 

At the specified time, Amazon EC2 Auto Scaling updates the group with the values for minimum, maximum, and desired size 
specified by the scaling action. 
 




Notify the development and operations team about the created or deleted S3 objects:
	Create an Amazon SNS topic and configure two Amazon SQS queues to subscribe to the topic. 
	Grant Amazon S3 permission to send notifications to Amazon SNS and update the bucket to use the new SNS topic.	

Take note that Amazon S3 event notifications are designed to be delivered at least once and to one destination only. 
You cannot attach two or more SNS topics or SQS queues for S3 event notification. 
Therefore, you must send the event notification to Amazon SNS.






Amazon storage services should Hot and Cold storage:
	Use Amazon FSx For Lustre and Amazon S3 for hot and cold storage respectively.

Although EFS supports concurrent access to data, it does not have the high-performance ability that is required for 
machine learning workloads.
FSx For Windows File Server does not have a parallel file system, unlike Lustre.

Hot storage refers to the storage that keeps frequently accessed data (hot data). 
Warm storage refers to the storage that keeps less frequently accessed data (warm data). 
Cold storage refers to the storage that keeps rarely accessed data (cold data). 
	
Amazon FSx For Lustre is a high-performance file system for fast processing of workloads. Lustre is a popular open-source 
parallel file system which stores data across multiple network file servers to maximize performance and reduce bottlenecks.

Amazon FSx for Windows File Server is a fully managed Microsoft Windows file system with full support for the SMB protocol, 
Windows NTFS, Microsoft Active Directory (AD) Integration.

Amazon Elastic File System is a fully-managed file storage service that makes it easy to set up and scale file storage in 
the Amazon Cloud. 

Amazon S3 is an object storage service that offers industry-leading scalability, data availability, security, and performance.







Improve DynamoDB performance by distributing the workload evenly and using the provisioned throughput efficiently:
	 Use partition keys with high-cardinality attributes, which have a large number of distinct values for each item.

Remember that the more distinct partition key values your workload accesses, the more those requests will be spread across the 
partitioned space. 

Conversely, the less distinct partition key values, the less evenly spread it would be across the partitioned space, 
which effectively slows the performance

A composite primary key will provide more partition for the table and in turn, improves the performance.
	 
	 
	 

	 
There are three main parts in a distributed messaging system:
	1. The components of your distributed system (EC2 instances)
	2. Your queue (distributed on Amazon SQS servers)
	3. Messages in the queue.	 







EBS:
	Although an EBS Volume can be attached to multiple EC2 instances, Instance and EBS must be in same AZ. 
	What we need is high-available storage that can span multiple availability zones.

EFS:
	Multiple Amazon EC2 instances can access an Amazon EFS file system at the same time, allowing Amazon EFS to provide a common 
	data source for workloads and applications running on more than one Amazon EC2 instance.
EFS only supports Linux workloads.

Amazon EFS provides two modes of throughput: Provisioned and Bursting. 
EFS provides two classes of storage: One Zone and Standard. EFS Lifecycle.

EFS file systems can be accessed by Amazon EC2 Linux instances, Amazon ECS, Amazon EKS, AWS Fargate, 
and AWS Lambda functions via a file system interface such as NFS protocol.
Mult-AZ

FSx for Lustre: 
	For machine learning model, Which scales to hundreds of gigabytes every second and sub-millisecond latencies.
	FSx for Lustre is designed to support any Linux workload and is POSIX-compliant.
FSx for Lustre automatically encrypts your information in-transit and at-rest, and is ISO, SOC, and PCI-DSS compliant.

Amazon FSx for Lustre also integrates with Amazon S3.
FSx for Lustre can only be used by Linux-based instances.
Mult-AZ

FSx for NetApp ONTAP:
	FSx for ONTAP delivers NFS, SMB and iSCSI storage powered by NetApp’s advanced data management system.
	Multiprotocol file and block storage support.
	High availability across multi-AZs.
Mult-AZ








DynamoDB event notified via email:
	 Enable DynamoDB Stream and create an AWS Lambda trigger, as well as the IAM role which contains all of the permissions that 
	 the Lambda function will need at runtime. The data from the stream record will be processed by the Lambda 
	 function which will then publish a message to SNS Topic that will notify the subscribers via email.

Remember that the DynamoDB Stream feature is not enabled by default. 
	 
	 





Wants a high-performing solution to migrate this workload to the AWS cloud to take advantage of the cloud’s high availability:
	 Migrate the Oracle database to Amazon RDS for Oracle in a Multi-AZ deployment by using AWS Database Migration Service (AWS DMS).
	 Rehost the on-premises .NET application to an AWS Elastic Beanstalk Multi-AZ environment which runs in multiple Availability Zones.

DMS:
AWS Database Migration Service (AWS DMS) is a cloud service that makes it easy to migrate relational databases, data warehouses, 
NoSQL databases, and other types of data stores. 
You can use AWS DMS to migrate your data into the AWS Cloud or between combinations of cloud and on-premises setups.

With AWS DMS, you can perform one-time migrations, and you can replicate ongoing changes to keep sources and targets in sync.
Migrate to a different database engine use Schema Conversion Tool (AWS SCT).


AWS ElasticBeanstalk reduces management complexity without restricting choice or control. 
	You simply upload your application, and Elastic Beanstalk automatically handles the details of capacity provisioning, 
	load balancing, scaling, and application health monitoring.
	Elastic Beanstalk supports applications developed in Go, Java, .NET, Node.js, PHP, Python, and Ruby.


AWS Application Migration Service (AWS MGN) to migrate the on-premises Oracle database server to a new Amazon EC2 instance.
Amazon RDS supports standard Oracle databases so it would be better to use AWS DMS for the database migration, not AWS MGN.







Users take a lot of time to log into their website and HTTP 504 errors:
	Customize the content that the CloudFront web distribution delivers to your users using Lambda@Edge, which allows your 
	Lambda functions to execute the authentication process in AWS locations closer to the users.
	
	Set up an origin failover by creating an origin group with two origins. Specify one as the primary origin and the other 
	as the second origin which CloudFront automatically switches to when the primary origin returns specific HTTP status code 
	failure responses.
	 
	 



Query data that resides in multiple AWS accounts from a central data lake:
	 Use AWS Lake Formation to consolidate data from multiple accounts into a single account.
A data lake enables you to break down data silos and combine different types of analytics.

AWS Lake Formation is integrated with AWS Glue which you can use to create a data catalog that describes available datasets and 
their appropriate business applications.
Cross-account sharing which is free with AWS Lake Formation.





AWS resources centrally manage and share with multiple account:
	Use the AWS Resource Access Manager (RAM) service to easily and securely share your resources with your AWS accounts. 
	Consolidate all of the company's accounts using AWS Organizations.

AWS Organizations is an account management service that lets you consolidate multiple AWS accounts into an organization that you 
create and centrally manage.

AWS Control Tower simply offers the easiest way to set up and govern a new, secure, multi-account AWS environment. 
This is not the most suitable service to use to securely share your resources across AWS accounts or within your Organization. 
You have to use AWS Resources Access Manager (RAM) instead.





Aurora data-modifying info forwarded to a distributed processing system:
	Create a native function or a stored procedure that invokes a Lambda function. Configure the Lambda function to send event 
	notifications to an Amazon SQS queue for the processing system to consume.


RDS events only provide operational events such as DB instance events, DB parameter group events, DB security group events, and 
DB snapshot events. 
What we need  data-modifying events (INSERT, DELETE, UPDATE) which can be achieved thru native functions or stored procedures.






Use VPC endpoints to route all access to S3 and DynamoDB via private endpoints.

Transit Gateway simply connects your VPC and on-premises networks through a central hub. 
It acts as a cloud router that allows you to integrate multiple networks.





RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone.
RDS Read Replica provides an asynchronous replication instead of synchronous.

DynamoDB do not have a Read Replica approach.
Global tables replicate your DynamoDB tables automatically across  Regions.





Monitor how the different processes or threads on a DB instance use the CPU, including the percentage of the 
CPU bandwidth and total memory consumed by each proces:
	Enable Enhanced Monitoring in RDS.

By default, Enhanced Monitoring metrics are stored in the CloudWatch Logs for 30 days. To modify the amount of time the 
metrics are stored in the CloudWatch Logs, change the retention for the RDSOSMetrics log group in the CloudWatch console.

Differences between CloudWatch and Enhanced Monitoring Metrics:  
	CloudWatch gathers metrics about CPU utilization from the hypervisor for a DB instance, and 
	Enhanced Monitoring gathers its metrics from an agent on the instance. 

To get the specific percentage of the CPU bandwidth and total memory consumed by each database processes:
	Use Enhanced Monitoring metrics.
 
 
 
 
 
Move the files that are older than 2 years to a more cost-effective and scalable solution:
	The requirement is to move the files that are older than 2 years or 730 days, use  S3 Glacier after 2 years or S3 Standard-IA.
	
Maximum days for the EFS lifecycle policy is only 90 days. 





You can also sell your unused instance for Standard RIs but not Convertible RIs on the Reserved Instance Marketplace.
You can reserve capacity to a specific AWS Region (regional Reserved Instance) or specific 
Availability Zone (zonal Reserved Instance) only. 
You cannot reserve capacity to multiple AWS Regions in a single RI purchase.





Need a DB with unpredictable transactional workloads throughout:
	Launch an Amazon Aurora Serverless DB cluster then set the minimum and maximum capacity for the cluster.

Aurora without Aurora Serverless (provisioned DB clusters) works well when the database workload is predictable, 
because you can adjust capacity manually based on the expected workload.




Mitigate multi-region failure lessthen 1m for RTO and RPO:
	Amazon Aurora Global Database.
	
Amazon Aurora Global Database is designed for globally distributed applications, allowing a single Amazon Aurora database 
to span multiple AWS regions. It replicates your data with no impact on database performance, 
enables fast local reads with low latency in each region, and provides disaster recovery from region-wide outages.

RDS Multi-AZ deployment is only applicable inside a single region and not in a multi-region setup.





Launch a new file gateway that connects to your on-premises data center using AWS Storage Gateway. 
Upload the documents to the file gateway and set up a lifecycle policy to move the data into Glacier for data archival.

File gateway provides access to objects in S3 as files or file share mount points. With a file gateway, you can do the following:
	- You can store and retrieve files directly using the NFS version 3 or 4.1 protocol.
	- You can store and retrieve files directly using the SMB file system version, 2 and 3 protocol.
	- You can access your data directly in Amazon S3 from any AWS Cloud application or service.
	- You can manage your Amazon S3 data using lifecycle policies, cross-region replication, and versioning. 

You can think of a file gateway as a file system mount on S3.

AWS Storage Gateway supports S3 Standard, S3 Standard-IA, S3 One Zone-IA and Amazon Glacier storage classes.







RDS database can only be accessed using the profile credentials specific to your EC2 instances via an authentication token:
	Enable the IAM DB Authentication.
	
IAM database authentication provides the following benefits:
	Network traffic to and from the database is encrypted using Secure Sockets Layer (SSL).
	You can use IAM to centrally manage access to your database resources, instead of managing access individually on each DB instance.
	For applications running on Amazon EC2, you can use profile credentials specific to your EC2 instance to access your database

Although STS is used to send temporary tokens for authentication, this is not a compatible use case for RDS.


	 
 
Client-side encryption is the act of encrypting data before sending it to Amazon S3 are two way:
- Use an AWS KMS-managed customer master key.
- Use a client-side master key.

When using an AWS KMS-managed customer master key to enable client-side data encryption, you provide an 
AWS KMS customer master key ID (CMK ID) to AWS. 

When you use client-side master key for client-side data encryption, your client-side master keys and your unencrypted data 
are never sent to AWS. 





Enable Cross-origin resource sharing (CORS) configuration in the bucket.
	Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact 
	with resources in a different domain.




Secure the session data in the portal by requiring them to enter a password before they are granted permission to execute Redis commands:
	 Authenticate the users using Redis AUTH by creating a new Redis Cluster with both the 
	 --transit-encryption-enabled and 
	 --auth-token parameters enabled.
	 
	 
	 
	 

Database hostname-credentials, API credentials that prevent other developers access DEV, SIT, UAT, and PROD environments:
	Create a new KMS key and use it to enable encryption helpers that leverage on AWS Key Management Service to store and 
	encrypt the sensitive information.
	
Although Lambda encrypts the environment variables in your function by default, the sensitive information would still be 
visible to other users who have access to the Lambda console. This is because Lambda uses a default KMS key to encrypt 
the variables, which is usually accessible by other users. 

The best option in this scenario is to use encryption helpers to secure your environment variables.





Use the AWS Systems Manager Parameter Store to keep the database credentials and then encrypt using AWS KMS. 
	Create an IAM Role for your Amazon ECS task execution role (taskRoleArn) and reference it with your task definition, 
	which allows access to both KMS and the Parameter Store. 

Within your container definition, specify secrets with the name of the environment variable to set in the container 
and the full ARN of the Systems Manager Parameter Store parameter containing the sensitive data to present to the container.

Amazon Elastic Container Service (ECS) Anywhere is just a feature of Amazon ECS that enables you to easily run and manage 
container workloads on customer-managed infrastructure.




A report of all compliance-related documents for their account:
	Use AWS Artifact to view the security reports as well as other AWS compliance-related information.
 

AWS Artifact is your go-to, central resource for compliance-related information that matters to you. 
It provides on-demand access to AWS’ security and compliance reports and select online agreements. 

Reports available in AWS Artifact include our Service Organization Control (SOC) reports, Payment Card Industry (PCI) reports,
Business Associate Addendum (BAA) and the Nondisclosure Agreement (NDA).

	 
	 
	 
	 
	 
Even though AWS WAF can help you block common attack patterns to your VPC such as SQL injection or cross-site scripting, this is 
still not enough to withstand DDoS attacks. It is better to use AWS Shield.

Create a rate-based rule in AWS WAF and associate the web ACL to an Application Load Balancer.
a regular rule only matches the statement defined in the rule. If you need to add a rate limit to your rule, you should create a 
rate-based rule.

AWS Network Firewall is a managed service that is primarily used to deploy essential network protections for all of your VPCs 
and not particularly to your Application Load Balancers.






Storage solution to a specific Amazon VPC only:
	Configure an Amazon S3 Access Point for the S3 bucket to restrict data access to a particular Amazon VPC only.
	Create a new Amazon S3 bucket with the S3 Object Lock feature enabled. Store the documents in the bucket and set the 
	Legal Hold option for object retention.
Access points are named network endpoints that are attached to buckets.	 
S3 Multi-Region Access Points to provide a global endpoint that applications.	 

Before you lock any objects, you have to enable a bucket to use S3 Object Lock. 
When you create a bucket with Object Lock enabled, you can't disable Object Lock or suspend versioning for that bucket.
 
Object Versioning feature must also be enabled too in order for this to work. 
In fact, you cannot manually disable the Object Versioning feature if you have already selected the Object Lock option.





 
Amazon Macie generates two categories of findings: policy findings and sensitive data findings. 
	A policy finding is a detailed report of a potential policy violation or issue with the security or privacy of an  S3 bucket.
	A sensitive data finding is a detailed report of sensitive data in an S3 object.

Amazon Macie is an ML-powered security service that helps you prevent data loss by automatically discovering, classifying, 
and protecting sensitive data stored in Amazon S3. Amazon Macie uses machine learning to recognize sensitive data such as 
personally identifiable information (PII) 
  
Amazon Kendra is just an enterprise search service that allows developers to add search capabilities to their applications. 




 
Asynchronously process the request:
	Replace the Kinesis Data Streams with an Amazon SQS queue. Create a Lambda function that will asynchronously process the requests.

AWS Lambda supports the synchronous and asynchronous invocation of a Lambda function. 

Kinesis Data Streams is a real-time data streaming service that requires the provisioning of shards. Amazon SQS is a cheaper option 
because you only pay for what you use. Since there is no requirement for real-time processing in the scenario given, replacing 
Kinesis Data Streams with Amazon SQS would save more costs.


AWS Step Functions is a serverless orchestration service that lets developers create and manage multi-step application workflows 
in the cloud.
AWS Step Functions is a visual workflow service.
Step F.unctions is a managed service, so users don't have to deploy or maintain any infrastructure

Amazon SWF is a fully managed workflow service for building scalable, resilient applications.
User has to manage the infrastructure that runs the workflow logic and tasks.

If you require external signals (deciders) to intervene in your processes, or you would like to launch child processes that 
return a result to a parent, then you should consider Amazon SWF.








A report that summarizes the total billing accrued by each department:
	Tag resources with the department name and enable cost allocation tags.

After you or AWS applies tags to your AWS resources (such as  EC2  or  S3 buckets) and you activate the 
tags in the Billing and Cost Management console, AWS generates a cost allocation report as a comma-separated value (CSV file) 
with your usage and costs grouped by your active tags.

AWS Budgets only allows you to be alerted and run custom actions if your budget thresholds are exceeded.

Cost and Usage Report (CUR) provid cost by AWS services.






Architect has decided to move the historical records to AWS :
	Use AWS DataSync to move the historical records from on-premises to AWS. Choose Amazon S3 Glacier Deep Archive to be the 
	destination for the data.


Getting started with DataSync is easy: deploy the DataSync agent, connect it to your file system, select your AWS storage resources, 
and start moving data between them. You pay only for the data you move(online).
You can use DataSync to migrate active data sets or archives to AWS.


Amazon Managed Service for Prometheus is a Prometheus-compatible monitoring and alerting service. 
This service makes it easy for you to monitor containerized applications and infrastructure at scale but not stream live feeds.







Set up AWS Proton for deploying container applications and serverless solutions. 
Create components from the AWS Proton console and attach them to their respective service instance.

AWS Proton allows you to deploy any serverless or container-based application with increased efficiency, consistency, and control. 
You can define infrastructure standards and effective continuous delivery pipelines for your organization. 

Proton breaks down the infrastructure into environment and service (“infrastructure as code” templates).
With a component, a developer can add supplemental resources to their application.

SQS and  SWF are the services that you can use for creating a decoupled architecture in AWS.





Create an Amazon EMR cluster and store the processed data in Amazon RedShift.
	Amazon EMR (previously known as Amazon Elastic MapReduce) is an Amazon Web Services big data tool for processing and analysis.

	Amazon EMR is a managed cluster platform that simplifies running big data frameworks, such as Apache Hadoop and Apache Spark, on 
	AWS to process and analyze vast amounts of data. 


	Amazon Redshift is the most widely used cloud data warehouse. 
	It makes it fast, simple and cost-effective to analyze all your data using standard SQL and your existing 
	Business Intelligence (BI) tools.

To leverage big data processing frameworks, you need to use Amazon EMR. The cluster will perform data transformations (ETL) 
and load the processed data into Amazon Redshift for analytic and business intelligence applications.
 
Glue is just a serverless ETL service that crawls your data, builds a data catalog, performs data preparation, data transformation, 
and data ingestion. It won't allow you to utilize different big data frameworks effectively, unlike Amazon EMR.
  






MySQL database that needs to be replicated in Amazon S3 as CSV file:
	Create a full load and change data capture (CDC) replication task using AWS Database Migration Service (AWS DMS). 
	Add a new Certificate Authority (CA) certificate and create an AWS DMS endpoint with SSL.




Compliance requirements in these two locations, you want the Japanese users to connect to the servers in the 
ap-northeast-1 Asia Pacific (Tokyo) region, while the Swedish users should be connected to the servers in the eu-west-1 EU (Ireland).
	Use Route 53 Geolocation Routing policy.
	



Route 53 Weighted Routing policy:
		It just lets you associate multiple resources with a single domain name (tutorialsdojo.com) or 
		subdomain name (forums.tutorialsdojo.com) and choose how much traffic is routed to each resource. 
		
		
		

On-premises web service clients can only access trusted IP addresses whitelisted on their firewalls:		
	 Associate an Elastic IP address to a Network Load Balancer.
	 You can't assign an Elastic IP address to an Application Load Balancer.

	
	
	
Secure, Reliable and Scalable Access to Applications From Anywhere.
Amazon AppStream 2.0 is a fully managed application streaming service that provides users with instant access to their desktop 
applications from anywhere. 

AppStream 2.0 manages the AWS resources required to host and run your applications, scales automatically, 
and provides access to your users on demand.






Preventing database calls from traversing the public internet. An automated cross-account backup for the DynamoDB table:
	Create a DynamoDB gateway endpoint. Associate the endpoint to the appropriate route table. Use AWS Backup to automatically 
	copy the on-demand DynamoDB backups to another AWS account for disaster recovery.

DynamoDB on-demand backups cannot be copied to a different account or Region.
	
To create backup copies across AWS accounts and Regions and for other advanced features, you should use AWS Backup.	
Point-in-Time Recovery (PITR) feature is not capable of restoring a DynamoDB table to a particular point in time in a different 
AWS account.





(Simple Email Service) SES is a cloud-based email sending service designed to send notifications and transactional emails.
Use SNS instead of SES  when you want to monitor your EC2 instances.	
	
	


Here are the prerequisites for routing traffic to a website that is hosted in an Amazon S3 Bucket:
- An S3 bucket that is configured to host a static website. The bucket must have the same name as your domain or subdomain. 
- A registered domain name. You can use Route 53 as your domain registrar, or you can use a different registrar.
- Route 53 as the DNS service for the domain. 





Use Amazon Rekognition to detect images with graphic nudity or violence in Amazon S3. 
Create an Interface VPC endpoint for Amazon Rekognition with the necessary policies to prevent any traffic from traversing the 
public Internet.

To connect your VPC to Amazon Rekognition, you define an interface VPC endpoint for Amazon Rekognition. An interface 
endpoint is an elastic network interface with a private IP address that serves as an entry point for traffic destined to a supported 
AWS service.

Amazon GuardDuty is primarily used as an intelligent threat detection solution and not a networking service.

Amazon Detective is commonly used to analyze, investigate, and quickly identify the root cause of potential security issues in your 
AWS workloads, as well as for detecting suspicious activities. 

AWS Audit Manager just continuously audits your AWS usage to simplify how you assess risk and compliance with regulations and industry 
standards.

Amazon Monitron is simply a service that detects abnormal conditions in industrial equipment such as fans, compressors, motors, etc. 






DNS failover to a static website:
	 Use Route53 with the failover option to a static S3 website bucket or CloudFront distribution.




Automated backup of all of the EBS Volumes for your EC2:
	 Use Amazon Data Lifecycle Manager (Amazon DLM) to automate the creation of EBS snapshots.

You can use Amazon Data Lifecycle Manager DLM to automate the creation, retention, and deletion of snapshots taken 
to back up your Amazon EBS volumes.
 
 
 
 

If your application is composed of several individual services, ALB can route a request to a 
service based on the content of the request such as Host field, Path URL, HTTP header, HTTP method, Query string, or Source IP address.

ALBs can also route and load balance gRPC traffic between microservices or between gRPC-enabled clients and services.
Network Load Balancers do not support gRPC.

A Gateway Load Balancer operates as a Layer 3 Gateway and a Layer 4 Load Balancing service. gRPC protocol is at Layer 7. 





Huge amounts of data and perform quick and flexible queries on it:
	Amazon RedShift

You can use Redshift to analyze all your data using standard SQL and your existing Business Intelligence (BI) tools. 


Amazon Athena can be used to access the information from the file resided over S3 by creating a table on top of it.

Amazon EMR is a way of accessing the Hadoop system like HDFS, Hive, Pig, spark from AWS.No SQL, Need data engineer, OpenSource Frameworks.

Amazon Redshift is data warehouse, which is based on columnar architecture and it has a plug in to add, which is Redshift spectrum, 
to access the files on top S3 as similar to Amazon Athena.
Redshift Traditional data warehouse,SQL, AWS Manage Services, no data engineering team.






Increase network availability by allowing the traffic flow to resume in another instance if the primary instance is terminated:
	Create a secondary elastic network interface and point its private IPv4 address to the application’s domain name. 
	Attach the new network interface to the primary instance. If the instance goes down, move the secondary network interface to 
	another instance.
	
	



Using an Elastic Load Balancer is an ideal solution for adding elasticity to your application. Alternatively, you can also 
create a policy in Route 53, such as a Weighted routing policy, to evenly distribute the traffic to 2 or more EC2 instances.





EBS volume in an Availability Zone, it is automatically replicated within that region only, and not on a separate AWS region, 
to prevent data loss due to a failure of any single hardware component.

EBS volumes can only be attached to an EC2 instance in the same Availability Zone.
EBS Volume snapshots are actually sent to Amazon S3.





In Route 53, which record types will you use to point the DNS name of the Application Load Balancer?
Alias with a type "AAAA" record set and Alias with a type "A" record set.





In Auto Scaling, the following statements are correct regarding the cooldown period:
	It ensures that the Auto Scaling group does not launch or terminate additional EC2 instances before the 
	previous scaling activity takes effect.
	Its default value is 300 seconds - 5m.
	It is a configurable setting for your Auto Scaling group.





Monitor the available swap space of each EC2:
	Install the CloudWatch agent on each instance and monitor the SwapUtilization metric.





CloudWatch Alam is primarily used for monitoring CloudWatch metrics.
CloudWatch Events service is commonly used to deliver a near real-time stream of system events that describe changes in some 
Amazon Web Services (AWS) resources.





Data access from S3 with their strict compliance standards, unauthorized access or suspicious access patterns in S3:
	Use Amazon GuardDuty to monitor malicious activity on S3.





Generate an endpoint policy for trusted S3 buckets.
When you create a Gateway endpoint, you can attach an endpoint policy that controls access to the service to which you are connecting.





AWS Config is a service that enables you to assess, audit, and evaluate the configurations of your AWS resources.
Config dashboard shows the compliance status of your rules and resources. You can verify if your resources 
comply with your desired configurations and learn which specific resources are noncompliant.

AWS Trusted Advisor only provides best practice recommendations. It cannot define rules for your AWS resources.


CloudTrail can track changes and store a history of what happened to your resources, this service still cannot enforce rules 
to comply with your organization's policies.






Each organization unit (OU) must be able to launch new accounts with preapproved configurations from the security team:
	Set up an AWS Control Tower Landing Zone. Enable pre-packaged guardrails to enforce policies or detect violations.

AWS Control Tower provides a single location to easily set up your new well-architected multi-account environment and 
govern your AWS workloads with rules for security, operations, and internal compliance. 
you can select and apply pre-packaged policies enterprise-wide or to specific groups of accounts.






Application takes several minutes to become fully operational:
	Migrate the application to an EC2 instance with hibernation enabled.

While the instance is in hibernation, you pay only for the EBS volumes and Elastic IP Addresses attached to it; there are 
no other hourly charges (just like any other stopped instance).


CloudEndure Migration is just a highly automated lift-and-shift (rehost) solution that simplifies, expedites, 
and reduces the cost of migrating applications to AWS. 






The company require consistent and dedicated access to these network:
	Create a new Direct Connect gateway and integrate it with the existing Direct Connect connection. 
	Set up a Transit Gateway between AWS accounts and associate it with the Direct Connect gateway.
	
AWS Transit Gateway provides a hub and spoke design for connecting VPCs and on-premises networks. 
You can attach all your hybrid connectivity (VPN and Direct Connect connections) to a single Transit Gateway 
consolidating and controlling your organization's.

By attaching a transit gateway to a Direct Connect gateway using a transit virtual interface, you can manage a single connection 
for multiple VPCs or VPNs that are in the same AWS Region.







What service must be used to easily capture, transform, and load streaming data into S3, ElasticSearch, and Splunk?
	Amazon Kinesis Data Firehose

Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. 
It can capture, transform, and load streaming data into  S3,  Redshift,  Elasticsearch Service, and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you are already using today.

Amazon SQS lets you easily move data between distributed application components and helps you build applications in which messages are processed independently (with message-level ack/fail semantics), such as automated workflows. Amazon Kinesis Data Firehose is primarily used to load streaming data into data stores and analytics tools.
SQS can't capture, transform, and load streaming data into Amazon S3,

AWS Data Exchange is  is just a data marketplace service.






To save costs, From Reserved instances as soon as possible:
	Go to the AWS Reserved Instance Marketplace and sell the Reserved instances.
	Terminate the Reserved instances as soon as possible to avoid getting billed at the on-demand price when it expires.
	 
Stopping the Reserved instances as soon as possible if false because It is also possible that there are associated 
Elastic IP addresses, which will incur charges. You have to terminate.





S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and your S3 bucket. 
Transfer Acceleration leverages Amazon CloudFront’s globally distributed AWS Edge Locations. 
As data arrives at an AWS Edge Location, data is routed to your  S3 bucket over an optimized network path.






AWS Fargate is a serverless compute engine for containers that works with both ECS and EKS.

Amazon EKS is more suitable to run the Kubernetes management infrastructure and not Docker. 
It not remove the need to provision and manage servers nor let you specify and pay for resources per application, unlike Fargate EKS.






Collect logs and then easily perform log analysis:
	 S3 for storing ELB log files and EMR for analyzing the log files.
	 
Amazon EMR is the industry-leading cloud big data tools managed Hadoop framework and solution for petabyte-scale data 
processing, interactive analytics, and machine learning using open-source frameworks such as Apache Spark, Apache Hive, and Presto.







Launch a real-time analytics service:
	Create a Kinesis Data Stream and use AWS Lambda to read records from the data stream.

Although Amazon Kinesis Data Firehose captures and loads data in near real-time, AWS Lambda can't be set as its destination.





You can create read replicas within a Region or between Regions for your 
RDS for MySQL, MariaDB, PostgreSQL, and Oracle database instances encrypted at rest with AWS Key Management Service (KMS).





S3 is composed of buckets, object keys, object metadata, object tags, and many other components as shown below:
	S3 bucket name is globally unique, and the namespace is shared by all AWS accounts.
	S3 object key refers to the key name, which uniquely identifies the object in the bucket.
	S3 object metadata is a name-value pair that provides information about the object.
	S3 object tag is a key-pair value used for object tagging to categorize storage.
	 
 
 



	 
Ensure that the required components are properly running before the CloudFormation stack creation proceeds:
	Configure a CreationPolicy attribute to the instance in the CloudFormation template. 
	Send a success signal after the applications are installed and configured using the cfn-signal helper script.
	
In CloudFormation template Use the CreationPolicy attribute when you want to wait on resource configuration actions 
before stack creation proceeds. 

In such cases, you can add a CreationPolicy attribute to the instance and then send a success signal to the instance 
after the applications are installed and configured.





Docker It is compulsory that the application has access to 5 GB of ephemeral storage:
	Deploy the application to an Amazon ECS cluster that uses Fargate tasks.
By default, Fargate tasks are given a minimum of 20 GiB of free ephemeral storage. 
	
	 



A VPC peering connection is a networking connection between two VPCs that enables you to route traffic between them privately. 
Instances in either VPC can communicate with each other as they are in the same network. 

You can create a VPC peering connection between your own VPCs,  another AWS account, or different Region.





Amazon Aurora DB cluster to Autora serverless:
	Changing the Aurora instance class from Provisioned to Serverless is not possible.
	Use AWS Database Migration Service (AWS DMS) to migrate to a new Aurora Serverless database.
AWS Database Migration Service helps you migrate your databases to AWS with virtually no downtime. 
You can set up a DMS task for either one-time migration or ongoing replication. 


Take a snapshot involves a long period of downtime since you have to stop the application until the new cluster is created.

Add an Aurora Replica to the cluster and set its instance class to Serverless,While this method is valid, 
the database becomes unavailable for writing for a short period of time during failover.




You can launch an EBS-backed EC2 instance and attach several Instance Store volumes but remember that there are some 
EC2 Instance types that don't support this kind of setup.

ENI will stay attached even if you stopped your EC2 instance.
EIP will actually remain associated with your instance even after stopping it.


Since only EBS-backed instances can be stopped and restarted, it is implied that the instance is EBS-backed. 
Remember that an instance store-backed instance can only be rebooted or terminated, and its data will be erased if the 
EC2 instance is either stopped or terminated.

If you stopped an EBS-backed EC2 instance, the volume is preserved, but the data in any attached instance store volume will be erased. 
Keep in mind that an EC2 instance has an underlying physical host computer. 
If the instance is stopped, AWS usually moves the instance to a new host computer. 
Your instance may stay on the same host computer if there are no problems with the host computer.
 
In addition, its Elastic IP address is remove from the instance if it is an EC2-Classic instance. 
Otherwise, if it is an EC2-VPC instance, the Elastic IP address remains associated.






MySQL database hosted on Amazon RDS is running out of disk storage:
	Modify the DB instance settings to enable autoscaling.





Aurora as the Amazon RDS database need 90-day backup retention:
	Create an AWS Backup plan to take daily snapshots with a retention period of 90 days.

Aurora maximum backup retention period for automated backup is only 35 days.

AWS Backup makes protecting your AWS storage volumes, databases, and file systems simple by providing a central place where you 
can configure and audit the AWS resources you want to backup, automate backup scheduling, set retention policies, 
and monitor all recent backup and restore activity.





You are limited to provision a maximum of 20 instances per region or 
On-Demand Instances per your vCPU-based On-Demand Instance limit, 
20 Reserved Instances, and requesting Spot Instances per your dynamic Spot limit per region. 

New AWS accounts may start with limits that are lower than the limits described here.

vCPU-based On-Demand Instance limit is set per region and not per Availability Zone. 






The company’s solutions architect must implement a solution that checks for untagged AWS resources.
	Use an AWS Config rule to detect non-compliant tags.
	
	
	
	
Developers are unable to remove or modify any rules in AWS Config.
	 Add the developers' AWS account to an Organization Unit (OU). Attach a service control policy (SCP) to the OU that 
	 restricts access to AWS Config.
	 
SCPs alone is not sufficient to grant permissions to the accounts in your organization. No permissions are granted by an SCP. 
An SCP defines a guardrail or sets limits on the actions that the account's administrator can delegate to the IAM users and roles 
in the affected accounts.

In the scenario, even if a developer has admin privileges, he/she will be unable to modify Config rules if an SCP does not permit it.

Configure an AWS Config rule, This solution just monitors changes on AWS Config rules; 
it does not restrict permissions, which is what's needed in the scenario. 

The AWS Control Tower service is commonly used to set up and govern a secure multi-account AWS environment. 
This service is not used to restrict access from invoking an action to a specific resource, such as AWS Config.







Use Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) :
	with a master key that it regularly rotates. 
	S3 server-side encryption uses one of the strongest block ciphers available, 256-bit Advanced Encryption.

	 
Use Server-Side Encryption with Customer Master Keys (CMKs) Stored in AWS Key Management Service (SSE-KMS):
	use envelope encryption,SSE-KMS also provides you with an audit trail that shows when your CMK was used and by whom. 
	Additionally, you can create and manage customer-managed CMKs or use AWS managed CMKs that are unique to you, your service, 
	and your Region.

Use Server-Side Encryption with Customer-Provided Keys (SSE-C):
	You manage the encryption keys and Amazon S3 manages the encryption, as it writes to disks, and decryption when you access 
	your objects.


SSE-S3 and SSE	-C do not provide  audit trail that shows when your Key was used and by whom,unlike SSE-KMS.
	 
	 
	 



Unified CloudWatch agent, and an older CloudWatch Logs agen:
	Collect both logs and advanced metrics with the installation and configuration of just one agent.
	
Unified agent collect metrics and logs from  EC2, hybrid, and on-premises servers running both Linux and Windows
Unified agent also enables the collection of additional system metrics, for in-guest visibility.
	
CloudWatch Logs Insights enables you to interactively search and analyze your log data in CloudWatch Logs.	
	 
	 
	 


Duplicating resources in another region:
	AWS CloudFormation
You can create a template that describes all the AWS resources that you want (like  EC2 or RDS ), 
AWS CloudFormation takes care of provisioning and configuring those resources for you with VPC.

AWS ElasticBeanstalk is incorrect. 
	Elastic Beanstalk is a high-level service that simplifies the creation of application resources such as an 
	EC2 with preconfigured proxy servers (Nginx or Apache), a load balancer, an auto-scaling group, and so on. 
	Elastic Beanstalk environments have limited resources; for example, Elastic Beanstalk does not create a VPC for you.




 
Auto Scaling group need new AMI instance:
	 Create a new Launch Configuration with the new instance type and update the Auto Scaling Group.
	 You can't modify a launch configuration after you've created it.
	 
	 
	 
	 
	 
EBS provides three volume types to best meet the needs of your workloads: 
	General Purpose (SSD)   for cost-effective storage option for a wide variety of workloads.  gp2
	Provisioned IOPS (SSD)  for very intensive I/O workloads that require very high throughput. io1 
	Magnetic                for Low-cost HDD volume designed for throughput-intensive/infrequently accessed data workloads. st1/sc1




	 
Increase read-throughput on the MySQL database:
	Enable Amazon RDS Read Replicas
	 
Read replicas are available in Amazon RDS for MySQL, MariaDB, Oracle, and PostgreSQL as well as Amazon Aurora.	 
	 
	 




VM workloads to the AWS cloud, “lift-and-shift” strategy: 
		Install the AWS Replication Agent on each of the on-premises VMs to continuously replicate the servers to AWS. 
		Use AWS Migration Service (AWS MGN) to launch test instances and perform cutover once testing is completed.
		
AWS Application Migration Service (AWS MGN) is the primary migration service recommended for lift-and-shift migrations to AWS.	 
AWS MGN enables organizations to move applications to AWS without having to make any changes to the applications, 
their architecture, or the migrated servers.

AWS MGN automatically converting your source servers from physical, virtual machines, and cloud infrastructure to run natively on AWS.
Implementation begins by installing the AWS Replication Agent on your source servers.
	 
	 
AWS Application Discovery Service is primarily used to track the migration status not capable of doing the actual migration.


	 
	 
	 

Requirement if I/O throughput is the highest priority:
		Use Storage optimized instances with Instance Store Volume.
	 
EC2 Instance types can be broadly classified into five:
	General Purpose         =  Provide a balance of compute, memory and networking resources.
	Compute-Optimized       =  These types of instances have a higher CPU to memory ratio.
	Memory-Optimized        =  Optimized to execute memory-intensive operations like in-memory databases or processing real-time data.
	Storage-Optimized       =  Storage optimized EC2 instances are used to support high I/O workloads such as parallel processing.
	Accelerated Computing   =  It provides compute capacity for very high performant machine learning and scientific workloads( With GPU).




UDP is not supported in Application Load Balancer. UDP is a Layer 4 traffic, use a Network Load Balancer.
	
	
	
	
AWS resources in Amazon VPC don’t go beyond their respective service limits,rovides real-time guidance:
	AWS Trusted Advisor.
	
Trusted Advisor is online tool that provides you with real-time guidance to help you provision your resources following best practices. 
It inspects your AWS environment and makes recommendations for saving money, improving system performance and reliability,security gaps.

	

	 
	 
Development of its GraphQL APIs, custom domain feature and https:
	Develop the application using the AWS AppSync service and use its built-in custom domain feature. 
	Associate an SSL certificate to the AWS AppSync API using the ACM service to enable HTTPS communication.

With AppSync, you can use custom domain names to configure a single, memorable domain that works for both your GraphQL and real-time APIs.
	
	
	
	
	 
	 
Multiple AWS Site-to-Site VPN,slow connectivity issues:
	Associate the VPCs to an Equal Cost Multipath Routing (ECMR)-enabled Transit Gateway and attach additional VPN tunnels.
	 
AWS Transit Gateway also enables you to scale the IPsec VPN throughput with equal-cost multi-path (ECMP) routing support over 
multiple VPN tunnels. 
A single VPN tunnel still has a maximum throughput of 1.25 Gbps. 
If you establish multiple VPN tunnels to an ECMP-enabled Transit Gateway, it can scale beyond the default limit of 1.25 Gbps.

	 
	 
	 
	 
For provides higher bandwidth, higher packet per second (PPS) performance, and consistently lower inter-instance latencies: 
	Enable Enhanced Networking with Elastic Network Adapter (ENA) on the Windows EC2 Instances. 
	 
With RDS Enhanced Monitoring, you can monitor the operating system of your DB instance in real time.
With EC2 enable Detailed Monitoring, EC2 console displays monitoring graphs with a 1-minute period for the instance.

	 
	 
	 
	 
In SQS the number of messages is constantly growing:	 
		Create an AMI of the backend application's EC2 instance. Use the image to set up an Auto Scaling group and configure a 
		target tracking scaling policy based on the ApproximateAgeOfOldestMessage metric.
		
The ApproximateAgeOfOldestMessage metric is useful when applications have time-sensitive messages and you need to ensure that 
messages are processed within a specific time period.






On Receives a burst of traffic then instance takes 1 minute to boot up before it can respond to user requests:
		Create a step scaling policy and configure an instance warm-up time condition.
	 
	 
	 
	 

Telecommunication carriers' 5G networks:	 
		Launch the application to an Amazon Elastic Kubernetes Service (Amazon EKS) cluster. Create node groups in 
		Wavelength Zones for the Amazon EKS cluster via the AWS Wavelength service. 
		Apply the AWS authenticator configuration map (aws-auth ConfigMap) to your cluster.
		
AWS Wavelength combines the high bandwidth and ultralow latency of 5G networks with AWS compute and storage services so that 
developers can innovate and build a new class of applications.
	
	



The Volume Gateway is a cloud-based iSCSI block storage volume for your on-premises applications.

There are two options for Volume Gateway:
	Cached Volumes - you store volume data in AWS, with a small portion of recently accessed data in the cache on-premises.
	Stored Volumes - you store the entire set of volume data on-premises and store periodic point-in-time backups (snapshots) in AWS.

			
			
	 
	 
	 
Both the HTTP (80) and HTTPS (443) check offered Application Load Balancer. 
A TCP health check is only offered in Network Load Balancers and Classic Load Balancers.


	 



Security groups stateful
Network Firewall is a stateful, supports both stateless and stateful rules. 
Network ACLs are stateless.
 
 
 


IAM roles are global services that are available to all regions hence, 
all you have to do is assign the existing IAM role to the instance in the new region.





Multi-Region VPC transfer data between the instances without traversing the public internet:
	Set up a VPC peering connection between the VPCs.
	Re-configure the route table’s target and destination of the instances’ subnet.

VPC endpoints are region-specific only and do not support inter-region communication.
VPC endpoint enables users to privately connect their VPC to supported AWS services. 




Generated log files should be encrypted to avoid any security issues:
	Use CloudTrail with its default settings.
	
By default, CloudTrail event log files are encrypted using Amazon S3 server-side encryption (SSE). 
You can also choose to encrypt your log files with an AWS Key Management Service (AWS KMS) key. 





In EBS encryption, what service does AWS use to secure the volume's data at rest? 
	By using your own keys       	in AWS Key Management Service (KMS).
	By using Amazon-managed keys 	in AWS Key Management Service (KMS).






Enable the security team to inspect traffic entering and exiting their VPC:
	Create a firewall using the AWS Network Firewall service at the VPC level then add custom rule groups for inspecting ingress 
	and egress traffic. Update the necessary VPC route tables.

Traffic Mirroring is simply an Amazon VPC feature that you can use to copy network traffic from an elastic network interface. 
Traffic mirror filters can't inspect the actual packet of the incoming and outgoing traffic.






Processing should not be delayed or interrupted:
	Use On-Demand Capacity Reservations, which provide compute capacity that is always available on the specified recurring schedule.

On-Demand Capacity Reservations enable you to reserve compute capacity for your EC2 instances in a specific Availability Zone 
for any duration






Performance Issue of the Kinesis Data Streams:
	Increase the number of shards of the Kinesis stream by using the UpdateShardCount command.	




Highly scalable, yet still cost-effective:
	Launch an Auto-Scaling group of EC2 instances to host your application services and an SQS queue. 
	Include an Auto Scaling trigger to watch the SQS queue size which will either scale in or scale out the number of 
	EC2 instances based on the queue.
	
	
	
	
Extracting and visualizing sentiments from the transcribed files:
	Create an Amazon Comprehend analysis job. Index the sentiment along with the transcript to an Amazon OpenSearch cluster. 
	Visualize the results using the OpenSearch Dashboard.
	
	


Lambda execution The default timeout is 3 seconds, and minumum 1 second up to a maximum value of 15 minutes.




Set up the multi-account AWS environment for your company:
	Use AWS Organizations and Service Control Policies to control services on each account.

AWS Organizations offers policy-based management for multiple AWS accounts. 
With Organizations, you can create groups of accounts, automate account creation, apply and manage policies for those groups.

Organizations enable you to centrally manage policies across multiple accounts without requiring custom scripts and manual processes. 
It allows you to create Service Control Policies (SCPs) that centrally control AWS service use across multiple AWS accounts.



@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@

10 applications with an on-premises data footprint of about 70TB for each application, two weeks to migration:
	Order 10 Snowball Edge Storage Optimized devices to complete the one-time data transfer
	Setup Site-to-Site VPN to establish on-going connectivity between the on-premises data center and AWS Cloud

Snowball Edge:
	It provides up to 80 TB of usable HDD storage, 40 vCPUs, 1 TB of SATA SSD storage, and up to 40 Gb network connectivity.
 
Site-to-Site VPN:
	VPN Connections can be configured in minutes and are a good solution if you have an immediate need, have low to modest 
	bandwidth requirements with internat base connectivity.





Snowmobile capacity of up to 100 petabytes. 
To migrate large datasets of 10PB or more in a single location, you should use Snowmobile.
For datasets less than 10PB or distributed in multiple locations, you should use Snowball. 






When you apply a retention period to an object version explicitly, you specify a Retain Until Date for the object version.
S3 stores the Retain Until Date setting in the object version's metadata and protects the object version until the retention period expires.

In Default setting you specify a duration, in either days or years, for every object version placed in the bucket.





Intermediary query results are kept only for 24 hours:
	Store the intermediary query results in S3 Standard storage class


S3 Glacier Instant Retrieval:
	S3 Glacier Instant Retrieval delivers the fastest access to archive storage, with the same throughput and milliseconds access as 
	the S3 Standard and S3 Standard-IA storage classes.





Native Windows workloads should continue to AWS:
	Amazon Storage Gateway’s File Gateway: When you need to access S3 using a file system protocol, you should use File Gateway. 
	You get a local cache in the gateway that provides high throughput and low latency over SMB.
	Its, does not support file shares for native Windows workloads, for that use Amazon FSx File Gateway.

Use Amazon FSx File Gateway to provide low-latency, on-premises access to fully managed file shares in  FSx for Windows File Server.
The applications deployed on AWS can access this data directly from Amazon FSx in AWS.
(SMB clients with native Windows SMB environment)





Wants to integrate data files from application with AWS Cloud via an NFS interface:
	AWS Storage Gateway - File Gateway.
	
AWS Storage Gateway's file interface, or file gateway, offers you a seamless way to connect to the cloud in order to 
store application data files and backup images as durable objects on Amazon S3 cloud storage. 

File gateway offers SMB or NFS-based access to data in Amazon S3 with local caching. 
As the company wants to integrate data files from its analytical instruments into AWS via an NFS interface, 
therefore AWS Storage Gateway - File Gateway is the correct answer.

Volume Gateway to present iSCSI block storage volumes, Volume Gateway does not support NFS interface.
Tape Gateway does not support NFS interface.
You cannot use AWS Site-to-Site VPN to integrate data files via the NFS interface.



	
	

1 EC2 instance, 1 AMI and 1 snapshot exist in region B:
	When the new AMI is copied from region A into region B, it automatically creates a snapshot in region B because 
	AMIs are based on the underlying snapshots.
	



GuardDuty service. All the existing findings have to be deleted:
	Disable the service in the general settings - Disabling the service will delete all remaining data, including your 
	findings and configurations before relinquishing the service permissions and resetting the service.


Suspend the service in the general settings:
	This will immediately stop the service from analyzing data, but does not delete your existing findings or configurations.
	
No De-register option,  only Disable and Suspend.


	


ALB Routing:
	Host-based Routing:
	You can route a client request based on the Host field of the HTTP header allowing you to route to multiple 
	domains from the same load balancer.

	Path-based Routing:
	You can route a client request based on the URL path of the HTTP header.

	HTTP header-based routing:
	You can route a client request based on the value of any standard or custom HTTP header.

	HTTP method-based routing:
	You can route a client request based on any standard or custom HTTP method.

	Query string parameter-based routing:
	You can route a client request based on the query string or query parameters.

	Source IP address CIDR-based routing:
	You can route a client request based on source IP address CIDR from where the request originates.

The path pattern is applied only to the path of the URL, not to its query parameters.




As the given use-case requires exactly 10 instances to be available during the peak hour:
	Configure your Auto Scaling group by creating a scheduled action that kicks-off at the designated hour on the last day of the month. 
	Set the desired capacity of instances to 10. This causes the scale-out to happen before peak traffic kicks in at the designated hour.

A scheduled action sets the minimum, maximum, and desired sizes to what is specified by the scheduled action at the time 
specified by the scheduled action. For the given use case, the correct solution is to set the desired capacity to 10. 
When we want to specify a range of instances, then we must use min and max values.

Target tracking policy or simple tracking policy cannot be used to effect a scaling action at a certain designated hour.





AWS services would you recommend as a caching layer:
	DynamoDB Accelerator (DAX) - Amazon DynamoDB Accelerator (DAX) is a fully managed, highly available, in-memory cache for DynamoDB.
	ElastiCache - Amazon ElastiCache for Memcached is an ideal front-end for data stores like Amazon RDS or Amazon DynamoDB.





INVALID lifecycle transitions:
	S3 Intelligent-Tiering => S3 Standard
	S3 One Zone-IA => S3 Standard-IA


Any storage class to the S3 Standard storage class. 
Any storage class to the Reduced Redundancy storage class. 
S3 Intelligent-Tiering storage class to the S3 Standard-IA storage class.
S3 One Zone-IA storage class to the S3 Standard-IA or S3 Intelligent-Tiering.
 
 

VALID lifecycle transitions:
	S3 Standard => S3 Intelligent-Tiering
	S3 Standard-IA => S3 Intelligent-Tiering
	S3 Standard-IA => S3 One Zone-IA


S3 Standard storage class to any other storage class. 
Any storage class to the S3 Glacier or S3 Glacier Deep Archive.
S3 Standard-IA storage class to the S3 Intelligent-Tiering or S3 One Zone-IA storage classes.
S3 Intelligent-Tiering storage class to the S3 One Zone-IA storage class.
S3 Glacier storage class to the S3 Glacier Deep Archive storage class.





 
Use Instance Store based EC2 instances for high random I/O performance at low cost,and the resilient architecture 
	can adjust for the loss of any instance.

Use EBS based EC2 instances - EBS based volumes would need to use Provisioned IOPS (io1) as the storage type and that would 
incur additional costs. As we are looking for the most cost-optimal solution, this option is ruled out.

Use EC2 instances with EFS mount points - Using EFS implies that extra resources would have to be provisioned. 
As we are looking for the most resource-efficient solution, this option is also ruled out.





Configure AWS WAF on the Application Load Balancer in a VPC:
	WAF with ALB to allow or block requests based on the rules in a web access control list (web ACL). 
	Geographic (Geo) Match Conditions in AWS WAF allows you to use AWS WAF to restrict application access based on the 
	geographic location of your viewers. 
With geo match conditions you can choose the countries from which AWS WAF should allow access.
	
Use Geo Restriction feature of Amazon CloudFront in a VPC :
	CloudFront helps in restricting traffic based on the user's geographic location. 
	But, CloudFront works from edge locations and doesn't belong to a VPC, this is Incorrect.





Ingest the data in Kinesis Data Firehose and use an intermediary Lambda function to filter and transform the incoming stream 
before the output is dumped on S3.

	Amazon Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. 
	It can capture, transform, and load streaming data into Amazon S3, Amazon Redshift, Amazon Elasticsearch Service, 
	and Splunk, enabling near real-time analytics with existing business intelligence tools and dashboards you’re already using today.


	Kinesis Data Analytics cannot directly ingest data from the source as it ingests data either from 
	Kinesis Data Streams or Kinesis Data Firehose, so this option is ruled out.

	Kinesis Data Streams cannot directly write the output to S3. Unlike Firehose, KDS does not offer a ready-made integration via an 
	intermediary Lambda function to reliably dump data into S3. 

	EMR uses Hadoop, an open-source framework, to distribute your data and processing across a resizable cluster of Amazon EC2 instances. 
	Using an EMR cluster would imply managing the underlying infrastructure so it’s ruled out because the correct solution 
	for the given use-case should require the least amount of infrastructure maintenance.

	 
	 
 

Make More resilient to spikes in request rates:
	You can use Aurora replicas and CloudFront distribution to make the application more resilient to spikes in request rates.


Aurora Replicas have two main purposes. You can issue queries to them to scale the read operations for your application.
Aurora Replicas also help to increase availability. If the writer instance in a cluster becomes unavailable, 
Aurora automatically promotes one of the reader instances to take its place as the new writer.

Use AWS Global Accelerator - AWS Global Accelerator is a service that improves the availability and performance of your 
applications with local or global users. It provides static IP addresses that act as a fixed entry point to your application 
endpoints in a single or multiple AWS Regions.
Since CloudFront is better for improving application resiliency to handle spikes in traffic, so this option is ruled out.






Since the data is accessed only twice in a financial year but needs rapid access when required, the most cost-effective 
storage class for this use-case is S3 Standard-IA. 

Standard-IA has the same availability as that of S3 Intelligent-Tiering. So, it's cost-efficient to use 
S3 Standard-IA instead of S3 Intelligent-Tiering.





Maintenance patch, the instance, MOST time/resource efficient steps:
	Put the instance into the Standby state and then update the instance by applying the maintenance patch. 
	Once the instance is ready, you can exit the Standby state and then return the instance to service
You can put an instance that is in the InService state into the Standby state, update some software or troubleshoot the instance.	
Instances that are on standby are still part of the Auto Scaling group, but they do not actively handle application traffic.	

Suspend the ReplaceUnhealthy process type for the Auto Scaling group and apply the maintenance patch to the instance. 
Once the instance is ready, you can manually set the instance's health status back to healthy and activate the 
ReplaceUnhealthy process type again.


Taking the snapshot of the existing instance to create a new AMI and then creating a new instance not time/resource optimal.




Peak rate of about 1000 messages per second to be processed via SQS:
	Use Amazon SQS FIFO queue in batch mode of 4 messages per operation to process the messages at the peak rate.
	
Maximum batch 10 messages per operation , FIFO queues can support up to 3,000 messages per second. 
	



24*7 in the production environment and 8 hour for dev:
	Use reserved EC2 instances for the production application and on-demand instances for the dev application.

Spot blocks can only be used for a span of up to 6 hours, so this option does not meet the requirements,
also note that AWS has stopped offering Spot blocks to new customers.




There are no S3 data transfer charges when data is transferred in from the internet. 
Also with S3TA, you pay only for transfers that are accelerated.
Does not need to pay any transfer charges for the upload because S3TA did not result in an accelerated transfer.





Default ASG Scaling- in: Select the AZ with most instance and then:
	First priority is given to any allocation strategy for On-Demand vs Spot instances. 
	The next priority is to consider any instance with the oldest launch template unless there is an instance 
	that uses a launch configuration. So this rules out Instance A. 
	Next, you need to consider any instance which has the oldest launch configuration. 
	This implies Instance B will be selected for termination and Instance C will also be ruled out as it has the 
	newest launch configuration. 
	Instance D, which is closest to the next billing hour, is not selected as this criterion is last in the order of priority.
	
	





Wants to manage the workload using a mix of on-demand and spot instances across multiple instance types:
	You can only use a launch template to provision capacity across multiple instance types using both 
	On-Demand Instances and Spot Instances to achieve the desired scale, performance, and cost.
	
You cannot use a launch configuration to provision capacity across multiple instance types using both 
On-Demand Instances and Spot Instances.




(ASG) is not terminating an unhealthy Amazon EC2 instance:
	The health check grace period for the instance has not expired.(with until the health check grace period expires, def 5m, with CLI 0)
	The instance maybe in Impaired status.(waits a few minutes for the instance to recover.)
	The instance has failed the ELB health check status. (By default, Amazon EC2 Auto Scaling doesn't use the results of ELB health 
	
	checks to determine an instance's 
	health status when the group's health check configuration is set to EC2. As a result, 
	Amazon EC2 Auto Scaling doesn't terminate instances that fail ELB health checks)
	
ASG terminates Spot instances when capacity is no longer available or the Spot price exceeds your maximum price.
ASG needs more number of instances, ASG will launch new, healthy instances and does not keep unhealthy ones alive.
ASG terminates the unhealthy instance also if A custom health check might have failed.




Kinesis Agent cannot write to a Kinesis Firehose for which the delivery stream source is already set as Kinesis Data Streams.

Kinesis Agent is a stand-alone Java software application that offers an easy way to collect and send data to Kinesis Data Streams or Kinesis Firehose.





AWS Organizations and you would like to ensure all EC2 instances in all these accounts can communicate privately:
	Create a VPC in an account and share one or more of its subnets with the other accounts using Resource Access Manager.
	
AWS Resource Access Manager (RAM) is a service that enables you to easily and securely share AWS resources with any 
AWS account or within your AWS Organization. You can share Transit Gateways, Subnets,Reoute53, DNS Resolver etc.
	



Run their applications on single-tenant hardware and MOST cost-effective way of isolating EC2 instances to a single tenant:
	Dedicated Instances. (Not BYOL)

A Dedicated Host is also a physical server that's dedicated for your use. (BYOL)
With a Dedicated Host, you have visibility and control over how instances are placed on the server.
This option is costlier than the Dedicated Instance and hence is not the right choice for the current requirement.





Setup a lifecycle policy to transition the raw zone data into Glacier Deep Archive after 1 day of object creation.
Use Glue ETL job to write the transformed data in the refined zone using a compressed file format.

It is cost-optimal to write the data in the refined zone using a compressed format instead of CSV format.



By default, an S3 object is owned by the AWS account that uploaded it. 
So the S3 bucket owner will not implicitly have access to the objects written by Redshift cluster.





AWS Global Accelerator, you can shift traffic gradually or all at once between the blue and the green environment and 
vice-versa without being subject to DNS caching on client devices and internet resolvers(mobile phones which are to DNS caching).

Route 53 weighted routing to spread traffic across different deployments not working because
DNS caching is a negative behavior for this use case and hence Route 53 is not a good option.


ALB with weighted target groups feature for blue/green deployments now working because ALB not Global servies it Regional.

	
	


All the log files (consisting of system logs, application logs, database logs, etc) that can be processed in a serverless fashion:
	Kinesis Data Firehose.
	
 
 
 

"Effect": "Allow",
  "Resource": "*",
  "Condition": {
	"StringEquals": {
	  "aws:RequestedRegion": "eu-west-1"
	}

It allows running EC2 instances only in the eu-west-1 region, and the API call can be made from anywhere in the world.

aws:RequestedRegion represents the target of the API call. 
So in this example, we can only launch EC2 instances in eu-west-1, and we can do this API call from anywhere.



Prevent team of developers in your company, make self admin:
	For each developer, define an IAM permission boundary that will restrict the managed policies they can attach to themselves.
AWS supports permissions boundaries for IAM entities (users or roles).

SCP not work here because, SCPs offer central control over the maximum available permissions for all accounts in your Organization.





Notifies the security team 30 days before the certificate expiration:
	Leverage AWS Config managed rule to check if any third-party SSL/TLS certificates imported into ACM are marked for expiration 
	within 30 days. Configure the rule to trigger an SNS notification to the security team if any certificate expires within 30 days.
	

You can leverage an AWS Config managed rule to check if any ACM certificates in your account are marked for 
expiration within the specified number of days. Certificates provided by ACM are automatically renewed. 

ACM does not automatically renew the certificates that you import. 

Certificate Manager (ACM) does not attempt to renew third-party certificates that are imported.

Any SSL/TLS certificates created via ACM do not need any monitoring/intervention for expiration. 
ACM automatically renews such certificates. 


It is certainly possible to use the days to expiry CloudWatch metric to build a CloudWatch alarm to monitor the imported ACM certificates. 
But this option needs more configuration effort than directly using the AWS Config managed rule.



Notified via an email whenever the CPU utilization high:
	SNS and Amazon CloudWatch.
You can use CloudWatch Alarms to send an email via You can use CloudWatch Alarms to send an email via SNS whenever 
any of the EC2 instances breaches a certain threshold. whenever any of the EC2 instances breaches a certain threshold.
	
	
	

decouple the user authentication process for the application:
	Use Cognito Authentication via Cognito User Pools for your Application Load Balancer
	Application Load Balancer can be used to securely authenticate users for accessing your applications.


You cannot directly integrate Cognito User Pools with CloudFront distribution as you have to create a separate Lambda@Edge 
This involves additional development effort.







replicate the newly created on-premises video files to the EFS file system:
	Configure an AWS DataSync agent on the on-premises server that has access to the NFS file system. 
	Transfer data over the Direct Connect connection to an AWS PrivateLink interface VPC endpoint for Amazon EFS by using a private VIF. 
	Set up a DataSync scheduled task to send the video files to the EFS file system every 24 hours.
	



PostgreSQL port = 5432 HTTP port = 80 HTTPS port = 443
The security group of RDS should have an inbound rule from the security group of the EC2 instances in the ASG on port 5432

The security group of the EC2 instances should have an inbound rule from the security group of the ALB on port 80

The security group of the ALB should have an inbound rule from anywhere on port 443










=================================================
#Code | Helping Heand | Example
=================================================


#Node Lambda API
-------------------------------------------------
exports.handler =  async function(event, context) {
    return {
        statusCode: 200,
        body: JSON.stringify("Simple NodeJs API Response !"),
      };
}


#PythonLabda
-------------------------------------------------
import json

def lambda_handler(event, context):
    body = "Hello from Lambda!"
    statusCode = 200
    return {
        "statusCode": statusCode,
        "body": json.dumps(body),
        "headers": {
            "Content-Type": "application/json"
        }
    }
	
	
